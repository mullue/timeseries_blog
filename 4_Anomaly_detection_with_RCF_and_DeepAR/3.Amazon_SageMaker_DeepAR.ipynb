{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3. Amazon SageMaker DeepAR\n",
    "\n",
    "This notebook shows how to apply the SageMaker [DeepAR built-in algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html). DeepAR forecasting algorithm is a supervised learning algorithm for forecasting scalar (one-dimensional) time series using recurrent neural networks (RNN) to produce both point and probabilistic forecasts.The DeepAR forecasting algorithm can provide better forecast accuracies compared to classical forecasting techniques such as Autoregressive Integrated Moving Average (ARIMA) or Exponential Smoothing (ES), both of which are implemented in many open-source and commercial software packages for forecasting. \n",
    "\n",
    "## Table Of Contents\n",
    "The overall process for this is:\n",
    "\n",
    "1. Setup\n",
    "1. Data Preparation\n",
    "1. Training the DeepAR Model\n",
    "1. Prediction\n",
    "1. Plotting the Prediction\n",
    "\n",
    "To get started, simply execute the cells below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup \n",
    "\n",
    "We use variables and dataframes that we stored in Lab1. Please make sure you already finished 1st step.\n",
    "- [1.Exploratory_Data_Analysis.ipynb](1.Exploratory_Data_Analysis.ipynb)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "We will divide our clikstream events by page so that each page has its own clickstream timesereis.\n",
    "\n",
    "**Note**\n",
    "> If you went through the [3rd Hands on Lab](../3_Automate_sales_projections_with_Amazon_Forecast/README.md) of Amazon forecast service. You may consider the pages as products (SKU) sold in retail store.  \n",
    "> If we use Amazon Forecast, page click data will be target timeseries and other series (users, urls) will be related timesreies. \n",
    "\n",
    "We will predict the number of clicks in 10 minutes by referring to the number of visitors. To do this, we use the number of clicks as the target feature and the number of users as the dynamic feature.\n",
    "\n",
    "Change the data to the format that DeepAR algorithm use. The records in your input files should contain the following fields:\n",
    "\n",
    "* **start** : The start timestamp. A string with the format YYYY-MM-DD HH:MM:SS.\n",
    "* **target** : An array of floating-point values or integers that represent the time series. Here, we will use clickstream counts in 10 minutes for forecasting value.\n",
    "* **dynamic_feat (optional)** : An array of arrays of floating-point values or integers that represents the vector of custom feature time series. Here, we will use the number of visitors in 10 minutes for dynamic features.\n",
    "* **cat (optional)** : An array of categorical features that can be used to encode the groups that the record belongs to. We do not use categorical values in this example.\n",
    "\n",
    "```python\n",
    "# example:\n",
    "{\"start\": \"2012-03-01 00:00:00\", \"target\": [24.0, 22.0, 20.0, 17.0, ...], \"dynamic_feat\": [[13, 14, 8, ...]]}\n",
    "```\n",
    "\n",
    "For more information regarding input/outpot format of DeepAR : https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html#deepar-inputoutput\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "for index, url in zip(range(len(urls)), urls):\n",
    "    agg_click_users = filtered_clickstream[filtered_clickstream['url'] == url].set_index('timestamp').resample('10T')\n",
    "    clicks = agg_click_users.sum()['clickstream_id']\n",
    "    users  = agg_click_users.nunique()['user_session_id']\n",
    "    \n",
    "    data = {'start' : str(agg_click_users.nunique().index[0]),\n",
    "            'target': list(clicks.values.astype('float')),\n",
    "            'dynamic_feat': [list(users.values.astype('float'))]\n",
    "            }\n",
    "    training_data.append(data)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the dict type above into a json file.  \n",
    "Write training and test files in JSON Lines, and upload to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def write_dicts_to_file(path, data):\n",
    "    with open(path, 'wb') as fp:\n",
    "        for row in training_data:\n",
    "            fp.write(json.dumps(row).encode(\"utf-8\"))\n",
    "            fp.write(\"\\n\".encode('utf-8'))\n",
    "            \n",
    "write_dicts_to_file(\"train.json\", training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-308961792850/deepar-clickstream/train.json'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "s3_bucket = sagemaker.Session().default_bucket()  # replace with an existing bucket if needed\n",
    "s3_prefix = 'deepar-clickstream'    # prefix used for all data stored within the bucket\n",
    "\n",
    "role = sagemaker.get_execution_role()             # IAM role to use by SageMaker\n",
    "\n",
    "train_s3 = sagemaker_session.upload_data(path='train.json', key_prefix=s3_prefix)\n",
    "train_s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the status of the upload by skiming the uploaded file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"start\": \"2012-03-01 00:00:00\", \"target\": [24.0, 22.0, 20.0, 17.0, 15.0, 12.0, 15.0, 10.0, 14.0, 9....\n"
     ]
    }
   ],
   "source": [
    "import s3fs\n",
    "\n",
    "s3filesystem = s3fs.S3FileSystem()\n",
    "with s3filesystem.open(train_s3, 'rb') as fp:\n",
    "    print(fp.readline().decode(\"utf-8\")[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training the DeepAR Model\n",
    "\n",
    "Just like other built-in algorithms, we need to define Estimator with algorhtim and hyperparameters and fit the model with the training data that we prepared above.\n",
    "\n",
    "We are using the [Python SageMaker SDK](https://sagemaker.readthedocs.io/en/stable/index.html) to:\n",
    "\n",
    "1. Create our [Estimator](https://sagemaker.readthedocs.io/en/stable/estimators.html) defining the algorithm and fitting/hyper-parameters\n",
    "2. Define our [data channels](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo-running-container.html#your-algorithms-training-algo-running-container-inputdataconfig) to fit and validate on\n",
    "3. [Fit](https://sagemaker.readthedocs.io/en/stable/estimators.html#sagemaker.estimator.Estimator.fit) a model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "# we use 10 minutes frequency for the time series\n",
    "freq = datetime.timedelta(minutes=10)\n",
    "\n",
    "# we predict for 24 hours and use same context length with prediction length.\n",
    "prediction_length = 24 * 6\n",
    "context_length = 24 * 6\n",
    "\n",
    "image_name = sagemaker.amazon.amazon_estimator.get_image_uri(region, \"forecasting-deepar\", \"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    base_job_name='deepar-clickstream'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to set some hyperparameters: for example, frequency of the time series used, number of data points the model will look at in the past, number of predicted data points. \n",
    "\n",
    "The other hyperparameters concern the model to train (number of layers, number of cells per layer, likelihood function) and the training options such as early stopping patience, number of epochs, batch size, and learning rate, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"time_freq\": '10min',\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"mini_batch_size\": \"64\",\n",
    "    \"learning_rate\": \"5E-4\"\n",
    "}\n",
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to launch the training job. SageMaker will start an EC2 instance, download the data from S3, start training the model and save the trained model. Training will take about 20 minutes in c4.2xlarge instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.5 ms, sys: 3.46 ms, total: 15 ms\n",
      "Wall time: 211 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\n",
    "    \"train\": train_s3\n",
    "}\n",
    "\n",
    "estimator.fit(data_channels, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-30 06:18:58 Starting - Starting the training job...\n",
      "2020-09-30 06:18:59 Starting - Launching requested ML instances......\n",
      "2020-09-30 06:20:09 Starting - Preparing the instances for training......\n",
      "2020-09-30 06:21:23 Downloading - Downloading input data\n",
      "2020-09-30 06:21:23 Training - Downloading the training image...\n",
      "2020-09-30 06:21:44 Training - Training image download completed. Training in progress.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:47 INFO 140285796738880] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:47 INFO 140285796738880] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'5E-4', u'prediction_length': u'144', u'epochs': u'400', u'time_freq': u'10min', u'context_length': u'144', u'mini_batch_size': u'64', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:47 INFO 140285796738880] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'5E-4', u'num_layers': u'2', u'epochs': u'400', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'64', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'144', u'time_freq': u'10min', u'context_length': u'144', u'_kvstore': u'auto', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:47 INFO 140285796738880] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:47 INFO 140285796738880] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:47 INFO 140285796738880] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:47 INFO 140285796738880] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:47 INFO 140285796738880] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=1 from dataset.\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:47 INFO 140285796738880] Training set statistics:\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:47 INFO 140285796738880] Integer time series\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:47 INFO 140285796738880] number of time series: 16\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:47 INFO 140285796738880] number of observations: 34556\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:47 INFO 140285796738880] mean target length: 2159\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:47 INFO 140285796738880] min/mean/max target: 0.0/12.1908206968/477.0\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:47 INFO 140285796738880] mean abs(target): 12.1908206968\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:47 INFO 140285796738880] contains missing values: no\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:47 INFO 140285796738880] Small number of time series. Doing 40 passes over dataset with prob 1.0 per epoch.\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:47 INFO 140285796738880] No test channel found not running evaluations\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:47 INFO 140285796738880] nvidia-smi took: 0.025171995163 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:47 INFO 140285796738880] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:47 INFO 140285796738880] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 2263.995885848999, \"sum\": 2263.995885848999, \"min\": 2263.995885848999}}, \"EndTime\": 1601446909.767079, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446907.502237}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:49 INFO 140285796738880] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 3655.3051471710205, \"sum\": 3655.3051471710205, \"min\": 3655.3051471710205}}, \"EndTime\": 1601446911.157672, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446909.767169}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:52 INFO 140285796738880] Epoch[0] Batch[0] avg_epoch_loss=3.874082\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:52 INFO 140285796738880] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=3.87408232689\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:54 INFO 140285796738880] Epoch[0] Batch[5] avg_epoch_loss=3.751550\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:54 INFO 140285796738880] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=3.75154964129\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:54 INFO 140285796738880] Epoch[0] Batch [5]#011Speed: 173.57 samples/sec#011loss=3.751550\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:56 INFO 140285796738880] Epoch[0] Batch[10] avg_epoch_loss=3.608484\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:56 INFO 140285796738880] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=3.43680548668\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:56 INFO 140285796738880] Epoch[0] Batch [10]#011Speed: 164.38 samples/sec#011loss=3.436805\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:56 INFO 140285796738880] processed a total of 682 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 400, \"sum\": 400.0, \"min\": 400}, \"update.time\": {\"count\": 1, \"max\": 4865.1909828186035, \"sum\": 4865.1909828186035, \"min\": 4865.1909828186035}}, \"EndTime\": 1601446916.023121, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446911.157813}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:56 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=140.175026878 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:56 INFO 140285796738880] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:56 INFO 140285796738880] #quality_metric: host=algo-1, epoch=0, train loss <loss>=3.60848411647\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:56 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:56 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_ebbca21c-d16d-46a6-89ae-9c5ea79761db-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 179.26692962646484, \"sum\": 179.26692962646484, \"min\": 179.26692962646484}}, \"EndTime\": 1601446916.203072, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446916.023229}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:57 INFO 140285796738880] Epoch[1] Batch[0] avg_epoch_loss=3.345405\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:57 INFO 140285796738880] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=3.34540534019\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:58 INFO 140285796738880] Epoch[1] Batch[5] avg_epoch_loss=3.296064\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:58 INFO 140285796738880] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=3.29606425762\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:21:58 INFO 140285796738880] Epoch[1] Batch [5]#011Speed: 180.96 samples/sec#011loss=3.296064\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:00 INFO 140285796738880] Epoch[1] Batch[10] avg_epoch_loss=3.264825\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:00 INFO 140285796738880] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=3.22733693123\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:00 INFO 140285796738880] Epoch[1] Batch [10]#011Speed: 176.79 samples/sec#011loss=3.227337\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:00 INFO 140285796738880] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4433.290958404541, \"sum\": 4433.290958404541, \"min\": 4433.290958404541}}, \"EndTime\": 1601446920.636537, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446916.203166}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:00 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=147.290252649 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:00 INFO 140285796738880] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:00 INFO 140285796738880] #quality_metric: host=algo-1, epoch=1, train loss <loss>=3.26482456381\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:00 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:00 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_e5be02ff-5b33-4eb8-804a-e251a407ae1f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 119.94290351867676, \"sum\": 119.94290351867676, \"min\": 119.94290351867676}}, \"EndTime\": 1601446920.757097, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446920.636626}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:01 INFO 140285796738880] Epoch[2] Batch[0] avg_epoch_loss=3.047279\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:01 INFO 140285796738880] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=3.04727888107\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:03 INFO 140285796738880] Epoch[2] Batch[5] avg_epoch_loss=3.122602\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:03 INFO 140285796738880] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=3.12260150909\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:03 INFO 140285796738880] Epoch[2] Batch [5]#011Speed: 180.82 samples/sec#011loss=3.122602\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:05 INFO 140285796738880] Epoch[2] Batch[10] avg_epoch_loss=3.093725\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:05 INFO 140285796738880] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=3.05907411575\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:05 INFO 140285796738880] Epoch[2] Batch [10]#011Speed: 179.42 samples/sec#011loss=3.059074\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:05 INFO 140285796738880] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4422.093152999878, \"sum\": 4422.093152999878, \"min\": 4422.093152999878}}, \"EndTime\": 1601446925.17936, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446920.757184}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:05 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=147.210589834 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:05 INFO 140285796738880] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:05 INFO 140285796738880] #quality_metric: host=algo-1, epoch=2, train loss <loss>=3.09372542121\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:05 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:05 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_5bfc0ce4-7afb-4454-9403-45124a6acf3a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 113.83509635925293, \"sum\": 113.83509635925293, \"min\": 113.83509635925293}}, \"EndTime\": 1601446925.293826, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446925.179458}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:06 INFO 140285796738880] Epoch[3] Batch[0] avg_epoch_loss=2.908490\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:06 INFO 140285796738880] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=2.90848970413\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:07 INFO 140285796738880] Epoch[3] Batch[5] avg_epoch_loss=2.878213\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:07 INFO 140285796738880] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=2.87821273009\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:07 INFO 140285796738880] Epoch[3] Batch [5]#011Speed: 183.02 samples/sec#011loss=2.878213\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:09 INFO 140285796738880] Epoch[3] Batch[10] avg_epoch_loss=2.813458\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:09 INFO 140285796738880] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=2.73575334549\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:09 INFO 140285796738880] Epoch[3] Batch [10]#011Speed: 182.34 samples/sec#011loss=2.735753\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:09 INFO 140285796738880] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4322.760105133057, \"sum\": 4322.760105133057, \"min\": 4322.760105133057}}, \"EndTime\": 1601446929.616754, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446925.293908}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:09 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=149.205532459 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:09 INFO 140285796738880] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:09 INFO 140285796738880] #quality_metric: host=algo-1, epoch=3, train loss <loss>=2.81345846436\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:09 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:09 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_08277180-4f5a-4893-8637-408f433e495f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 117.2950267791748, \"sum\": 117.2950267791748, \"min\": 117.2950267791748}}, \"EndTime\": 1601446929.734671, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446929.616843}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:10 INFO 140285796738880] Epoch[4] Batch[0] avg_epoch_loss=2.756173\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:10 INFO 140285796738880] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=2.75617265701\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:12 INFO 140285796738880] Epoch[4] Batch[5] avg_epoch_loss=2.751660\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:12 INFO 140285796738880] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=2.75165963173\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:12 INFO 140285796738880] Epoch[4] Batch [5]#011Speed: 179.97 samples/sec#011loss=2.751660\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:14 INFO 140285796738880] Epoch[4] Batch[10] avg_epoch_loss=2.735503\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:14 INFO 140285796738880] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=2.71611447334\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:14 INFO 140285796738880] Epoch[4] Batch [10]#011Speed: 182.83 samples/sec#011loss=2.716114\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:14 INFO 140285796738880] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4352.050065994263, \"sum\": 4352.050065994263, \"min\": 4352.050065994263}}, \"EndTime\": 1601446934.086877, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446929.734747}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:14 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=151.647923415 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:14 INFO 140285796738880] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:14 INFO 140285796738880] #quality_metric: host=algo-1, epoch=4, train loss <loss>=2.73550274155\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:14 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:14 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_b9c14555-1b1d-489c-a0ad-3f456ae20a8c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 118.14379692077637, \"sum\": 118.14379692077637, \"min\": 118.14379692077637}}, \"EndTime\": 1601446934.205693, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446934.086968}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:15 INFO 140285796738880] Epoch[5] Batch[0] avg_epoch_loss=2.787192\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:15 INFO 140285796738880] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=2.78719210625\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:16 INFO 140285796738880] Epoch[5] Batch[5] avg_epoch_loss=2.739620\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:16 INFO 140285796738880] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=2.73961961269\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:16 INFO 140285796738880] Epoch[5] Batch [5]#011Speed: 179.25 samples/sec#011loss=2.739620\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:18 INFO 140285796738880] Epoch[5] Batch[10] avg_epoch_loss=2.652645\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:18 INFO 140285796738880] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=2.54827528\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:18 INFO 140285796738880] Epoch[5] Batch [10]#011Speed: 182.31 samples/sec#011loss=2.548275\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:18 INFO 140285796738880] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4393.357038497925, \"sum\": 4393.357038497925, \"min\": 4393.357038497925}}, \"EndTime\": 1601446938.599198, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446934.20577}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:18 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=154.319237111 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:18 INFO 140285796738880] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:18 INFO 140285796738880] #quality_metric: host=algo-1, epoch=5, train loss <loss>=2.65264491601\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:18 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:18 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_9b4bda9c-3684-42c2-8aeb-150801e651d6-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 141.71195030212402, \"sum\": 141.71195030212402, \"min\": 141.71195030212402}}, \"EndTime\": 1601446938.741514, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446938.599289}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:19 INFO 140285796738880] Epoch[6] Batch[0] avg_epoch_loss=2.760855\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:19 INFO 140285796738880] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=2.76085543633\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:21 INFO 140285796738880] Epoch[6] Batch[5] avg_epoch_loss=2.585715\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:21 INFO 140285796738880] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=2.58571501573\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:21 INFO 140285796738880] Epoch[6] Batch [5]#011Speed: 176.34 samples/sec#011loss=2.585715\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:23 INFO 140285796738880] Epoch[6] Batch[10] avg_epoch_loss=2.644343\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:23 INFO 140285796738880] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=2.71469759941\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:23 INFO 140285796738880] Epoch[6] Batch [10]#011Speed: 178.61 samples/sec#011loss=2.714698\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:23 INFO 140285796738880] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4419.256925582886, \"sum\": 4419.256925582886, \"min\": 4419.256925582886}}, \"EndTime\": 1601446943.16092, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446938.741594}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:23 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=150.473354027 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:23 INFO 140285796738880] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:23 INFO 140285796738880] #quality_metric: host=algo-1, epoch=6, train loss <loss>=2.64434346286\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:23 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:23 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_e2c2d7a7-a3d9-438e-807e-5ca7f401f6c7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 112.46800422668457, \"sum\": 112.46800422668457, \"min\": 112.46800422668457}}, \"EndTime\": 1601446943.274063, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446943.16101}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:24 INFO 140285796738880] Epoch[7] Batch[0] avg_epoch_loss=2.367643\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:24 INFO 140285796738880] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=2.36764287949\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:25 INFO 140285796738880] Epoch[7] Batch[5] avg_epoch_loss=2.444241\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:25 INFO 140285796738880] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=2.44424128532\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:25 INFO 140285796738880] Epoch[7] Batch [5]#011Speed: 176.37 samples/sec#011loss=2.444241\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:27 INFO 140285796738880] Epoch[7] Batch[10] avg_epoch_loss=2.430558\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:27 INFO 140285796738880] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=2.41413826942\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:27 INFO 140285796738880] Epoch[7] Batch [10]#011Speed: 178.90 samples/sec#011loss=2.414138\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:27 INFO 140285796738880] processed a total of 684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4434.276819229126, \"sum\": 4434.276819229126, \"min\": 4434.276819229126}}, \"EndTime\": 1601446947.708503, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446943.274145}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:27 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=154.248151165 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:27 INFO 140285796738880] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:27 INFO 140285796738880] #quality_metric: host=algo-1, epoch=7, train loss <loss>=2.43055809628\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:27 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:27 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_0468e823-dcc3-447d-8597-1d7c6277eb59-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 170.212984085083, \"sum\": 170.212984085083, \"min\": 170.212984085083}}, \"EndTime\": 1601446947.879335, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446947.708595}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:28 INFO 140285796738880] Epoch[8] Batch[0] avg_epoch_loss=2.291189\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:28 INFO 140285796738880] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=2.29118943214\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:30 INFO 140285796738880] Epoch[8] Batch[5] avg_epoch_loss=2.390388\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:30 INFO 140285796738880] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=2.3903879722\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:30 INFO 140285796738880] Epoch[8] Batch [5]#011Speed: 179.00 samples/sec#011loss=2.390388\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:32 INFO 140285796738880] Epoch[8] Batch[10] avg_epoch_loss=2.378908\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:32 INFO 140285796738880] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=2.36513109207\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:32 INFO 140285796738880] Epoch[8] Batch [10]#011Speed: 179.84 samples/sec#011loss=2.365131\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:32 INFO 140285796738880] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4392.441034317017, \"sum\": 4392.441034317017, \"min\": 4392.441034317017}}, \"EndTime\": 1601446952.271947, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446947.879425}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:32 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=153.896028935 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:32 INFO 140285796738880] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:32 INFO 140285796738880] #quality_metric: host=algo-1, epoch=8, train loss <loss>=2.37890757214\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:32 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:32 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_d2c7cf8d-81fb-4903-a2b5-6b3e80a9f493-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 141.2029266357422, \"sum\": 141.2029266357422, \"min\": 141.2029266357422}}, \"EndTime\": 1601446952.413778, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446952.272038}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:33 INFO 140285796738880] Epoch[9] Batch[0] avg_epoch_loss=2.294278\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:33 INFO 140285796738880] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=2.294277668\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:35 INFO 140285796738880] Epoch[9] Batch[5] avg_epoch_loss=2.225768\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:35 INFO 140285796738880] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=2.22576836745\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:35 INFO 140285796738880] Epoch[9] Batch [5]#011Speed: 177.69 samples/sec#011loss=2.225768\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:36 INFO 140285796738880] Epoch[9] Batch[10] avg_epoch_loss=2.193199\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:36 INFO 140285796738880] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=2.15411474705\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:36 INFO 140285796738880] Epoch[9] Batch [10]#011Speed: 178.53 samples/sec#011loss=2.154115\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:36 INFO 140285796738880] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4401.246070861816, \"sum\": 4401.246070861816, \"min\": 4401.246070861816}}, \"EndTime\": 1601446956.815185, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446952.413857}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:36 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=147.907985739 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:36 INFO 140285796738880] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:36 INFO 140285796738880] #quality_metric: host=algo-1, epoch=9, train loss <loss>=2.19319853999\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:36 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:36 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_a4608d2e-7666-4bc2-914c-4318f5fe1482-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 128.5569667816162, \"sum\": 128.5569667816162, \"min\": 128.5569667816162}}, \"EndTime\": 1601446956.94434, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446956.815278}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:37 INFO 140285796738880] Epoch[10] Batch[0] avg_epoch_loss=2.372867\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:37 INFO 140285796738880] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=2.37286734581\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:39 INFO 140285796738880] Epoch[10] Batch[5] avg_epoch_loss=2.288379\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:39 INFO 140285796738880] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=2.28837947051\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:39 INFO 140285796738880] Epoch[10] Batch [5]#011Speed: 180.49 samples/sec#011loss=2.288379\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:40 INFO 140285796738880] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4022.426128387451, \"sum\": 4022.426128387451, \"min\": 4022.426128387451}}, \"EndTime\": 1601446960.966932, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446956.944413}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:40 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=156.118056467 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:40 INFO 140285796738880] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:40 INFO 140285796738880] #quality_metric: host=algo-1, epoch=10, train loss <loss>=2.2577589035\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:40 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:41 INFO 140285796738880] Epoch[11] Batch[0] avg_epoch_loss=2.103789\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:41 INFO 140285796738880] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=2.10378861427\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:43 INFO 140285796738880] Epoch[11] Batch[5] avg_epoch_loss=2.189526\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:43 INFO 140285796738880] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=2.1895258824\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:43 INFO 140285796738880] Epoch[11] Batch [5]#011Speed: 179.44 samples/sec#011loss=2.189526\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:45 INFO 140285796738880] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4034.9130630493164, \"sum\": 4034.9130630493164, \"min\": 4034.9130630493164}}, \"EndTime\": 1601446965.002478, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446960.967051}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:45 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=152.910281834 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:45 INFO 140285796738880] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:45 INFO 140285796738880] #quality_metric: host=algo-1, epoch=11, train loss <loss>=2.17554998398\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:45 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:45 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_ccaf664a-7b0c-470a-9a78-4fcb5e39106f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 143.7680721282959, \"sum\": 143.7680721282959, \"min\": 143.7680721282959}}, \"EndTime\": 1601446965.146924, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446965.002567}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:45 INFO 140285796738880] Epoch[12] Batch[0] avg_epoch_loss=2.233068\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:45 INFO 140285796738880] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=2.23306822777\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:47 INFO 140285796738880] Epoch[12] Batch[5] avg_epoch_loss=2.151562\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:47 INFO 140285796738880] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=2.15156165759\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:47 INFO 140285796738880] Epoch[12] Batch [5]#011Speed: 180.99 samples/sec#011loss=2.151562\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:49 INFO 140285796738880] Epoch[12] Batch[10] avg_epoch_loss=2.084535\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:49 INFO 140285796738880] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=2.00410225391\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:49 INFO 140285796738880] Epoch[12] Batch [10]#011Speed: 178.48 samples/sec#011loss=2.004102\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:49 INFO 140285796738880] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4375.655889511108, \"sum\": 4375.655889511108, \"min\": 4375.655889511108}}, \"EndTime\": 1601446969.522767, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446965.14703}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:49 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=151.972587081 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:49 INFO 140285796738880] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:49 INFO 140285796738880] #quality_metric: host=algo-1, epoch=12, train loss <loss>=2.08453465592\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:49 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:49 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_8108e2cc-0090-48a2-ae41-966fbd88e6a7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 115.71812629699707, \"sum\": 115.71812629699707, \"min\": 115.71812629699707}}, \"EndTime\": 1601446969.639148, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446969.522857}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:50 INFO 140285796738880] Epoch[13] Batch[0] avg_epoch_loss=1.976660\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:50 INFO 140285796738880] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=1.97666025162\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:52 INFO 140285796738880] Epoch[13] Batch[5] avg_epoch_loss=2.069884\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:52 INFO 140285796738880] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=2.06988362471\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:52 INFO 140285796738880] Epoch[13] Batch [5]#011Speed: 179.95 samples/sec#011loss=2.069884\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:53 INFO 140285796738880] Epoch[13] Batch[10] avg_epoch_loss=2.008578\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:53 INFO 140285796738880] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=1.93501074314\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:53 INFO 140285796738880] Epoch[13] Batch [10]#011Speed: 182.85 samples/sec#011loss=1.935011\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:53 INFO 140285796738880] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4360.188007354736, \"sum\": 4360.188007354736, \"min\": 4360.188007354736}}, \"EndTime\": 1601446973.999489, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446969.63923}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:53 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=155.951930227 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:53 INFO 140285796738880] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:53 INFO 140285796738880] #quality_metric: host=algo-1, epoch=13, train loss <loss>=2.00857776945\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:53 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:54 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_7e71c736-476a-4ef9-a048-578cb674036d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 164.4001007080078, \"sum\": 164.4001007080078, \"min\": 164.4001007080078}}, \"EndTime\": 1601446974.164465, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446973.999578}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:54 INFO 140285796738880] Epoch[14] Batch[0] avg_epoch_loss=1.994277\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:54 INFO 140285796738880] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=1.99427700043\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:56 INFO 140285796738880] Epoch[14] Batch[5] avg_epoch_loss=1.991869\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:56 INFO 140285796738880] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=1.99186899265\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:56 INFO 140285796738880] Epoch[14] Batch [5]#011Speed: 177.06 samples/sec#011loss=1.991869\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:58 INFO 140285796738880] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4033.9090824127197, \"sum\": 4033.9090824127197, \"min\": 4033.9090824127197}}, \"EndTime\": 1601446978.198554, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446974.164557}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:58 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=158.153436554 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:58 INFO 140285796738880] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:58 INFO 140285796738880] #quality_metric: host=algo-1, epoch=14, train loss <loss>=1.99186501503\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:58 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:58 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_802b342b-c64d-45a3-b268-a8b1dc26a5d0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 106.38689994812012, \"sum\": 106.38689994812012, \"min\": 106.38689994812012}}, \"EndTime\": 1601446978.305665, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446978.198654}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:59 INFO 140285796738880] Epoch[15] Batch[0] avg_epoch_loss=2.001177\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:22:59 INFO 140285796738880] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=2.00117731094\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:00 INFO 140285796738880] Epoch[15] Batch[5] avg_epoch_loss=1.998723\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:00 INFO 140285796738880] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=1.99872346719\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:00 INFO 140285796738880] Epoch[15] Batch [5]#011Speed: 174.62 samples/sec#011loss=1.998723\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:02 INFO 140285796738880] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4093.1379795074463, \"sum\": 4093.1379795074463, \"min\": 4093.1379795074463}}, \"EndTime\": 1601446982.398967, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446978.305745}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:02 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=152.932908844 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:02 INFO 140285796738880] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:02 INFO 140285796738880] #quality_metric: host=algo-1, epoch=15, train loss <loss>=1.99665442705\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:02 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:03 INFO 140285796738880] Epoch[16] Batch[0] avg_epoch_loss=2.311652\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:03 INFO 140285796738880] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=2.3116517067\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:04 INFO 140285796738880] Epoch[16] Batch[5] avg_epoch_loss=2.046573\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:04 INFO 140285796738880] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=2.04657342037\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:04 INFO 140285796738880] Epoch[16] Batch [5]#011Speed: 182.80 samples/sec#011loss=2.046573\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:06 INFO 140285796738880] Epoch[16] Batch[10] avg_epoch_loss=1.991209\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:06 INFO 140285796738880] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=1.92477133274\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:06 INFO 140285796738880] Epoch[16] Batch [10]#011Speed: 179.07 samples/sec#011loss=1.924771\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:06 INFO 140285796738880] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4381.831884384155, \"sum\": 4381.831884384155, \"min\": 4381.831884384155}}, \"EndTime\": 1601446986.78141, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446982.399082}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:06 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=154.268617165 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:06 INFO 140285796738880] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:06 INFO 140285796738880] #quality_metric: host=algo-1, epoch=16, train loss <loss>=1.99120883508\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:06 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:06 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_6cb97b20-3c2a-4e49-94c2-3858f503d55d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 117.156982421875, \"sum\": 117.156982421875, \"min\": 117.156982421875}}, \"EndTime\": 1601446986.899204, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446986.781501}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:07 INFO 140285796738880] Epoch[17] Batch[0] avg_epoch_loss=1.977224\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:07 INFO 140285796738880] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=1.97722434998\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:09 INFO 140285796738880] Epoch[17] Batch[5] avg_epoch_loss=1.940258\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:09 INFO 140285796738880] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=1.94025822481\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:09 INFO 140285796738880] Epoch[17] Batch [5]#011Speed: 182.35 samples/sec#011loss=1.940258\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:11 INFO 140285796738880] Epoch[17] Batch[10] avg_epoch_loss=1.905280\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:11 INFO 140285796738880] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=1.86330714226\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:11 INFO 140285796738880] Epoch[17] Batch [10]#011Speed: 178.90 samples/sec#011loss=1.863307\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:11 INFO 140285796738880] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4370.810985565186, \"sum\": 4370.810985565186, \"min\": 4370.810985565186}}, \"EndTime\": 1601446991.270183, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446986.899287}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:11 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=154.886339508 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:11 INFO 140285796738880] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:11 INFO 140285796738880] #quality_metric: host=algo-1, epoch=17, train loss <loss>=1.90528046001\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:11 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:11 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_61e01938-a9f2-4c3d-ae81-5de6b0fe3c41-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 128.33619117736816, \"sum\": 128.33619117736816, \"min\": 128.33619117736816}}, \"EndTime\": 1601446991.399142, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446991.270275}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:12 INFO 140285796738880] Epoch[18] Batch[0] avg_epoch_loss=1.830540\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:12 INFO 140285796738880] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=1.83054029942\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:14 INFO 140285796738880] Epoch[18] Batch[5] avg_epoch_loss=1.858846\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:14 INFO 140285796738880] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=1.85884575049\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:14 INFO 140285796738880] Epoch[18] Batch [5]#011Speed: 179.31 samples/sec#011loss=1.858846\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:15 INFO 140285796738880] Epoch[18] Batch[10] avg_epoch_loss=1.857300\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:15 INFO 140285796738880] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=1.85544409752\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:15 INFO 140285796738880] Epoch[18] Batch [10]#011Speed: 178.43 samples/sec#011loss=1.855444\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:15 INFO 140285796738880] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4400.498151779175, \"sum\": 4400.498151779175, \"min\": 4400.498151779175}}, \"EndTime\": 1601446995.79982, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446991.399235}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:15 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=151.114628604 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:15 INFO 140285796738880] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:15 INFO 140285796738880] #quality_metric: host=algo-1, epoch=18, train loss <loss>=1.85729954459\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:15 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:15 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_278c3487-3944-46e9-9ba1-ca6260482987-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 108.45780372619629, \"sum\": 108.45780372619629, \"min\": 108.45780372619629}}, \"EndTime\": 1601446995.908939, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446995.799906}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:16 INFO 140285796738880] Epoch[19] Batch[0] avg_epoch_loss=1.940945\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:16 INFO 140285796738880] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=1.94094526768\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:18 INFO 140285796738880] Epoch[19] Batch[5] avg_epoch_loss=1.890058\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:18 INFO 140285796738880] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=1.89005796115\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:18 INFO 140285796738880] Epoch[19] Batch [5]#011Speed: 181.81 samples/sec#011loss=1.890058\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:19 INFO 140285796738880] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3967.534065246582, \"sum\": 3967.534065246582, \"min\": 3967.534065246582}}, \"EndTime\": 1601446999.876623, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446995.909018}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:19 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=158.279094091 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:19 INFO 140285796738880] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:19 INFO 140285796738880] #quality_metric: host=algo-1, epoch=19, train loss <loss>=1.87580039501\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:19 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:20 INFO 140285796738880] Epoch[20] Batch[0] avg_epoch_loss=1.816958\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:20 INFO 140285796738880] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=1.81695783138\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:22 INFO 140285796738880] Epoch[20] Batch[5] avg_epoch_loss=1.818277\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:22 INFO 140285796738880] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=1.81827688217\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:22 INFO 140285796738880] Epoch[20] Batch [5]#011Speed: 179.81 samples/sec#011loss=1.818277\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:24 INFO 140285796738880] Epoch[20] Batch[10] avg_epoch_loss=1.834060\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:24 INFO 140285796738880] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=1.85300028324\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:24 INFO 140285796738880] Epoch[20] Batch [10]#011Speed: 182.39 samples/sec#011loss=1.853000\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:24 INFO 140285796738880] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4367.706060409546, \"sum\": 4367.706060409546, \"min\": 4367.706060409546}}, \"EndTime\": 1601447004.244944, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601446999.876721}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:24 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=153.622489321 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:24 INFO 140285796738880] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:24 INFO 140285796738880] #quality_metric: host=algo-1, epoch=20, train loss <loss>=1.83406024629\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:24 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:24 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_353cc30c-fe6b-49f7-b685-4e483737a1fd-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 128.1881332397461, \"sum\": 128.1881332397461, \"min\": 128.1881332397461}}, \"EndTime\": 1601447004.373752, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447004.245043}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:25 INFO 140285796738880] Epoch[21] Batch[0] avg_epoch_loss=1.963838\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:25 INFO 140285796738880] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=1.96383833885\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:26 INFO 140285796738880] Epoch[21] Batch[5] avg_epoch_loss=1.882524\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:26 INFO 140285796738880] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=1.88252379497\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:26 INFO 140285796738880] Epoch[21] Batch [5]#011Speed: 177.04 samples/sec#011loss=1.882524\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:28 INFO 140285796738880] Epoch[21] Batch[10] avg_epoch_loss=1.835372\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:28 INFO 140285796738880] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=1.77878932953\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:28 INFO 140285796738880] Epoch[21] Batch [10]#011Speed: 179.23 samples/sec#011loss=1.778789\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:28 INFO 140285796738880] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4409.754991531372, \"sum\": 4409.754991531372, \"min\": 4409.754991531372}}, \"EndTime\": 1601447008.783686, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447004.373843}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:28 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=156.467023018 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:28 INFO 140285796738880] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:28 INFO 140285796738880] #quality_metric: host=algo-1, epoch=21, train loss <loss>=1.83537176522\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:28 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:29 INFO 140285796738880] Epoch[22] Batch[0] avg_epoch_loss=1.792076\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:29 INFO 140285796738880] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=1.792075634\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:31 INFO 140285796738880] Epoch[22] Batch[5] avg_epoch_loss=1.758715\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:31 INFO 140285796738880] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=1.75871527195\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:31 INFO 140285796738880] Epoch[22] Batch [5]#011Speed: 179.10 samples/sec#011loss=1.758715\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:33 INFO 140285796738880] Epoch[22] Batch[10] avg_epoch_loss=1.751829\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:33 INFO 140285796738880] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=1.7435649395\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:33 INFO 140285796738880] Epoch[22] Batch [10]#011Speed: 180.14 samples/sec#011loss=1.743565\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:33 INFO 140285796738880] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4381.549835205078, \"sum\": 4381.549835205078, \"min\": 4381.549835205078}}, \"EndTime\": 1601447013.165742, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447008.783757}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:33 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=155.419694784 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:33 INFO 140285796738880] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:33 INFO 140285796738880] #quality_metric: host=algo-1, epoch=22, train loss <loss>=1.7518287572\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:33 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:33 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_53b355d9-f3a2-47ad-83a9-9236d17de691-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 115.23103713989258, \"sum\": 115.23103713989258, \"min\": 115.23103713989258}}, \"EndTime\": 1601447013.281576, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447013.165832}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:34 INFO 140285796738880] Epoch[23] Batch[0] avg_epoch_loss=1.765139\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:34 INFO 140285796738880] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=1.76513886452\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:35 INFO 140285796738880] Epoch[23] Batch[5] avg_epoch_loss=1.807052\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:35 INFO 140285796738880] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=1.80705205599\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:35 INFO 140285796738880] Epoch[23] Batch [5]#011Speed: 179.47 samples/sec#011loss=1.807052\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:37 INFO 140285796738880] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4008.6541175842285, \"sum\": 4008.6541175842285, \"min\": 4008.6541175842285}}, \"EndTime\": 1601447017.290406, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447013.281668}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:37 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=155.408064051 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:37 INFO 140285796738880] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:37 INFO 140285796738880] #quality_metric: host=algo-1, epoch=23, train loss <loss>=1.78019018173\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:37 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:38 INFO 140285796738880] Epoch[24] Batch[0] avg_epoch_loss=1.606681\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:38 INFO 140285796738880] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=1.60668063164\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:39 INFO 140285796738880] Epoch[24] Batch[5] avg_epoch_loss=1.722894\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:39 INFO 140285796738880] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=1.72289355596\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:39 INFO 140285796738880] Epoch[24] Batch [5]#011Speed: 182.10 samples/sec#011loss=1.722894\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:41 INFO 140285796738880] Epoch[24] Batch[10] avg_epoch_loss=1.744560\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:41 INFO 140285796738880] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=1.77055871487\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:41 INFO 140285796738880] Epoch[24] Batch [10]#011Speed: 180.02 samples/sec#011loss=1.770559\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:41 INFO 140285796738880] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4351.304054260254, \"sum\": 4351.304054260254, \"min\": 4351.304054260254}}, \"EndTime\": 1601447021.642356, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447017.290505}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:41 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=151.214171456 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:41 INFO 140285796738880] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:41 INFO 140285796738880] #quality_metric: host=algo-1, epoch=24, train loss <loss>=1.74455953728\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:41 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:41 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_5b28aec6-7fa0-4468-ba71-6df8fae67a06-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 127.25591659545898, \"sum\": 127.25591659545898, \"min\": 127.25591659545898}}, \"EndTime\": 1601447021.770259, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447021.642447}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:42 INFO 140285796738880] Epoch[25] Batch[0] avg_epoch_loss=1.748681\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:42 INFO 140285796738880] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=1.74868071079\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:44 INFO 140285796738880] Epoch[25] Batch[5] avg_epoch_loss=1.808059\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:44 INFO 140285796738880] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=1.80805863937\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:44 INFO 140285796738880] Epoch[25] Batch [5]#011Speed: 182.12 samples/sec#011loss=1.808059\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:46 INFO 140285796738880] Epoch[25] Batch[10] avg_epoch_loss=1.886216\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:46 INFO 140285796738880] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=1.98000416756\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:46 INFO 140285796738880] Epoch[25] Batch [10]#011Speed: 178.58 samples/sec#011loss=1.980004\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:46 INFO 140285796738880] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4369.100093841553, \"sum\": 4369.100093841553, \"min\": 4369.100093841553}}, \"EndTime\": 1601447026.139531, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447021.770345}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:46 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=152.65830153 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:46 INFO 140285796738880] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:46 INFO 140285796738880] #quality_metric: host=algo-1, epoch=25, train loss <loss>=1.88621569764\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:46 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:46 INFO 140285796738880] Epoch[26] Batch[0] avg_epoch_loss=1.624992\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:46 INFO 140285796738880] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=1.62499189377\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:48 INFO 140285796738880] Epoch[26] Batch[5] avg_epoch_loss=1.694266\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:48 INFO 140285796738880] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=1.69426570336\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:48 INFO 140285796738880] Epoch[26] Batch [5]#011Speed: 182.32 samples/sec#011loss=1.694266\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:50 INFO 140285796738880] Epoch[26] Batch[10] avg_epoch_loss=1.650555\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:50 INFO 140285796738880] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=1.59810304642\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:50 INFO 140285796738880] Epoch[26] Batch [10]#011Speed: 181.32 samples/sec#011loss=1.598103\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:50 INFO 140285796738880] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4352.8711795806885, \"sum\": 4352.8711795806885, \"min\": 4352.8711795806885}}, \"EndTime\": 1601447030.493054, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447026.139622}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:50 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=147.713405469 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:50 INFO 140285796738880] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:50 INFO 140285796738880] #quality_metric: host=algo-1, epoch=26, train loss <loss>=1.65055540475\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:50 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:50 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_705ef0ba-7201-4fd2-9693-ba06c6dba77e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 120.84794044494629, \"sum\": 120.84794044494629, \"min\": 120.84794044494629}}, \"EndTime\": 1601447030.614518, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447030.493145}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:51 INFO 140285796738880] Epoch[27] Batch[0] avg_epoch_loss=1.699254\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:51 INFO 140285796738880] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=1.69925439358\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:53 INFO 140285796738880] Epoch[27] Batch[5] avg_epoch_loss=1.670758\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:53 INFO 140285796738880] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=1.67075751225\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:53 INFO 140285796738880] Epoch[27] Batch [5]#011Speed: 181.28 samples/sec#011loss=1.670758\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:54 INFO 140285796738880] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4023.6330032348633, \"sum\": 4023.6330032348633, \"min\": 4023.6330032348633}}, \"EndTime\": 1601447034.638289, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447030.614584}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:54 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=153.587112732 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:54 INFO 140285796738880] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:54 INFO 140285796738880] #quality_metric: host=algo-1, epoch=27, train loss <loss>=1.67867645025\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:54 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:55 INFO 140285796738880] Epoch[28] Batch[0] avg_epoch_loss=1.655084\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:55 INFO 140285796738880] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=1.65508365631\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:57 INFO 140285796738880] Epoch[28] Batch[5] avg_epoch_loss=1.666142\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:57 INFO 140285796738880] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=1.66614156961\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:57 INFO 140285796738880] Epoch[28] Batch [5]#011Speed: 174.18 samples/sec#011loss=1.666142\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:59 INFO 140285796738880] Epoch[28] Batch[10] avg_epoch_loss=1.628894\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:59 INFO 140285796738880] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=1.58419620991\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:59 INFO 140285796738880] Epoch[28] Batch [10]#011Speed: 180.07 samples/sec#011loss=1.584196\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:59 INFO 140285796738880] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4429.922103881836, \"sum\": 4429.922103881836, \"min\": 4429.922103881836}}, \"EndTime\": 1601447039.068819, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447034.638387}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:59 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=147.627800371 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:59 INFO 140285796738880] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:59 INFO 140285796738880] #quality_metric: host=algo-1, epoch=28, train loss <loss>=1.62889367884\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:59 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:59 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_3e06f2bd-16af-4278-a942-6aa8023d640e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 116.96696281433105, \"sum\": 116.96696281433105, \"min\": 116.96696281433105}}, \"EndTime\": 1601447039.186411, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447039.068914}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:59 INFO 140285796738880] Epoch[29] Batch[0] avg_epoch_loss=1.605986\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:23:59 INFO 140285796738880] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=1.6059858799\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:01 INFO 140285796738880] Epoch[29] Batch[5] avg_epoch_loss=1.668970\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:01 INFO 140285796738880] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=1.66897048553\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:01 INFO 140285796738880] Epoch[29] Batch [5]#011Speed: 176.06 samples/sec#011loss=1.668970\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:03 INFO 140285796738880] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4047.853946685791, \"sum\": 4047.853946685791, \"min\": 4047.853946685791}}, \"EndTime\": 1601447043.234423, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447039.186486}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:03 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=154.892066942 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:03 INFO 140285796738880] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:03 INFO 140285796738880] #quality_metric: host=algo-1, epoch=29, train loss <loss>=1.64276373386\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:03 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:04 INFO 140285796738880] Epoch[30] Batch[0] avg_epoch_loss=1.639903\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:04 INFO 140285796738880] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=1.63990271091\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:05 INFO 140285796738880] Epoch[30] Batch[5] avg_epoch_loss=1.540637\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:05 INFO 140285796738880] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=1.54063733419\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:05 INFO 140285796738880] Epoch[30] Batch [5]#011Speed: 179.95 samples/sec#011loss=1.540637\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:07 INFO 140285796738880] Epoch[30] Batch[10] avg_epoch_loss=1.537033\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:07 INFO 140285796738880] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=1.5327072382\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:07 INFO 140285796738880] Epoch[30] Batch [10]#011Speed: 169.39 samples/sec#011loss=1.532707\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:07 INFO 140285796738880] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4468.2910442352295, \"sum\": 4468.2910442352295, \"min\": 4468.2910442352295}}, \"EndTime\": 1601447047.703427, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447043.234507}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:07 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=146.808011732 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:07 INFO 140285796738880] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:07 INFO 140285796738880] #quality_metric: host=algo-1, epoch=30, train loss <loss>=1.5370327451\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:07 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:07 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_b2e1193a-19e6-49ab-9033-065ea03e3386-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 109.66801643371582, \"sum\": 109.66801643371582, \"min\": 109.66801643371582}}, \"EndTime\": 1601447047.813765, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447047.703517}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:08 INFO 140285796738880] Epoch[31] Batch[0] avg_epoch_loss=1.562496\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:08 INFO 140285796738880] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=1.56249570847\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:10 INFO 140285796738880] Epoch[31] Batch[5] avg_epoch_loss=1.573610\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:10 INFO 140285796738880] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=1.57361026605\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:10 INFO 140285796738880] Epoch[31] Batch [5]#011Speed: 180.62 samples/sec#011loss=1.573610\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:12 INFO 140285796738880] Epoch[31] Batch[10] avg_epoch_loss=1.737765\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:12 INFO 140285796738880] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=1.93475060463\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:12 INFO 140285796738880] Epoch[31] Batch [10]#011Speed: 178.65 samples/sec#011loss=1.934751\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:12 INFO 140285796738880] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4366.83988571167, \"sum\": 4366.83988571167, \"min\": 4366.83988571167}}, \"EndTime\": 1601447052.180828, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447047.813852}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:12 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=146.970247557 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:12 INFO 140285796738880] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:12 INFO 140285796738880] #quality_metric: host=algo-1, epoch=31, train loss <loss>=1.7377649654\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:12 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:13 INFO 140285796738880] Epoch[32] Batch[0] avg_epoch_loss=1.829025\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:13 INFO 140285796738880] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=1.82902503014\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:14 INFO 140285796738880] Epoch[32] Batch[5] avg_epoch_loss=1.690569\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:14 INFO 140285796738880] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=1.69056926171\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:14 INFO 140285796738880] Epoch[32] Batch [5]#011Speed: 179.31 samples/sec#011loss=1.690569\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:16 INFO 140285796738880] Epoch[32] Batch[10] avg_epoch_loss=1.582162\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:16 INFO 140285796738880] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=1.45207264423\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:16 INFO 140285796738880] Epoch[32] Batch [10]#011Speed: 179.17 samples/sec#011loss=1.452073\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:16 INFO 140285796738880] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4390.935897827148, \"sum\": 4390.935897827148, \"min\": 4390.935897827148}}, \"EndTime\": 1601447056.573587, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447052.180978}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:16 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=147.799906285 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:16 INFO 140285796738880] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:16 INFO 140285796738880] #quality_metric: host=algo-1, epoch=32, train loss <loss>=1.58216170831\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:16 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:17 INFO 140285796738880] Epoch[33] Batch[0] avg_epoch_loss=1.685435\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:17 INFO 140285796738880] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=1.68543493748\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:19 INFO 140285796738880] Epoch[33] Batch[5] avg_epoch_loss=1.613264\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:19 INFO 140285796738880] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=1.61326398452\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:19 INFO 140285796738880] Epoch[33] Batch [5]#011Speed: 182.59 samples/sec#011loss=1.613264\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:20 INFO 140285796738880] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3968.1501388549805, \"sum\": 3968.1501388549805, \"min\": 3968.1501388549805}}, \"EndTime\": 1601447060.542298, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447056.573679}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:20 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=151.450284699 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:20 INFO 140285796738880] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:20 INFO 140285796738880] #quality_metric: host=algo-1, epoch=33, train loss <loss>=1.56501348019\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:20 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:21 INFO 140285796738880] Epoch[34] Batch[0] avg_epoch_loss=1.433644\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:21 INFO 140285796738880] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=1.43364429474\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:23 INFO 140285796738880] Epoch[34] Batch[5] avg_epoch_loss=1.531744\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:23 INFO 140285796738880] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=1.53174414237\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:23 INFO 140285796738880] Epoch[34] Batch [5]#011Speed: 181.68 samples/sec#011loss=1.531744\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:24 INFO 140285796738880] Epoch[34] Batch[10] avg_epoch_loss=1.483457\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:24 INFO 140285796738880] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=1.42551176548\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:24 INFO 140285796738880] Epoch[34] Batch [10]#011Speed: 181.19 samples/sec#011loss=1.425512\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:24 INFO 140285796738880] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4352.71692276001, \"sum\": 4352.71692276001, \"min\": 4352.71692276001}}, \"EndTime\": 1601447064.895633, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447060.542402}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:24 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=153.003239713 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:24 INFO 140285796738880] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:24 INFO 140285796738880] #quality_metric: host=algo-1, epoch=34, train loss <loss>=1.48345669833\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:24 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:25 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_8687e7fa-b144-459d-a269-7299ec881d13-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 124.36318397521973, \"sum\": 124.36318397521973, \"min\": 124.36318397521973}}, \"EndTime\": 1601447065.020605, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447064.89572}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:25 INFO 140285796738880] Epoch[35] Batch[0] avg_epoch_loss=1.540352\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:25 INFO 140285796738880] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=1.5403522253\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:27 INFO 140285796738880] Epoch[35] Batch[5] avg_epoch_loss=1.491581\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:27 INFO 140285796738880] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=1.49158130089\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:27 INFO 140285796738880] Epoch[35] Batch [5]#011Speed: 176.47 samples/sec#011loss=1.491581\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:29 INFO 140285796738880] Epoch[35] Batch[10] avg_epoch_loss=1.465686\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:29 INFO 140285796738880] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=1.43461079597\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:29 INFO 140285796738880] Epoch[35] Batch [10]#011Speed: 181.85 samples/sec#011loss=1.434611\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:29 INFO 140285796738880] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4393.9008712768555, \"sum\": 4393.9008712768555, \"min\": 4393.9008712768555}}, \"EndTime\": 1601447069.414657, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447065.020686}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:29 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=148.155297163 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:29 INFO 140285796738880] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:29 INFO 140285796738880] #quality_metric: host=algo-1, epoch=35, train loss <loss>=1.46568561684\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:29 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:29 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_7b9924ab-54d8-4ed8-8ffb-68f01c338ade-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 149.67799186706543, \"sum\": 149.67799186706543, \"min\": 149.67799186706543}}, \"EndTime\": 1601447069.564987, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447069.414749}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:30 INFO 140285796738880] Epoch[36] Batch[0] avg_epoch_loss=1.405066\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:30 INFO 140285796738880] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=1.40506637096\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:32 INFO 140285796738880] Epoch[36] Batch[5] avg_epoch_loss=1.558509\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:32 INFO 140285796738880] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=1.55850855509\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:32 INFO 140285796738880] Epoch[36] Batch [5]#011Speed: 178.15 samples/sec#011loss=1.558509\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:33 INFO 140285796738880] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4030.1480293273926, \"sum\": 4030.1480293273926, \"min\": 4030.1480293273926}}, \"EndTime\": 1601447073.595313, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447069.565082}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:33 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=155.571853029 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:33 INFO 140285796738880] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:33 INFO 140285796738880] #quality_metric: host=algo-1, epoch=36, train loss <loss>=1.5240044117\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:33 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:34 INFO 140285796738880] Epoch[37] Batch[0] avg_epoch_loss=1.561836\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:34 INFO 140285796738880] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=1.56183552742\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:36 INFO 140285796738880] Epoch[37] Batch[5] avg_epoch_loss=1.535727\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:36 INFO 140285796738880] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=1.53572744131\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:36 INFO 140285796738880] Epoch[37] Batch [5]#011Speed: 178.79 samples/sec#011loss=1.535727\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:37 INFO 140285796738880] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4089.7138118743896, \"sum\": 4089.7138118743896, \"min\": 4089.7138118743896}}, \"EndTime\": 1601447077.685644, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447073.595411}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:37 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=155.995333838 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:37 INFO 140285796738880] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:37 INFO 140285796738880] #quality_metric: host=algo-1, epoch=37, train loss <loss>=1.49559472799\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:37 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:38 INFO 140285796738880] Epoch[38] Batch[0] avg_epoch_loss=1.517336\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:38 INFO 140285796738880] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=1.51733624935\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:40 INFO 140285796738880] Epoch[38] Batch[5] avg_epoch_loss=1.521663\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:40 INFO 140285796738880] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=1.52166295052\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:40 INFO 140285796738880] Epoch[38] Batch [5]#011Speed: 181.37 samples/sec#011loss=1.521663\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:42 INFO 140285796738880] Epoch[38] Batch[10] avg_epoch_loss=1.513933\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:42 INFO 140285796738880] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=1.50465800762\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:42 INFO 140285796738880] Epoch[38] Batch [10]#011Speed: 175.92 samples/sec#011loss=1.504658\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:42 INFO 140285796738880] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4402.720928192139, \"sum\": 4402.720928192139, \"min\": 4402.720928192139}}, \"EndTime\": 1601447082.088994, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447077.685749}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:42 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=151.492745072 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:42 INFO 140285796738880] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:42 INFO 140285796738880] #quality_metric: host=algo-1, epoch=38, train loss <loss>=1.51393343102\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:42 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:42 INFO 140285796738880] Epoch[39] Batch[0] avg_epoch_loss=1.537530\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:42 INFO 140285796738880] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=1.53753018379\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:44 INFO 140285796738880] Epoch[39] Batch[5] avg_epoch_loss=1.495836\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:44 INFO 140285796738880] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=1.49583552281\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:44 INFO 140285796738880] Epoch[39] Batch [5]#011Speed: 181.10 samples/sec#011loss=1.495836\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:46 INFO 140285796738880] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4009.740114212036, \"sum\": 4009.740114212036, \"min\": 4009.740114212036}}, \"EndTime\": 1601447086.099321, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447082.089082}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:46 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=157.610586522 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:46 INFO 140285796738880] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:46 INFO 140285796738880] #quality_metric: host=algo-1, epoch=39, train loss <loss>=1.48140362501\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:46 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:46 INFO 140285796738880] Epoch[40] Batch[0] avg_epoch_loss=1.536778\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:46 INFO 140285796738880] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=1.53677761555\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:48 INFO 140285796738880] Epoch[40] Batch[5] avg_epoch_loss=1.536752\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:48 INFO 140285796738880] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=1.53675204515\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:48 INFO 140285796738880] Epoch[40] Batch [5]#011Speed: 182.51 samples/sec#011loss=1.536752\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:50 INFO 140285796738880] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3997.7569580078125, \"sum\": 3997.7569580078125, \"min\": 3997.7569580078125}}, \"EndTime\": 1601447090.097768, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447086.099419}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:50 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=157.332674316 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:50 INFO 140285796738880] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:50 INFO 140285796738880] #quality_metric: host=algo-1, epoch=40, train loss <loss>=1.46687018871\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:50 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:50 INFO 140285796738880] Epoch[41] Batch[0] avg_epoch_loss=1.521308\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:50 INFO 140285796738880] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=1.52130806446\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:52 INFO 140285796738880] Epoch[41] Batch[5] avg_epoch_loss=1.468154\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:52 INFO 140285796738880] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=1.46815387408\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:52 INFO 140285796738880] Epoch[41] Batch [5]#011Speed: 180.88 samples/sec#011loss=1.468154\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:54 INFO 140285796738880] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4062.235116958618, \"sum\": 4062.235116958618, \"min\": 4062.235116958618}}, \"EndTime\": 1601447094.160613, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447090.097865}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:54 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=153.112481745 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:54 INFO 140285796738880] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:54 INFO 140285796738880] #quality_metric: host=algo-1, epoch=41, train loss <loss>=1.39915403128\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:54 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:54 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_dafa9229-9dca-432c-8939-952cc63fb1b9-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 130.8889389038086, \"sum\": 130.8889389038086, \"min\": 130.8889389038086}}, \"EndTime\": 1601447094.292155, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447094.160707}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:55 INFO 140285796738880] Epoch[42] Batch[0] avg_epoch_loss=1.480153\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:55 INFO 140285796738880] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=1.48015296459\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:56 INFO 140285796738880] Epoch[42] Batch[5] avg_epoch_loss=1.468229\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:56 INFO 140285796738880] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=1.46822859844\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:56 INFO 140285796738880] Epoch[42] Batch [5]#011Speed: 180.79 samples/sec#011loss=1.468229\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:58 INFO 140285796738880] Epoch[42] Batch[10] avg_epoch_loss=1.450610\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:58 INFO 140285796738880] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=1.42946875095\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:58 INFO 140285796738880] Epoch[42] Batch [10]#011Speed: 178.32 samples/sec#011loss=1.429469\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:58 INFO 140285796738880] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4398.051977157593, \"sum\": 4398.051977157593, \"min\": 4398.051977157593}}, \"EndTime\": 1601447098.690363, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447094.292238}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:58 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=146.424035788 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:58 INFO 140285796738880] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:58 INFO 140285796738880] #quality_metric: host=algo-1, epoch=42, train loss <loss>=1.45061048594\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:58 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:59 INFO 140285796738880] Epoch[43] Batch[0] avg_epoch_loss=1.235302\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:24:59 INFO 140285796738880] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=1.23530197144\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:01 INFO 140285796738880] Epoch[43] Batch[5] avg_epoch_loss=1.400833\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:01 INFO 140285796738880] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=1.40083346764\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:01 INFO 140285796738880] Epoch[43] Batch [5]#011Speed: 181.02 samples/sec#011loss=1.400833\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:03 INFO 140285796738880] Epoch[43] Batch[10] avg_epoch_loss=1.416021\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:03 INFO 140285796738880] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=1.43424522877\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:03 INFO 140285796738880] Epoch[43] Batch [10]#011Speed: 175.26 samples/sec#011loss=1.434245\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:03 INFO 140285796738880] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4434.869050979614, \"sum\": 4434.869050979614, \"min\": 4434.869050979614}}, \"EndTime\": 1601447103.125805, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447098.690453}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:03 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=152.875477424 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:03 INFO 140285796738880] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:03 INFO 140285796738880] #quality_metric: host=algo-1, epoch=43, train loss <loss>=1.41602063179\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:03 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:03 INFO 140285796738880] Epoch[44] Batch[0] avg_epoch_loss=1.505716\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:03 INFO 140285796738880] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=1.50571632385\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:05 INFO 140285796738880] Epoch[44] Batch[5] avg_epoch_loss=1.496942\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:05 INFO 140285796738880] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=1.49694220225\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:05 INFO 140285796738880] Epoch[44] Batch [5]#011Speed: 179.94 samples/sec#011loss=1.496942\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:07 INFO 140285796738880] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4027.3849964141846, \"sum\": 4027.3849964141846, \"min\": 4027.3849964141846}}, \"EndTime\": 1601447107.153802, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447103.125875}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:07 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=155.430133422 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:07 INFO 140285796738880] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:07 INFO 140285796738880] #quality_metric: host=algo-1, epoch=44, train loss <loss>=1.48028383255\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:07 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:07 INFO 140285796738880] Epoch[45] Batch[0] avg_epoch_loss=1.396230\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:07 INFO 140285796738880] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=1.39623045921\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:09 INFO 140285796738880] Epoch[45] Batch[5] avg_epoch_loss=1.429938\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:09 INFO 140285796738880] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=1.42993829648\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:09 INFO 140285796738880] Epoch[45] Batch [5]#011Speed: 179.55 samples/sec#011loss=1.429938\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:11 INFO 140285796738880] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4020.8728313446045, \"sum\": 4020.8728313446045, \"min\": 4020.8728313446045}}, \"EndTime\": 1601447111.175303, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447107.153901}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:11 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=158.418861709 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:11 INFO 140285796738880] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:11 INFO 140285796738880] #quality_metric: host=algo-1, epoch=45, train loss <loss>=1.43169962168\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:11 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:11 INFO 140285796738880] Epoch[46] Batch[0] avg_epoch_loss=1.410240\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:11 INFO 140285796738880] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=1.41024005413\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:13 INFO 140285796738880] Epoch[46] Batch[5] avg_epoch_loss=1.377957\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:13 INFO 140285796738880] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=1.3779566288\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:13 INFO 140285796738880] Epoch[46] Batch [5]#011Speed: 178.87 samples/sec#011loss=1.377957\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:15 INFO 140285796738880] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4025.0961780548096, \"sum\": 4025.0961780548096, \"min\": 4025.0961780548096}}, \"EndTime\": 1601447115.201017, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447111.175376}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:15 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=151.544398276 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:15 INFO 140285796738880] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:15 INFO 140285796738880] #quality_metric: host=algo-1, epoch=46, train loss <loss>=1.38377718925\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:15 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:15 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_9886d8a8-d8d4-47fc-b499-2cf8b33190d4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 109.08102989196777, \"sum\": 109.08102989196777, \"min\": 109.08102989196777}}, \"EndTime\": 1601447115.310793, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447115.201105}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:16 INFO 140285796738880] Epoch[47] Batch[0] avg_epoch_loss=1.331899\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:16 INFO 140285796738880] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=1.33189916611\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:17 INFO 140285796738880] Epoch[47] Batch[5] avg_epoch_loss=1.351573\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:17 INFO 140285796738880] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=1.35157332818\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:17 INFO 140285796738880] Epoch[47] Batch [5]#011Speed: 176.99 samples/sec#011loss=1.351573\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:19 INFO 140285796738880] Epoch[47] Batch[10] avg_epoch_loss=1.392925\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:19 INFO 140285796738880] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=1.44254760742\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:19 INFO 140285796738880] Epoch[47] Batch [10]#011Speed: 178.27 samples/sec#011loss=1.442548\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:19 INFO 140285796738880] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4405.695199966431, \"sum\": 4405.695199966431, \"min\": 4405.695199966431}}, \"EndTime\": 1601447119.716667, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447115.310887}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:19 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=145.716012395 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:19 INFO 140285796738880] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:19 INFO 140285796738880] #quality_metric: host=algo-1, epoch=47, train loss <loss>=1.39292527329\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:19 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:20 INFO 140285796738880] Epoch[48] Batch[0] avg_epoch_loss=1.580105\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:20 INFO 140285796738880] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=1.58010482788\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:22 INFO 140285796738880] Epoch[48] Batch[5] avg_epoch_loss=1.388201\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:22 INFO 140285796738880] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=1.38820060094\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:22 INFO 140285796738880] Epoch[48] Batch [5]#011Speed: 179.28 samples/sec#011loss=1.388201\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:24 INFO 140285796738880] Epoch[48] Batch[10] avg_epoch_loss=1.392136\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:24 INFO 140285796738880] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=1.39685873985\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:24 INFO 140285796738880] Epoch[48] Batch [10]#011Speed: 181.78 samples/sec#011loss=1.396859\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:24 INFO 140285796738880] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4386.149168014526, \"sum\": 4386.149168014526, \"min\": 4386.149168014526}}, \"EndTime\": 1601447124.103371, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447119.716756}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:24 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=151.381023975 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:24 INFO 140285796738880] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:24 INFO 140285796738880] #quality_metric: host=algo-1, epoch=48, train loss <loss>=1.39213611863\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:24 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:24 INFO 140285796738880] Epoch[49] Batch[0] avg_epoch_loss=1.394215\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:24 INFO 140285796738880] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=1.39421498775\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:26 INFO 140285796738880] Epoch[49] Batch[5] avg_epoch_loss=1.440502\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:26 INFO 140285796738880] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=1.4405023853\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:26 INFO 140285796738880] Epoch[49] Batch [5]#011Speed: 181.06 samples/sec#011loss=1.440502\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:28 INFO 140285796738880] Epoch[49] Batch[10] avg_epoch_loss=1.460753\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:28 INFO 140285796738880] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=1.48505403996\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:28 INFO 140285796738880] Epoch[49] Batch [10]#011Speed: 179.19 samples/sec#011loss=1.485054\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:28 INFO 140285796738880] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4383.527040481567, \"sum\": 4383.527040481567, \"min\": 4383.527040481567}}, \"EndTime\": 1601447128.487446, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447124.103461}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:28 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=151.471565706 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:28 INFO 140285796738880] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:28 INFO 140285796738880] #quality_metric: host=algo-1, epoch=49, train loss <loss>=1.46075313742\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:28 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:29 INFO 140285796738880] Epoch[50] Batch[0] avg_epoch_loss=1.300282\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:29 INFO 140285796738880] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=1.30028176308\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:31 INFO 140285796738880] Epoch[50] Batch[5] avg_epoch_loss=1.408605\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:31 INFO 140285796738880] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=1.40860460202\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:31 INFO 140285796738880] Epoch[50] Batch [5]#011Speed: 181.29 samples/sec#011loss=1.408605\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:32 INFO 140285796738880] Epoch[50] Batch[10] avg_epoch_loss=1.380209\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:32 INFO 140285796738880] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=1.3461335063\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:32 INFO 140285796738880] Epoch[50] Batch [10]#011Speed: 179.02 samples/sec#011loss=1.346134\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:32 INFO 140285796738880] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4373.196840286255, \"sum\": 4373.196840286255, \"min\": 4373.196840286255}}, \"EndTime\": 1601447132.861223, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447128.487536}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:32 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=147.942149737 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:32 INFO 140285796738880] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:32 INFO 140285796738880] #quality_metric: host=algo-1, epoch=50, train loss <loss>=1.38020864942\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:32 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:32 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_ceb495c9-9f28-43d9-99f0-ae7578758120-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 114.18414115905762, \"sum\": 114.18414115905762, \"min\": 114.18414115905762}}, \"EndTime\": 1601447132.976036, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447132.861312}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:33 INFO 140285796738880] Epoch[51] Batch[0] avg_epoch_loss=1.499977\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:33 INFO 140285796738880] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=1.49997735023\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:35 INFO 140285796738880] Epoch[51] Batch[5] avg_epoch_loss=1.436160\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:35 INFO 140285796738880] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=1.43615998824\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:35 INFO 140285796738880] Epoch[51] Batch [5]#011Speed: 181.70 samples/sec#011loss=1.436160\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:36 INFO 140285796738880] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4000.6370544433594, \"sum\": 4000.6370544433594, \"min\": 4000.6370544433594}}, \"EndTime\": 1601447136.976846, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447132.976127}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:36 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=159.718783981 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:36 INFO 140285796738880] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:36 INFO 140285796738880] #quality_metric: host=algo-1, epoch=51, train loss <loss>=1.44611849785\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:36 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:37 INFO 140285796738880] Epoch[52] Batch[0] avg_epoch_loss=1.565719\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:37 INFO 140285796738880] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=1.56571948528\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:39 INFO 140285796738880] Epoch[52] Batch[5] avg_epoch_loss=1.420378\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:39 INFO 140285796738880] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=1.42037789027\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:39 INFO 140285796738880] Epoch[52] Batch [5]#011Speed: 181.59 samples/sec#011loss=1.420378\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:41 INFO 140285796738880] Epoch[52] Batch[10] avg_epoch_loss=1.343567\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:41 INFO 140285796738880] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=1.25139446259\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:41 INFO 140285796738880] Epoch[52] Batch [10]#011Speed: 181.36 samples/sec#011loss=1.251394\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:41 INFO 140285796738880] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4358.829975128174, \"sum\": 4358.829975128174, \"min\": 4358.829975128174}}, \"EndTime\": 1601447141.336299, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447136.976944}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:41 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=150.265064142 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:41 INFO 140285796738880] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:41 INFO 140285796738880] #quality_metric: host=algo-1, epoch=52, train loss <loss>=1.34356724132\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:41 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:41 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_fad66e06-5c46-439d-9d6d-1f26556fc586-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 141.55912399291992, \"sum\": 141.55912399291992, \"min\": 141.55912399291992}}, \"EndTime\": 1601447141.478484, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447141.33639}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:42 INFO 140285796738880] Epoch[53] Batch[0] avg_epoch_loss=1.194423\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:42 INFO 140285796738880] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=1.19442296028\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:44 INFO 140285796738880] Epoch[53] Batch[5] avg_epoch_loss=1.332427\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:44 INFO 140285796738880] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=1.33242678642\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:44 INFO 140285796738880] Epoch[53] Batch [5]#011Speed: 181.35 samples/sec#011loss=1.332427\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:45 INFO 140285796738880] Epoch[53] Batch[10] avg_epoch_loss=1.450135\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:45 INFO 140285796738880] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=1.59138495922\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:45 INFO 140285796738880] Epoch[53] Batch [10]#011Speed: 181.97 samples/sec#011loss=1.591385\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:45 INFO 140285796738880] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4355.6458950042725, \"sum\": 4355.6458950042725, \"min\": 4355.6458950042725}}, \"EndTime\": 1601447145.83427, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447141.478564}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:45 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=148.538235457 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:45 INFO 140285796738880] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:45 INFO 140285796738880] #quality_metric: host=algo-1, epoch=53, train loss <loss>=1.45013504679\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:45 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:46 INFO 140285796738880] Epoch[54] Batch[0] avg_epoch_loss=1.282922\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:46 INFO 140285796738880] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=1.2829220295\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:48 INFO 140285796738880] Epoch[54] Batch[5] avg_epoch_loss=1.313540\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:48 INFO 140285796738880] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=1.31354041894\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:48 INFO 140285796738880] Epoch[54] Batch [5]#011Speed: 181.03 samples/sec#011loss=1.313540\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:50 INFO 140285796738880] Epoch[54] Batch[10] avg_epoch_loss=1.348466\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:50 INFO 140285796738880] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=1.39037771225\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:50 INFO 140285796738880] Epoch[54] Batch [10]#011Speed: 181.44 samples/sec#011loss=1.390378\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:50 INFO 140285796738880] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4361.670017242432, \"sum\": 4361.670017242432, \"min\": 4361.670017242432}}, \"EndTime\": 1601447150.19652, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447145.834363}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:50 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=151.772031474 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:50 INFO 140285796738880] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:50 INFO 140285796738880] #quality_metric: host=algo-1, epoch=54, train loss <loss>=1.34846646136\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:50 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:51 INFO 140285796738880] Epoch[55] Batch[0] avg_epoch_loss=1.373724\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:51 INFO 140285796738880] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=1.37372362614\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:52 INFO 140285796738880] Epoch[55] Batch[5] avg_epoch_loss=1.383204\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:52 INFO 140285796738880] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=1.38320350647\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:52 INFO 140285796738880] Epoch[55] Batch [5]#011Speed: 181.11 samples/sec#011loss=1.383204\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:54 INFO 140285796738880] Epoch[55] Batch[10] avg_epoch_loss=1.327097\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:54 INFO 140285796738880] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=1.25976908207\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:54 INFO 140285796738880] Epoch[55] Batch [10]#011Speed: 183.51 samples/sec#011loss=1.259769\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:54 INFO 140285796738880] processed a total of 717 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4754.22215461731, \"sum\": 4754.22215461731, \"min\": 4754.22215461731}}, \"EndTime\": 1601447154.951296, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447150.196611}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:54 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=150.808814373 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:54 INFO 140285796738880] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:54 INFO 140285796738880] #quality_metric: host=algo-1, epoch=55, train loss <loss>=1.30784820517\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:54 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:55 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_a80eb6a1-16eb-4d11-9ba4-387fa486dc9e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 117.10906028747559, \"sum\": 117.10906028747559, \"min\": 117.10906028747559}}, \"EndTime\": 1601447155.069111, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447154.951393}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:55 INFO 140285796738880] Epoch[56] Batch[0] avg_epoch_loss=1.100156\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:55 INFO 140285796738880] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=1.10015618801\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:57 INFO 140285796738880] Epoch[56] Batch[5] avg_epoch_loss=1.340170\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:57 INFO 140285796738880] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=1.34016974767\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:57 INFO 140285796738880] Epoch[56] Batch [5]#011Speed: 178.79 samples/sec#011loss=1.340170\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:59 INFO 140285796738880] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4042.2070026397705, \"sum\": 4042.2070026397705, \"min\": 4042.2070026397705}}, \"EndTime\": 1601447159.111496, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447155.069204}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:59 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=151.644238617 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:59 INFO 140285796738880] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:59 INFO 140285796738880] #quality_metric: host=algo-1, epoch=56, train loss <loss>=1.39321057796\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:59 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:59 INFO 140285796738880] Epoch[57] Batch[0] avg_epoch_loss=1.399974\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:25:59 INFO 140285796738880] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=1.39997410774\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:01 INFO 140285796738880] Epoch[57] Batch[5] avg_epoch_loss=1.329493\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:01 INFO 140285796738880] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=1.32949306568\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:01 INFO 140285796738880] Epoch[57] Batch [5]#011Speed: 178.63 samples/sec#011loss=1.329493\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:03 INFO 140285796738880] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4073.5559463500977, \"sum\": 4073.5559463500977, \"min\": 4073.5559463500977}}, \"EndTime\": 1601447163.185675, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447159.111597}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:03 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=149.986535671 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:03 INFO 140285796738880] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:03 INFO 140285796738880] #quality_metric: host=algo-1, epoch=57, train loss <loss>=1.32622576952\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:03 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:04 INFO 140285796738880] Epoch[58] Batch[0] avg_epoch_loss=1.380979\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:04 INFO 140285796738880] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=1.38097929955\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:05 INFO 140285796738880] Epoch[58] Batch[5] avg_epoch_loss=1.342416\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:05 INFO 140285796738880] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=1.34241594871\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:05 INFO 140285796738880] Epoch[58] Batch [5]#011Speed: 180.89 samples/sec#011loss=1.342416\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:07 INFO 140285796738880] Epoch[58] Batch[10] avg_epoch_loss=1.304155\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:07 INFO 140285796738880] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=1.25824173689\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:07 INFO 140285796738880] Epoch[58] Batch [10]#011Speed: 180.38 samples/sec#011loss=1.258242\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:07 INFO 140285796738880] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4403.678894042969, \"sum\": 4403.678894042969, \"min\": 4403.678894042969}}, \"EndTime\": 1601447167.589957, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447163.185772}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:07 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=148.50769623 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:07 INFO 140285796738880] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:07 INFO 140285796738880] #quality_metric: host=algo-1, epoch=58, train loss <loss>=1.30415494334\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:07 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:07 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_0a9671de-818a-41f9-9989-bb4e5aea8ab7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 122.23291397094727, \"sum\": 122.23291397094727, \"min\": 122.23291397094727}}, \"EndTime\": 1601447167.712804, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447167.590047}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:08 INFO 140285796738880] Epoch[59] Batch[0] avg_epoch_loss=1.173954\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:08 INFO 140285796738880] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=1.17395365238\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:10 INFO 140285796738880] Epoch[59] Batch[5] avg_epoch_loss=1.374485\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:10 INFO 140285796738880] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=1.37448503574\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:10 INFO 140285796738880] Epoch[59] Batch [5]#011Speed: 179.28 samples/sec#011loss=1.374485\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:11 INFO 140285796738880] processed a total of 585 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4005.5840015411377, \"sum\": 4005.5840015411377, \"min\": 4005.5840015411377}}, \"EndTime\": 1601447171.718798, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447167.713134}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:11 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=146.040799705 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:11 INFO 140285796738880] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:11 INFO 140285796738880] #quality_metric: host=algo-1, epoch=59, train loss <loss>=1.34759376049\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:11 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:12 INFO 140285796738880] Epoch[60] Batch[0] avg_epoch_loss=1.303015\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:12 INFO 140285796738880] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=1.30301511288\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:14 INFO 140285796738880] Epoch[60] Batch[5] avg_epoch_loss=1.297117\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:14 INFO 140285796738880] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=1.29711741209\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:14 INFO 140285796738880] Epoch[60] Batch [5]#011Speed: 181.80 samples/sec#011loss=1.297117\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:15 INFO 140285796738880] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4006.412982940674, \"sum\": 4006.412982940674, \"min\": 4006.412982940674}}, \"EndTime\": 1601447175.725865, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447171.718898}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:15 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=158.989301462 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:15 INFO 140285796738880] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:15 INFO 140285796738880] #quality_metric: host=algo-1, epoch=60, train loss <loss>=1.27589130402\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:15 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:15 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_ee83e9bb-ab88-4556-9730-e4b5f88839d6-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 120.94402313232422, \"sum\": 120.94402313232422, \"min\": 120.94402313232422}}, \"EndTime\": 1601447175.847473, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447175.725964}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:16 INFO 140285796738880] Epoch[61] Batch[0] avg_epoch_loss=1.239081\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:16 INFO 140285796738880] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=1.23908054829\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:18 INFO 140285796738880] Epoch[61] Batch[5] avg_epoch_loss=1.366431\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:18 INFO 140285796738880] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=1.36643093824\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:18 INFO 140285796738880] Epoch[61] Batch [5]#011Speed: 179.46 samples/sec#011loss=1.366431\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:20 INFO 140285796738880] Epoch[61] Batch[10] avg_epoch_loss=1.311438\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:20 INFO 140285796738880] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=1.24544641972\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:20 INFO 140285796738880] Epoch[61] Batch [10]#011Speed: 178.81 samples/sec#011loss=1.245446\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:20 INFO 140285796738880] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4397.392988204956, \"sum\": 4397.392988204956, \"min\": 4397.392988204956}}, \"EndTime\": 1601447180.245059, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447175.847561}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:20 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=151.676158695 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:20 INFO 140285796738880] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:20 INFO 140285796738880] #quality_metric: host=algo-1, epoch=61, train loss <loss>=1.31143797528\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:20 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:21 INFO 140285796738880] Epoch[62] Batch[0] avg_epoch_loss=1.144556\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:21 INFO 140285796738880] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=1.1445556879\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:22 INFO 140285796738880] Epoch[62] Batch[5] avg_epoch_loss=1.255389\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:22 INFO 140285796738880] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=1.25538867712\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:22 INFO 140285796738880] Epoch[62] Batch [5]#011Speed: 180.62 samples/sec#011loss=1.255389\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:24 INFO 140285796738880] Epoch[62] Batch[10] avg_epoch_loss=1.300210\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:24 INFO 140285796738880] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=1.35399487019\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:24 INFO 140285796738880] Epoch[62] Batch [10]#011Speed: 181.64 samples/sec#011loss=1.353995\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:24 INFO 140285796738880] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4348.212003707886, \"sum\": 4348.212003707886, \"min\": 4348.212003707886}}, \"EndTime\": 1601447184.593841, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447180.245148}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:24 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=152.931637137 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:24 INFO 140285796738880] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:24 INFO 140285796738880] #quality_metric: host=algo-1, epoch=62, train loss <loss>=1.30020967397\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:24 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:25 INFO 140285796738880] Epoch[63] Batch[0] avg_epoch_loss=1.517728\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:25 INFO 140285796738880] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=1.51772773266\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:27 INFO 140285796738880] Epoch[63] Batch[5] avg_epoch_loss=1.313350\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:27 INFO 140285796738880] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=1.31334994237\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:27 INFO 140285796738880] Epoch[63] Batch [5]#011Speed: 181.40 samples/sec#011loss=1.313350\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:28 INFO 140285796738880] processed a total of 596 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4042.1769618988037, \"sum\": 4042.1769618988037, \"min\": 4042.1769618988037}}, \"EndTime\": 1601447188.636577, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447184.593931}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:28 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=147.440013868 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:28 INFO 140285796738880] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:28 INFO 140285796738880] #quality_metric: host=algo-1, epoch=63, train loss <loss>=1.3070197463\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:28 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:29 INFO 140285796738880] Epoch[64] Batch[0] avg_epoch_loss=1.395473\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:29 INFO 140285796738880] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=1.39547252655\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:31 INFO 140285796738880] Epoch[64] Batch[5] avg_epoch_loss=1.294942\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:31 INFO 140285796738880] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=1.29494222005\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:31 INFO 140285796738880] Epoch[64] Batch [5]#011Speed: 180.07 samples/sec#011loss=1.294942\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:33 INFO 140285796738880] Epoch[64] Batch[10] avg_epoch_loss=1.318067\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:33 INFO 140285796738880] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=1.34581611156\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:33 INFO 140285796738880] Epoch[64] Batch [10]#011Speed: 180.66 samples/sec#011loss=1.345816\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:33 INFO 140285796738880] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4378.705024719238, \"sum\": 4378.705024719238, \"min\": 4378.705024719238}}, \"EndTime\": 1601447193.015872, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447188.636675}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:33 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=149.126286127 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:33 INFO 140285796738880] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:33 INFO 140285796738880] #quality_metric: host=algo-1, epoch=64, train loss <loss>=1.31806671619\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:33 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:33 INFO 140285796738880] Epoch[65] Batch[0] avg_epoch_loss=1.345280\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:33 INFO 140285796738880] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=1.3452796936\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:35 INFO 140285796738880] Epoch[65] Batch[5] avg_epoch_loss=1.276136\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:35 INFO 140285796738880] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=1.27613596121\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:35 INFO 140285796738880] Epoch[65] Batch [5]#011Speed: 178.92 samples/sec#011loss=1.276136\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:37 INFO 140285796738880] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4044.7349548339844, \"sum\": 4044.7349548339844, \"min\": 4044.7349548339844}}, \"EndTime\": 1601447197.061157, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447193.015963}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:37 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=150.314301067 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:37 INFO 140285796738880] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:37 INFO 140285796738880] #quality_metric: host=algo-1, epoch=65, train loss <loss>=1.25257569551\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:37 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:37 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_020e823a-3938-4faa-8dfb-f950addff6fc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 107.76400566101074, \"sum\": 107.76400566101074, \"min\": 107.76400566101074}}, \"EndTime\": 1601447197.169632, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447197.061237}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:37 INFO 140285796738880] Epoch[66] Batch[0] avg_epoch_loss=1.266333\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:37 INFO 140285796738880] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=1.26633346081\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:39 INFO 140285796738880] Epoch[66] Batch[5] avg_epoch_loss=1.234411\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:39 INFO 140285796738880] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=1.23441098134\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:39 INFO 140285796738880] Epoch[66] Batch [5]#011Speed: 179.34 samples/sec#011loss=1.234411\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:41 INFO 140285796738880] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4017.5631046295166, \"sum\": 4017.5631046295166, \"min\": 4017.5631046295166}}, \"EndTime\": 1601447201.187357, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447197.169714}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:41 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=154.815285456 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:41 INFO 140285796738880] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:41 INFO 140285796738880] #quality_metric: host=algo-1, epoch=66, train loss <loss>=1.22836034298\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:41 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:41 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_61140893-8841-4cd4-abda-1c1cf1dd7994-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 106.74500465393066, \"sum\": 106.74500465393066, \"min\": 106.74500465393066}}, \"EndTime\": 1601447201.294769, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447201.187441}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:42 INFO 140285796738880] Epoch[67] Batch[0] avg_epoch_loss=1.186773\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:42 INFO 140285796738880] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=1.18677306175\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:43 INFO 140285796738880] Epoch[67] Batch[5] avg_epoch_loss=1.266304\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:43 INFO 140285796738880] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=1.26630371809\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:43 INFO 140285796738880] Epoch[67] Batch [5]#011Speed: 180.20 samples/sec#011loss=1.266304\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:45 INFO 140285796738880] Epoch[67] Batch[10] avg_epoch_loss=1.239169\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:45 INFO 140285796738880] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=1.20660810471\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:45 INFO 140285796738880] Epoch[67] Batch [10]#011Speed: 179.21 samples/sec#011loss=1.206608\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:45 INFO 140285796738880] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4385.076999664307, \"sum\": 4385.076999664307, \"min\": 4385.076999664307}}, \"EndTime\": 1601447205.680011, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447201.29485}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:45 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=150.962047956 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:45 INFO 140285796738880] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:45 INFO 140285796738880] #quality_metric: host=algo-1, epoch=67, train loss <loss>=1.23916934837\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:45 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:46 INFO 140285796738880] Epoch[68] Batch[0] avg_epoch_loss=1.099817\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:46 INFO 140285796738880] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=1.09981703758\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:48 INFO 140285796738880] Epoch[68] Batch[5] avg_epoch_loss=1.281578\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:48 INFO 140285796738880] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=1.28157788515\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:48 INFO 140285796738880] Epoch[68] Batch [5]#011Speed: 178.69 samples/sec#011loss=1.281578\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:49 INFO 140285796738880] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4044.010877609253, \"sum\": 4044.010877609253, \"min\": 4044.010877609253}}, \"EndTime\": 1601447209.724633, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447205.680097}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:49 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=156.770038685 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:49 INFO 140285796738880] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:49 INFO 140285796738880] #quality_metric: host=algo-1, epoch=68, train loss <loss>=1.26800429821\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:49 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:50 INFO 140285796738880] Epoch[69] Batch[0] avg_epoch_loss=1.293235\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:50 INFO 140285796738880] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=1.29323494434\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:52 INFO 140285796738880] Epoch[69] Batch[5] avg_epoch_loss=1.290375\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:52 INFO 140285796738880] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=1.29037511349\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:52 INFO 140285796738880] Epoch[69] Batch [5]#011Speed: 177.49 samples/sec#011loss=1.290375\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:54 INFO 140285796738880] Epoch[69] Batch[10] avg_epoch_loss=1.296349\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:54 INFO 140285796738880] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=1.30351810455\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:54 INFO 140285796738880] Epoch[69] Batch [10]#011Speed: 179.57 samples/sec#011loss=1.303518\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:54 INFO 140285796738880] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4392.4360275268555, \"sum\": 4392.4360275268555, \"min\": 4392.4360275268555}}, \"EndTime\": 1601447214.117718, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447209.724722}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:54 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=146.155894444 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:54 INFO 140285796738880] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:54 INFO 140285796738880] #quality_metric: host=algo-1, epoch=69, train loss <loss>=1.29634920034\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:54 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:54 INFO 140285796738880] Epoch[70] Batch[0] avg_epoch_loss=1.238202\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:54 INFO 140285796738880] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=1.23820209503\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:56 INFO 140285796738880] Epoch[70] Batch[5] avg_epoch_loss=1.227981\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:56 INFO 140285796738880] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=1.22798113028\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:56 INFO 140285796738880] Epoch[70] Batch [5]#011Speed: 179.23 samples/sec#011loss=1.227981\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:58 INFO 140285796738880] Epoch[70] Batch[10] avg_epoch_loss=1.183307\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:58 INFO 140285796738880] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=1.12969784737\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:58 INFO 140285796738880] Epoch[70] Batch [10]#011Speed: 175.13 samples/sec#011loss=1.129698\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:58 INFO 140285796738880] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4449.053049087524, \"sum\": 4449.053049087524, \"min\": 4449.053049087524}}, \"EndTime\": 1601447218.567336, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447214.117808}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:58 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=144.970265654 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:58 INFO 140285796738880] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:58 INFO 140285796738880] #quality_metric: host=algo-1, epoch=70, train loss <loss>=1.18330691077\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:58 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:58 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_56fc89dc-d7f8-42a2-aa08-75aebfbda3e8-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 126.44600868225098, \"sum\": 126.44600868225098, \"min\": 126.44600868225098}}, \"EndTime\": 1601447218.694402, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447218.567427}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:59 INFO 140285796738880] Epoch[71] Batch[0] avg_epoch_loss=1.174934\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:26:59 INFO 140285796738880] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=1.17493379116\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:01 INFO 140285796738880] Epoch[71] Batch[5] avg_epoch_loss=1.208081\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:01 INFO 140285796738880] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=1.20808130503\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:01 INFO 140285796738880] Epoch[71] Batch [5]#011Speed: 181.95 samples/sec#011loss=1.208081\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:02 INFO 140285796738880] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4010.923147201538, \"sum\": 4010.923147201538, \"min\": 4010.923147201538}}, \"EndTime\": 1601447222.7057, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447218.694701}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:02 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=157.06567598 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:02 INFO 140285796738880] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:02 INFO 140285796738880] #quality_metric: host=algo-1, epoch=71, train loss <loss>=1.19366831779\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:02 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:03 INFO 140285796738880] Epoch[72] Batch[0] avg_epoch_loss=1.335325\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:03 INFO 140285796738880] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=1.33532476425\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:05 INFO 140285796738880] Epoch[72] Batch[5] avg_epoch_loss=1.235931\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:05 INFO 140285796738880] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=1.23593137662\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:05 INFO 140285796738880] Epoch[72] Batch [5]#011Speed: 179.99 samples/sec#011loss=1.235931\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:06 INFO 140285796738880] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4036.623954772949, \"sum\": 4036.623954772949, \"min\": 4036.623954772949}}, \"EndTime\": 1601447226.742914, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447222.705793}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:06 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=157.551003938 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:06 INFO 140285796738880] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:06 INFO 140285796738880] #quality_metric: host=algo-1, epoch=72, train loss <loss>=1.23805832863\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:06 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:07 INFO 140285796738880] Epoch[73] Batch[0] avg_epoch_loss=1.297556\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:07 INFO 140285796738880] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=1.29755616188\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:09 INFO 140285796738880] Epoch[73] Batch[5] avg_epoch_loss=1.273097\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:09 INFO 140285796738880] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=1.27309705814\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:09 INFO 140285796738880] Epoch[73] Batch [5]#011Speed: 181.38 samples/sec#011loss=1.273097\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:10 INFO 140285796738880] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4000.915050506592, \"sum\": 4000.915050506592, \"min\": 4000.915050506592}}, \"EndTime\": 1601447230.744522, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447226.743039}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:10 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=158.457970502 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:10 INFO 140285796738880] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:10 INFO 140285796738880] #quality_metric: host=algo-1, epoch=73, train loss <loss>=1.25984719992\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:10 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:11 INFO 140285796738880] Epoch[74] Batch[0] avg_epoch_loss=1.292210\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:11 INFO 140285796738880] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=1.29220974445\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:13 INFO 140285796738880] Epoch[74] Batch[5] avg_epoch_loss=1.229815\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:13 INFO 140285796738880] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=1.22981530428\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:13 INFO 140285796738880] Epoch[74] Batch [5]#011Speed: 180.87 samples/sec#011loss=1.229815\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:14 INFO 140285796738880] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4045.240879058838, \"sum\": 4045.240879058838, \"min\": 4045.240879058838}}, \"EndTime\": 1601447234.790433, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447230.744622}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:14 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=149.800288185 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:14 INFO 140285796738880] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:14 INFO 140285796738880] #quality_metric: host=algo-1, epoch=74, train loss <loss>=1.23614776134\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:14 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:15 INFO 140285796738880] Epoch[75] Batch[0] avg_epoch_loss=1.214962\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:15 INFO 140285796738880] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=1.21496200562\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:17 INFO 140285796738880] Epoch[75] Batch[5] avg_epoch_loss=1.238349\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:17 INFO 140285796738880] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=1.23834921916\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:17 INFO 140285796738880] Epoch[75] Batch [5]#011Speed: 179.25 samples/sec#011loss=1.238349\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:18 INFO 140285796738880] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4018.504858016968, \"sum\": 4018.504858016968, \"min\": 4018.504858016968}}, \"EndTime\": 1601447238.809604, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447234.790532}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:18 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=158.262138339 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:18 INFO 140285796738880] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:18 INFO 140285796738880] #quality_metric: host=algo-1, epoch=75, train loss <loss>=1.24304293394\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:18 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:19 INFO 140285796738880] Epoch[76] Batch[0] avg_epoch_loss=1.252238\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:19 INFO 140285796738880] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=1.25223815441\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:21 INFO 140285796738880] Epoch[76] Batch[5] avg_epoch_loss=1.187800\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:21 INFO 140285796738880] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=1.18779967229\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:21 INFO 140285796738880] Epoch[76] Batch [5]#011Speed: 178.44 samples/sec#011loss=1.187800\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:22 INFO 140285796738880] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4023.05006980896, \"sum\": 4023.05006980896, \"min\": 4023.05006980896}}, \"EndTime\": 1601447242.833288, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447238.809702}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:22 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=155.10064601 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:22 INFO 140285796738880] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:22 INFO 140285796738880] #quality_metric: host=algo-1, epoch=76, train loss <loss>=1.18949837685\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:22 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:23 INFO 140285796738880] Epoch[77] Batch[0] avg_epoch_loss=1.290118\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:23 INFO 140285796738880] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=1.29011833668\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:25 INFO 140285796738880] Epoch[77] Batch[5] avg_epoch_loss=1.180483\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:25 INFO 140285796738880] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=1.18048317234\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:25 INFO 140285796738880] Epoch[77] Batch [5]#011Speed: 182.22 samples/sec#011loss=1.180483\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:26 INFO 140285796738880] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4034.327983856201, \"sum\": 4034.327983856201, \"min\": 4034.327983856201}}, \"EndTime\": 1601447246.868254, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447242.833386}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:26 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=157.889385014 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:26 INFO 140285796738880] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:26 INFO 140285796738880] #quality_metric: host=algo-1, epoch=77, train loss <loss>=1.21805538535\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:26 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:27 INFO 140285796738880] Epoch[78] Batch[0] avg_epoch_loss=1.435348\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:27 INFO 140285796738880] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=1.43534755707\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:29 INFO 140285796738880] Epoch[78] Batch[5] avg_epoch_loss=1.287132\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:29 INFO 140285796738880] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=1.28713238239\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:29 INFO 140285796738880] Epoch[78] Batch [5]#011Speed: 176.75 samples/sec#011loss=1.287132\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:30 INFO 140285796738880] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4078.8700580596924, \"sum\": 4078.8700580596924, \"min\": 4078.8700580596924}}, \"EndTime\": 1601447250.947738, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447246.868351}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:30 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=154.93936586 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:30 INFO 140285796738880] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:30 INFO 140285796738880] #quality_metric: host=algo-1, epoch=78, train loss <loss>=1.24677077532\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:30 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:31 INFO 140285796738880] Epoch[79] Batch[0] avg_epoch_loss=1.196254\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:31 INFO 140285796738880] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=1.19625449181\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:33 INFO 140285796738880] Epoch[79] Batch[5] avg_epoch_loss=1.193304\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:33 INFO 140285796738880] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=1.19330378373\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:33 INFO 140285796738880] Epoch[79] Batch [5]#011Speed: 173.66 samples/sec#011loss=1.193304\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:35 INFO 140285796738880] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4075.5138397216797, \"sum\": 4075.5138397216797, \"min\": 4075.5138397216797}}, \"EndTime\": 1601447255.023901, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447250.947835}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:35 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=152.122601364 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:35 INFO 140285796738880] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:35 INFO 140285796738880] #quality_metric: host=algo-1, epoch=79, train loss <loss>=1.21608837843\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:35 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:35 INFO 140285796738880] Epoch[80] Batch[0] avg_epoch_loss=1.207311\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:35 INFO 140285796738880] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=1.20731127262\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:37 INFO 140285796738880] Epoch[80] Batch[5] avg_epoch_loss=1.285743\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:37 INFO 140285796738880] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=1.28574291865\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:37 INFO 140285796738880] Epoch[80] Batch [5]#011Speed: 180.11 samples/sec#011loss=1.285743\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:39 INFO 140285796738880] Epoch[80] Batch[10] avg_epoch_loss=1.420568\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:39 INFO 140285796738880] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=1.58235919476\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:39 INFO 140285796738880] Epoch[80] Batch [10]#011Speed: 181.70 samples/sec#011loss=1.582359\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:39 INFO 140285796738880] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4364.993095397949, \"sum\": 4364.993095397949, \"min\": 4364.993095397949}}, \"EndTime\": 1601447259.389531, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447255.024}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:39 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=150.28196877 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:39 INFO 140285796738880] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:39 INFO 140285796738880] #quality_metric: host=algo-1, epoch=80, train loss <loss>=1.4205684987\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:39 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:40 INFO 140285796738880] Epoch[81] Batch[0] avg_epoch_loss=1.188417\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:40 INFO 140285796738880] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=1.18841731548\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:41 INFO 140285796738880] Epoch[81] Batch[5] avg_epoch_loss=1.290901\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:41 INFO 140285796738880] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=1.29090102514\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:41 INFO 140285796738880] Epoch[81] Batch [5]#011Speed: 182.09 samples/sec#011loss=1.290901\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:43 INFO 140285796738880] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4019.014835357666, \"sum\": 4019.014835357666, \"min\": 4019.014835357666}}, \"EndTime\": 1601447263.409107, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447259.389622}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:43 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=157.744477897 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:43 INFO 140285796738880] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:43 INFO 140285796738880] #quality_metric: host=algo-1, epoch=81, train loss <loss>=1.32610712051\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:43 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:44 INFO 140285796738880] Epoch[82] Batch[0] avg_epoch_loss=1.321612\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:44 INFO 140285796738880] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=1.32161152363\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:46 INFO 140285796738880] Epoch[82] Batch[5] avg_epoch_loss=1.310286\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:46 INFO 140285796738880] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=1.31028630336\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:46 INFO 140285796738880] Epoch[82] Batch [5]#011Speed: 180.87 samples/sec#011loss=1.310286\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:47 INFO 140285796738880] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4033.0729484558105, \"sum\": 4033.0729484558105, \"min\": 4033.0729484558105}}, \"EndTime\": 1601447267.442798, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447263.409206}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:47 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=151.987775756 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:47 INFO 140285796738880] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:47 INFO 140285796738880] #quality_metric: host=algo-1, epoch=82, train loss <loss>=1.27928878069\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:47 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:48 INFO 140285796738880] Epoch[83] Batch[0] avg_epoch_loss=1.154759\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:48 INFO 140285796738880] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=1.15475904942\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:50 INFO 140285796738880] Epoch[83] Batch[5] avg_epoch_loss=1.240534\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:50 INFO 140285796738880] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=1.24053376913\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:50 INFO 140285796738880] Epoch[83] Batch [5]#011Speed: 180.02 samples/sec#011loss=1.240534\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:51 INFO 140285796738880] Epoch[83] Batch[10] avg_epoch_loss=1.254582\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:51 INFO 140285796738880] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=1.27143967152\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:51 INFO 140285796738880] Epoch[83] Batch [10]#011Speed: 180.23 samples/sec#011loss=1.271440\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:51 INFO 140285796738880] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4375.489950180054, \"sum\": 4375.489950180054, \"min\": 4375.489950180054}}, \"EndTime\": 1601447271.819037, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447267.442895}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:51 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=148.548915616 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:51 INFO 140285796738880] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:51 INFO 140285796738880] #quality_metric: host=algo-1, epoch=83, train loss <loss>=1.25458190658\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:51 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:52 INFO 140285796738880] Epoch[84] Batch[0] avg_epoch_loss=1.321379\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:52 INFO 140285796738880] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=1.32137918472\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:54 INFO 140285796738880] Epoch[84] Batch[5] avg_epoch_loss=1.299781\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:54 INFO 140285796738880] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=1.29978114367\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:54 INFO 140285796738880] Epoch[84] Batch [5]#011Speed: 182.10 samples/sec#011loss=1.299781\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:55 INFO 140285796738880] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4011.9919776916504, \"sum\": 4011.9919776916504, \"min\": 4011.9919776916504}}, \"EndTime\": 1601447275.83159, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447271.819128}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:55 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=154.281872689 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:55 INFO 140285796738880] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:55 INFO 140285796738880] #quality_metric: host=algo-1, epoch=84, train loss <loss>=1.29738132954\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:55 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:56 INFO 140285796738880] Epoch[85] Batch[0] avg_epoch_loss=1.134130\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:56 INFO 140285796738880] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=1.13412988186\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:58 INFO 140285796738880] Epoch[85] Batch[5] avg_epoch_loss=1.242760\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:58 INFO 140285796738880] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=1.24275966485\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:58 INFO 140285796738880] Epoch[85] Batch [5]#011Speed: 175.65 samples/sec#011loss=1.242760\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:59 INFO 140285796738880] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4094.024896621704, \"sum\": 4094.024896621704, \"min\": 4094.024896621704}}, \"EndTime\": 1601447279.92621, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447275.831688}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:59 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=155.58842831 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:59 INFO 140285796738880] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:59 INFO 140285796738880] #quality_metric: host=algo-1, epoch=85, train loss <loss>=1.230167377\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:27:59 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:00 INFO 140285796738880] Epoch[86] Batch[0] avg_epoch_loss=1.098905\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:00 INFO 140285796738880] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=1.09890508652\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:02 INFO 140285796738880] Epoch[86] Batch[5] avg_epoch_loss=1.221834\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:02 INFO 140285796738880] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=1.22183402379\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:02 INFO 140285796738880] Epoch[86] Batch [5]#011Speed: 179.58 samples/sec#011loss=1.221834\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:03 INFO 140285796738880] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4043.765068054199, \"sum\": 4043.765068054199, \"min\": 4043.765068054199}}, \"EndTime\": 1601447283.970584, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447279.926283}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:03 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=156.285197951 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:03 INFO 140285796738880] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:03 INFO 140285796738880] #quality_metric: host=algo-1, epoch=86, train loss <loss>=1.18944883347\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:03 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:04 INFO 140285796738880] Epoch[87] Batch[0] avg_epoch_loss=1.184148\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:04 INFO 140285796738880] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=1.18414843082\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:06 INFO 140285796738880] Epoch[87] Batch[5] avg_epoch_loss=1.203451\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:06 INFO 140285796738880] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=1.2034514149\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:06 INFO 140285796738880] Epoch[87] Batch [5]#011Speed: 181.07 samples/sec#011loss=1.203451\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:08 INFO 140285796738880] Epoch[87] Batch[10] avg_epoch_loss=1.181774\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:08 INFO 140285796738880] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=1.15576057434\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:08 INFO 140285796738880] Epoch[87] Batch [10]#011Speed: 180.51 samples/sec#011loss=1.155761\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:08 INFO 140285796738880] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4356.065988540649, \"sum\": 4356.065988540649, \"min\": 4356.065988540649}}, \"EndTime\": 1601447288.327336, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447283.970658}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:08 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=147.376113882 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:08 INFO 140285796738880] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:08 INFO 140285796738880] #quality_metric: host=algo-1, epoch=87, train loss <loss>=1.1817737601\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:08 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:08 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_99c2b463-2d55-4b86-bbb2-05a2c9a5d6dc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 118.8819408416748, \"sum\": 118.8819408416748, \"min\": 118.8819408416748}}, \"EndTime\": 1601447288.446852, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447288.327427}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:09 INFO 140285796738880] Epoch[88] Batch[0] avg_epoch_loss=1.253230\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:09 INFO 140285796738880] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=1.25323033333\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:11 INFO 140285796738880] Epoch[88] Batch[5] avg_epoch_loss=1.258699\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:11 INFO 140285796738880] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=1.25869915883\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:11 INFO 140285796738880] Epoch[88] Batch [5]#011Speed: 181.92 samples/sec#011loss=1.258699\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:12 INFO 140285796738880] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4019.8299884796143, \"sum\": 4019.8299884796143, \"min\": 4019.8299884796143}}, \"EndTime\": 1601447292.466874, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447288.446942}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:12 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=157.711162928 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:12 INFO 140285796738880] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:12 INFO 140285796738880] #quality_metric: host=algo-1, epoch=88, train loss <loss>=1.26467735767\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:12 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:13 INFO 140285796738880] Epoch[89] Batch[0] avg_epoch_loss=1.414281\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:13 INFO 140285796738880] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=1.41428089142\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:15 INFO 140285796738880] Epoch[89] Batch[5] avg_epoch_loss=1.187540\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:15 INFO 140285796738880] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=1.18753955762\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:15 INFO 140285796738880] Epoch[89] Batch [5]#011Speed: 180.68 samples/sec#011loss=1.187540\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:16 INFO 140285796738880] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4038.8689041137695, \"sum\": 4038.8689041137695, \"min\": 4038.8689041137695}}, \"EndTime\": 1601447296.506393, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447292.466971}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:16 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=157.711987159 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:16 INFO 140285796738880] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:16 INFO 140285796738880] #quality_metric: host=algo-1, epoch=89, train loss <loss>=1.20175395012\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:16 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:17 INFO 140285796738880] Epoch[90] Batch[0] avg_epoch_loss=1.171366\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:17 INFO 140285796738880] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=1.17136597633\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:19 INFO 140285796738880] Epoch[90] Batch[5] avg_epoch_loss=1.217946\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:19 INFO 140285796738880] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=1.21794561545\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:19 INFO 140285796738880] Epoch[90] Batch [5]#011Speed: 180.62 samples/sec#011loss=1.217946\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:20 INFO 140285796738880] processed a total of 597 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4052.2029399871826, \"sum\": 4052.2029399871826, \"min\": 4052.2029399871826}}, \"EndTime\": 1601447300.559178, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447296.506487}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:20 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=147.322035386 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:20 INFO 140285796738880] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:20 INFO 140285796738880] #quality_metric: host=algo-1, epoch=90, train loss <loss>=1.26542006731\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:20 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:21 INFO 140285796738880] Epoch[91] Batch[0] avg_epoch_loss=1.268934\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:21 INFO 140285796738880] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=1.26893436909\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:23 INFO 140285796738880] Epoch[91] Batch[5] avg_epoch_loss=1.209507\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:23 INFO 140285796738880] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=1.20950694879\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:23 INFO 140285796738880] Epoch[91] Batch [5]#011Speed: 178.15 samples/sec#011loss=1.209507\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:24 INFO 140285796738880] Epoch[91] Batch[10] avg_epoch_loss=1.077948\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:24 INFO 140285796738880] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=0.920078214258\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:24 INFO 140285796738880] Epoch[91] Batch [10]#011Speed: 181.36 samples/sec#011loss=0.920078\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:24 INFO 140285796738880] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4412.367105484009, \"sum\": 4412.367105484009, \"min\": 4412.367105484009}}, \"EndTime\": 1601447304.972157, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447300.559277}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:24 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=145.269124953 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:24 INFO 140285796738880] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:24 INFO 140285796738880] #quality_metric: host=algo-1, epoch=91, train loss <loss>=1.07794843309\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:24 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:25 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_896f8439-428c-411f-983f-4fbe3d72dfba-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 117.5391674041748, \"sum\": 117.5391674041748, \"min\": 117.5391674041748}}, \"EndTime\": 1601447305.090355, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447304.972248}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:25 INFO 140285796738880] Epoch[92] Batch[0] avg_epoch_loss=1.114984\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:25 INFO 140285796738880] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=1.11498439312\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:27 INFO 140285796738880] Epoch[92] Batch[5] avg_epoch_loss=1.175925\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:27 INFO 140285796738880] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=1.17592489719\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:27 INFO 140285796738880] Epoch[92] Batch [5]#011Speed: 181.08 samples/sec#011loss=1.175925\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:29 INFO 140285796738880] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4045.2089309692383, \"sum\": 4045.2089309692383, \"min\": 4045.2089309692383}}, \"EndTime\": 1601447309.135717, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447305.090434}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:29 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=153.509582242 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:29 INFO 140285796738880] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:29 INFO 140285796738880] #quality_metric: host=algo-1, epoch=92, train loss <loss>=1.19464366436\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:29 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:29 INFO 140285796738880] Epoch[93] Batch[0] avg_epoch_loss=1.325012\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:29 INFO 140285796738880] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=1.32501232624\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:31 INFO 140285796738880] Epoch[93] Batch[5] avg_epoch_loss=1.157595\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:31 INFO 140285796738880] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=1.15759506822\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:31 INFO 140285796738880] Epoch[93] Batch [5]#011Speed: 182.31 samples/sec#011loss=1.157595\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:33 INFO 140285796738880] Epoch[93] Batch[10] avg_epoch_loss=1.156119\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:33 INFO 140285796738880] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=1.15434672832\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:33 INFO 140285796738880] Epoch[93] Batch [10]#011Speed: 180.80 samples/sec#011loss=1.154347\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:33 INFO 140285796738880] processed a total of 722 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4745.558977127075, \"sum\": 4745.558977127075, \"min\": 4745.558977127075}}, \"EndTime\": 1601447313.881876, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447309.135812}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:33 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=152.137728444 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:33 INFO 140285796738880] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:33 INFO 140285796738880] #quality_metric: host=algo-1, epoch=93, train loss <loss>=1.09495160977\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:33 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:34 INFO 140285796738880] Epoch[94] Batch[0] avg_epoch_loss=1.157217\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:34 INFO 140285796738880] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=1.15721726418\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:36 INFO 140285796738880] Epoch[94] Batch[5] avg_epoch_loss=1.200006\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:36 INFO 140285796738880] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=1.20000553131\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:36 INFO 140285796738880] Epoch[94] Batch [5]#011Speed: 180.34 samples/sec#011loss=1.200006\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:37 INFO 140285796738880] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4028.2700061798096, \"sum\": 4028.2700061798096, \"min\": 4028.2700061798096}}, \"EndTime\": 1601447317.910763, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447313.881974}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:37 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=151.422815229 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:37 INFO 140285796738880] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:37 INFO 140285796738880] #quality_metric: host=algo-1, epoch=94, train loss <loss>=1.22587370872\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:37 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:38 INFO 140285796738880] Epoch[95] Batch[0] avg_epoch_loss=1.083050\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:38 INFO 140285796738880] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=1.08304965496\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:40 INFO 140285796738880] Epoch[95] Batch[5] avg_epoch_loss=1.293540\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:40 INFO 140285796738880] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=1.2935401996\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:40 INFO 140285796738880] Epoch[95] Batch [5]#011Speed: 181.76 samples/sec#011loss=1.293540\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:41 INFO 140285796738880] processed a total of 591 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4004.7130584716797, \"sum\": 4004.7130584716797, \"min\": 4004.7130584716797}}, \"EndTime\": 1601447321.916251, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447317.9109}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:41 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=147.570809809 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:41 INFO 140285796738880] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:41 INFO 140285796738880] #quality_metric: host=algo-1, epoch=95, train loss <loss>=1.18520995378\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:41 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:42 INFO 140285796738880] Epoch[96] Batch[0] avg_epoch_loss=1.111647\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:42 INFO 140285796738880] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=1.11164724827\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:44 INFO 140285796738880] Epoch[96] Batch[5] avg_epoch_loss=1.119058\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:44 INFO 140285796738880] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=1.11905791362\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:44 INFO 140285796738880] Epoch[96] Batch [5]#011Speed: 178.31 samples/sec#011loss=1.119058\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:46 INFO 140285796738880] Epoch[96] Batch[10] avg_epoch_loss=1.136855\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:46 INFO 140285796738880] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=1.15821137428\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:46 INFO 140285796738880] Epoch[96] Batch [10]#011Speed: 179.36 samples/sec#011loss=1.158211\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:46 INFO 140285796738880] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4424.507141113281, \"sum\": 4424.507141113281, \"min\": 4424.507141113281}}, \"EndTime\": 1601447326.341372, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447321.91635}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:46 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=147.356392827 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:46 INFO 140285796738880] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:46 INFO 140285796738880] #quality_metric: host=algo-1, epoch=96, train loss <loss>=1.13685494119\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:46 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:47 INFO 140285796738880] Epoch[97] Batch[0] avg_epoch_loss=1.422002\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:47 INFO 140285796738880] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=1.42200219631\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:48 INFO 140285796738880] Epoch[97] Batch[5] avg_epoch_loss=1.268452\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:48 INFO 140285796738880] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=1.26845212777\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:48 INFO 140285796738880] Epoch[97] Batch [5]#011Speed: 175.01 samples/sec#011loss=1.268452\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:50 INFO 140285796738880] Epoch[97] Batch[10] avg_epoch_loss=1.261989\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:50 INFO 140285796738880] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=1.25423414707\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:50 INFO 140285796738880] Epoch[97] Batch [10]#011Speed: 180.18 samples/sec#011loss=1.254234\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:50 INFO 140285796738880] processed a total of 695 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4429.3248653411865, \"sum\": 4429.3248653411865, \"min\": 4429.3248653411865}}, \"EndTime\": 1601447330.771278, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447326.341464}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:50 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=156.904532184 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:50 INFO 140285796738880] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:50 INFO 140285796738880] #quality_metric: host=algo-1, epoch=97, train loss <loss>=1.26198940927\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:50 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:51 INFO 140285796738880] Epoch[98] Batch[0] avg_epoch_loss=1.073366\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:51 INFO 140285796738880] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=1.07336628437\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:53 INFO 140285796738880] Epoch[98] Batch[5] avg_epoch_loss=1.205681\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:53 INFO 140285796738880] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=1.20568054914\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:53 INFO 140285796738880] Epoch[98] Batch [5]#011Speed: 175.26 samples/sec#011loss=1.205681\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:55 INFO 140285796738880] Epoch[98] Batch[10] avg_epoch_loss=1.123221\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:55 INFO 140285796738880] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=1.02426959276\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:55 INFO 140285796738880] Epoch[98] Batch [10]#011Speed: 182.01 samples/sec#011loss=1.024270\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:55 INFO 140285796738880] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4408.344984054565, \"sum\": 4408.344984054565, \"min\": 4408.344984054565}}, \"EndTime\": 1601447335.18022, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447330.771355}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:55 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=154.474972513 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:55 INFO 140285796738880] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:55 INFO 140285796738880] #quality_metric: host=algo-1, epoch=98, train loss <loss>=1.12322102352\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:55 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:55 INFO 140285796738880] Epoch[99] Batch[0] avg_epoch_loss=1.187565\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:55 INFO 140285796738880] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=1.18756473064\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:57 INFO 140285796738880] Epoch[99] Batch[5] avg_epoch_loss=1.115086\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:57 INFO 140285796738880] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=1.11508634686\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:57 INFO 140285796738880] Epoch[99] Batch [5]#011Speed: 181.07 samples/sec#011loss=1.115086\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:59 INFO 140285796738880] processed a total of 598 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4061.738967895508, \"sum\": 4061.738967895508, \"min\": 4061.738967895508}}, \"EndTime\": 1601447339.242534, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447335.180312}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:59 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=147.222974213 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:59 INFO 140285796738880] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:59 INFO 140285796738880] #quality_metric: host=algo-1, epoch=99, train loss <loss>=1.08712416291\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:28:59 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:00 INFO 140285796738880] Epoch[100] Batch[0] avg_epoch_loss=1.188967\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:00 INFO 140285796738880] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=1.18896687031\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:01 INFO 140285796738880] Epoch[100] Batch[5] avg_epoch_loss=1.226072\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:01 INFO 140285796738880] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=1.22607211272\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:01 INFO 140285796738880] Epoch[100] Batch [5]#011Speed: 179.81 samples/sec#011loss=1.226072\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:03 INFO 140285796738880] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4025.3539085388184, \"sum\": 4025.3539085388184, \"min\": 4025.3539085388184}}, \"EndTime\": 1601447343.268572, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447339.242622}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:03 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=152.775968984 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:03 INFO 140285796738880] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:03 INFO 140285796738880] #quality_metric: host=algo-1, epoch=100, train loss <loss>=1.205651474\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:03 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:04 INFO 140285796738880] Epoch[101] Batch[0] avg_epoch_loss=1.128302\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:04 INFO 140285796738880] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=1.12830150127\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:05 INFO 140285796738880] Epoch[101] Batch[5] avg_epoch_loss=1.136514\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:05 INFO 140285796738880] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=1.13651354114\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:05 INFO 140285796738880] Epoch[101] Batch [5]#011Speed: 181.79 samples/sec#011loss=1.136514\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:07 INFO 140285796738880] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3993.962049484253, \"sum\": 3993.962049484253, \"min\": 3993.962049484253}}, \"EndTime\": 1601447347.263173, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447343.268673}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:07 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=153.225812687 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:07 INFO 140285796738880] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:07 INFO 140285796738880] #quality_metric: host=algo-1, epoch=101, train loss <loss>=1.14865835905\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:07 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:08 INFO 140285796738880] Epoch[102] Batch[0] avg_epoch_loss=1.346660\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:08 INFO 140285796738880] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=1.34665989876\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:09 INFO 140285796738880] Epoch[102] Batch[5] avg_epoch_loss=1.175267\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:09 INFO 140285796738880] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=1.17526741823\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:09 INFO 140285796738880] Epoch[102] Batch [5]#011Speed: 178.70 samples/sec#011loss=1.175267\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:11 INFO 140285796738880] Epoch[102] Batch[10] avg_epoch_loss=1.174504\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:11 INFO 140285796738880] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=1.17358868122\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:11 INFO 140285796738880] Epoch[102] Batch [10]#011Speed: 179.54 samples/sec#011loss=1.173589\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:11 INFO 140285796738880] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4406.1150550842285, \"sum\": 4406.1150550842285, \"min\": 4406.1150550842285}}, \"EndTime\": 1601447351.669892, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447347.263271}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:11 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=150.241199787 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:11 INFO 140285796738880] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:11 INFO 140285796738880] #quality_metric: host=algo-1, epoch=102, train loss <loss>=1.17450435595\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:11 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:12 INFO 140285796738880] Epoch[103] Batch[0] avg_epoch_loss=1.084849\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:12 INFO 140285796738880] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=1.08484888077\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:14 INFO 140285796738880] Epoch[103] Batch[5] avg_epoch_loss=1.250738\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:14 INFO 140285796738880] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=1.25073840221\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:14 INFO 140285796738880] Epoch[103] Batch [5]#011Speed: 178.69 samples/sec#011loss=1.250738\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:15 INFO 140285796738880] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4013.6189460754395, \"sum\": 4013.6189460754395, \"min\": 4013.6189460754395}}, \"EndTime\": 1601447355.684119, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447351.669979}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:15 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=158.953036918 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:15 INFO 140285796738880] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:15 INFO 140285796738880] #quality_metric: host=algo-1, epoch=103, train loss <loss>=1.18810492754\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:15 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:16 INFO 140285796738880] Epoch[104] Batch[0] avg_epoch_loss=1.153477\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:16 INFO 140285796738880] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=1.15347707272\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:18 INFO 140285796738880] Epoch[104] Batch[5] avg_epoch_loss=1.084010\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:18 INFO 140285796738880] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=1.08401015401\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:18 INFO 140285796738880] Epoch[104] Batch [5]#011Speed: 181.27 samples/sec#011loss=1.084010\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:19 INFO 140285796738880] processed a total of 583 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3994.694948196411, \"sum\": 3994.694948196411, \"min\": 3994.694948196411}}, \"EndTime\": 1601447359.679432, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447355.684217}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:19 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=145.938481511 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:19 INFO 140285796738880] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:19 INFO 140285796738880] #quality_metric: host=algo-1, epoch=104, train loss <loss>=1.11226510406\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:19 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:20 INFO 140285796738880] Epoch[105] Batch[0] avg_epoch_loss=1.257452\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:20 INFO 140285796738880] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=1.25745224953\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:22 INFO 140285796738880] Epoch[105] Batch[5] avg_epoch_loss=1.165299\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:22 INFO 140285796738880] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=1.16529929638\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:22 INFO 140285796738880] Epoch[105] Batch [5]#011Speed: 181.34 samples/sec#011loss=1.165299\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:24 INFO 140285796738880] Epoch[105] Batch[10] avg_epoch_loss=1.136715\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:24 INFO 140285796738880] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=1.10241374969\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:24 INFO 140285796738880] Epoch[105] Batch [10]#011Speed: 179.36 samples/sec#011loss=1.102414\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:24 INFO 140285796738880] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4401.1290073394775, \"sum\": 4401.1290073394775, \"min\": 4401.1290073394775}}, \"EndTime\": 1601447364.081125, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447359.679526}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:24 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=146.548842959 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:24 INFO 140285796738880] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:24 INFO 140285796738880] #quality_metric: host=algo-1, epoch=105, train loss <loss>=1.13671495698\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:24 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:24 INFO 140285796738880] Epoch[106] Batch[0] avg_epoch_loss=1.213360\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:24 INFO 140285796738880] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=1.2133603096\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:26 INFO 140285796738880] Epoch[106] Batch[5] avg_epoch_loss=1.167755\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:26 INFO 140285796738880] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=1.16775510708\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:26 INFO 140285796738880] Epoch[106] Batch [5]#011Speed: 182.20 samples/sec#011loss=1.167755\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:28 INFO 140285796738880] Epoch[106] Batch[10] avg_epoch_loss=1.162451\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:28 INFO 140285796738880] #quality_metric: host=algo-1, epoch=106, batch=10 train loss <loss>=1.15608713627\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:28 INFO 140285796738880] Epoch[106] Batch [10]#011Speed: 179.34 samples/sec#011loss=1.156087\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:28 INFO 140285796738880] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4399.486064910889, \"sum\": 4399.486064910889, \"min\": 4399.486064910889}}, \"EndTime\": 1601447368.481157, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447364.081216}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:28 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=147.740062233 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:28 INFO 140285796738880] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:28 INFO 140285796738880] #quality_metric: host=algo-1, epoch=106, train loss <loss>=1.16245148399\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:28 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:29 INFO 140285796738880] Epoch[107] Batch[0] avg_epoch_loss=1.177408\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:29 INFO 140285796738880] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=1.17740786076\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:31 INFO 140285796738880] Epoch[107] Batch[5] avg_epoch_loss=1.124018\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:31 INFO 140285796738880] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=1.12401757638\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:31 INFO 140285796738880] Epoch[107] Batch [5]#011Speed: 179.43 samples/sec#011loss=1.124018\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:32 INFO 140285796738880] Epoch[107] Batch[10] avg_epoch_loss=1.117980\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:32 INFO 140285796738880] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=1.11073569059\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:32 INFO 140285796738880] Epoch[107] Batch [10]#011Speed: 179.46 samples/sec#011loss=1.110736\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:32 INFO 140285796738880] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4416.815996170044, \"sum\": 4416.815996170044, \"min\": 4416.815996170044}}, \"EndTime\": 1601447372.898519, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447368.481247}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:32 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=146.933938968 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:32 INFO 140285796738880] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:32 INFO 140285796738880] #quality_metric: host=algo-1, epoch=107, train loss <loss>=1.11798035557\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:32 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:33 INFO 140285796738880] Epoch[108] Batch[0] avg_epoch_loss=1.188474\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:33 INFO 140285796738880] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=1.18847382069\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:35 INFO 140285796738880] Epoch[108] Batch[5] avg_epoch_loss=1.212396\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:35 INFO 140285796738880] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=1.21239578724\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:35 INFO 140285796738880] Epoch[108] Batch [5]#011Speed: 181.71 samples/sec#011loss=1.212396\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:37 INFO 140285796738880] Epoch[108] Batch[10] avg_epoch_loss=1.197780\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:37 INFO 140285796738880] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=1.1802421093\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:37 INFO 140285796738880] Epoch[108] Batch [10]#011Speed: 181.60 samples/sec#011loss=1.180242\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:37 INFO 140285796738880] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4401.063919067383, \"sum\": 4401.063919067383, \"min\": 4401.063919067383}}, \"EndTime\": 1601447377.300163, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447372.89861}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:37 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=147.459845721 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:37 INFO 140285796738880] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:37 INFO 140285796738880] #quality_metric: host=algo-1, epoch=108, train loss <loss>=1.19778047908\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:37 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:38 INFO 140285796738880] Epoch[109] Batch[0] avg_epoch_loss=1.167585\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:38 INFO 140285796738880] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=1.16758537292\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:39 INFO 140285796738880] Epoch[109] Batch[5] avg_epoch_loss=1.124361\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:39 INFO 140285796738880] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=1.12436101834\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:39 INFO 140285796738880] Epoch[109] Batch [5]#011Speed: 180.52 samples/sec#011loss=1.124361\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:41 INFO 140285796738880] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4062.8650188446045, \"sum\": 4062.8650188446045, \"min\": 4062.8650188446045}}, \"EndTime\": 1601447381.363633, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447377.300253}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:41 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=154.319161862 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:41 INFO 140285796738880] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:41 INFO 140285796738880] #quality_metric: host=algo-1, epoch=109, train loss <loss>=1.12253582478\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:41 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:42 INFO 140285796738880] Epoch[110] Batch[0] avg_epoch_loss=1.047580\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:42 INFO 140285796738880] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=1.0475795269\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:44 INFO 140285796738880] Epoch[110] Batch[5] avg_epoch_loss=1.134831\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:44 INFO 140285796738880] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=1.13483073314\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:44 INFO 140285796738880] Epoch[110] Batch [5]#011Speed: 179.44 samples/sec#011loss=1.134831\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:45 INFO 140285796738880] Epoch[110] Batch[10] avg_epoch_loss=1.088069\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:45 INFO 140285796738880] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=1.03195540905\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:45 INFO 140285796738880] Epoch[110] Batch [10]#011Speed: 181.26 samples/sec#011loss=1.031955\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:45 INFO 140285796738880] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4409.041881561279, \"sum\": 4409.041881561279, \"min\": 4409.041881561279}}, \"EndTime\": 1601447385.77333, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447381.363731}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:45 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=154.450631965 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:45 INFO 140285796738880] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:45 INFO 140285796738880] #quality_metric: host=algo-1, epoch=110, train loss <loss>=1.08806922219\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:45 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:46 INFO 140285796738880] Epoch[111] Batch[0] avg_epoch_loss=1.097361\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:46 INFO 140285796738880] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=1.09736096859\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:48 INFO 140285796738880] Epoch[111] Batch[5] avg_epoch_loss=1.160887\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:48 INFO 140285796738880] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=1.16088654598\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:48 INFO 140285796738880] Epoch[111] Batch [5]#011Speed: 181.68 samples/sec#011loss=1.160887\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:50 INFO 140285796738880] Epoch[111] Batch[10] avg_epoch_loss=1.166539\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:50 INFO 140285796738880] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=1.17332191467\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:50 INFO 140285796738880] Epoch[111] Batch [10]#011Speed: 175.19 samples/sec#011loss=1.173322\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:50 INFO 140285796738880] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4425.516843795776, \"sum\": 4425.516843795776, \"min\": 4425.516843795776}}, \"EndTime\": 1601447390.199401, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447385.773421}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:50 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=147.323726221 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:50 INFO 140285796738880] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:50 INFO 140285796738880] #quality_metric: host=algo-1, epoch=111, train loss <loss>=1.16653898629\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:50 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:51 INFO 140285796738880] Epoch[112] Batch[0] avg_epoch_loss=1.071794\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:51 INFO 140285796738880] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=1.07179379463\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:52 INFO 140285796738880] Epoch[112] Batch[5] avg_epoch_loss=1.167133\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:52 INFO 140285796738880] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=1.16713341077\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:52 INFO 140285796738880] Epoch[112] Batch [5]#011Speed: 178.80 samples/sec#011loss=1.167133\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:54 INFO 140285796738880] Epoch[112] Batch[10] avg_epoch_loss=1.157546\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:54 INFO 140285796738880] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=1.1460414052\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:54 INFO 140285796738880] Epoch[112] Batch [10]#011Speed: 176.19 samples/sec#011loss=1.146041\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:54 INFO 140285796738880] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4421.856164932251, \"sum\": 4421.856164932251, \"min\": 4421.856164932251}}, \"EndTime\": 1601447394.621818, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447390.199471}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:54 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=146.992646317 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:54 INFO 140285796738880] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:54 INFO 140285796738880] #quality_metric: host=algo-1, epoch=112, train loss <loss>=1.15754613551\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:54 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:55 INFO 140285796738880] Epoch[113] Batch[0] avg_epoch_loss=1.363665\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:55 INFO 140285796738880] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=1.36366474628\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:57 INFO 140285796738880] Epoch[113] Batch[5] avg_epoch_loss=1.222122\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:57 INFO 140285796738880] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=1.22212153673\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:57 INFO 140285796738880] Epoch[113] Batch [5]#011Speed: 180.31 samples/sec#011loss=1.222122\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:58 INFO 140285796738880] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4054.119110107422, \"sum\": 4054.119110107422, \"min\": 4054.119110107422}}, \"EndTime\": 1601447398.676489, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447394.621907}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:58 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=156.87299895 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:58 INFO 140285796738880] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:58 INFO 140285796738880] #quality_metric: host=algo-1, epoch=113, train loss <loss>=1.23930866718\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:58 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:59 INFO 140285796738880] Epoch[114] Batch[0] avg_epoch_loss=1.092895\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:29:59 INFO 140285796738880] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=1.09289491177\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:01 INFO 140285796738880] Epoch[114] Batch[5] avg_epoch_loss=1.176621\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:01 INFO 140285796738880] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=1.17662070195\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:01 INFO 140285796738880] Epoch[114] Batch [5]#011Speed: 180.53 samples/sec#011loss=1.176621\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:02 INFO 140285796738880] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4042.354106903076, \"sum\": 4042.354106903076, \"min\": 4042.354106903076}}, \"EndTime\": 1601447402.719461, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447398.676562}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:02 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=152.38098761 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:02 INFO 140285796738880] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:02 INFO 140285796738880] #quality_metric: host=algo-1, epoch=114, train loss <loss>=1.15934081078\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:02 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:03 INFO 140285796738880] Epoch[115] Batch[0] avg_epoch_loss=1.099228\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:03 INFO 140285796738880] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=1.0992282629\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:05 INFO 140285796738880] Epoch[115] Batch[5] avg_epoch_loss=1.143105\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:05 INFO 140285796738880] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=1.14310537775\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:05 INFO 140285796738880] Epoch[115] Batch [5]#011Speed: 168.32 samples/sec#011loss=1.143105\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:06 INFO 140285796738880] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4223.273038864136, \"sum\": 4223.273038864136, \"min\": 4223.273038864136}}, \"EndTime\": 1601447406.943335, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447402.71956}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:06 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=147.984471972 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:06 INFO 140285796738880] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:06 INFO 140285796738880] #quality_metric: host=algo-1, epoch=115, train loss <loss>=1.13296814561\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:06 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:07 INFO 140285796738880] Epoch[116] Batch[0] avg_epoch_loss=1.090609\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:07 INFO 140285796738880] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=1.09060931206\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:09 INFO 140285796738880] Epoch[116] Batch[5] avg_epoch_loss=1.096844\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:09 INFO 140285796738880] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=1.09684443474\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:09 INFO 140285796738880] Epoch[116] Batch [5]#011Speed: 171.49 samples/sec#011loss=1.096844\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:11 INFO 140285796738880] Epoch[116] Batch[10] avg_epoch_loss=1.088941\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:11 INFO 140285796738880] #quality_metric: host=algo-1, epoch=116, batch=10 train loss <loss>=1.07945642471\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:11 INFO 140285796738880] Epoch[116] Batch [10]#011Speed: 181.84 samples/sec#011loss=1.079456\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:11 INFO 140285796738880] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4504.9920082092285, \"sum\": 4504.9920082092285, \"min\": 4504.9920082092285}}, \"EndTime\": 1601447411.448932, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447406.943431}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:11 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=145.16790176 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:11 INFO 140285796738880] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:11 INFO 140285796738880] #quality_metric: host=algo-1, epoch=116, train loss <loss>=1.08894079382\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:11 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:12 INFO 140285796738880] Epoch[117] Batch[0] avg_epoch_loss=1.195651\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:12 INFO 140285796738880] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=1.19565057755\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:14 INFO 140285796738880] Epoch[117] Batch[5] avg_epoch_loss=1.166160\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:14 INFO 140285796738880] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=1.16616006692\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:14 INFO 140285796738880] Epoch[117] Batch [5]#011Speed: 158.05 samples/sec#011loss=1.166160\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:16 INFO 140285796738880] Epoch[117] Batch[10] avg_epoch_loss=1.149630\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:16 INFO 140285796738880] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=1.12979425192\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:16 INFO 140285796738880] Epoch[117] Batch [10]#011Speed: 181.06 samples/sec#011loss=1.129794\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:16 INFO 140285796738880] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4648.330211639404, \"sum\": 4648.330211639404, \"min\": 4648.330211639404}}, \"EndTime\": 1601447416.097823, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447411.449026}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:16 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=143.703354067 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:16 INFO 140285796738880] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:16 INFO 140285796738880] #quality_metric: host=algo-1, epoch=117, train loss <loss>=1.14963015101\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:16 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:16 INFO 140285796738880] Epoch[118] Batch[0] avg_epoch_loss=0.929313\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:16 INFO 140285796738880] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=0.929312586784\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:18 INFO 140285796738880] Epoch[118] Batch[5] avg_epoch_loss=1.075857\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:18 INFO 140285796738880] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=1.07585736116\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:18 INFO 140285796738880] Epoch[118] Batch [5]#011Speed: 179.18 samples/sec#011loss=1.075857\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:20 INFO 140285796738880] processed a total of 586 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4041.285991668701, \"sum\": 4041.285991668701, \"min\": 4041.285991668701}}, \"EndTime\": 1601447420.139671, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447416.097913}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:20 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=144.998104477 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:20 INFO 140285796738880] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:20 INFO 140285796738880] #quality_metric: host=algo-1, epoch=118, train loss <loss>=1.21425144672\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:20 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:21 INFO 140285796738880] Epoch[119] Batch[0] avg_epoch_loss=0.849096\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:21 INFO 140285796738880] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=0.84909594059\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:22 INFO 140285796738880] Epoch[119] Batch[5] avg_epoch_loss=1.077693\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:22 INFO 140285796738880] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=1.07769315441\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:22 INFO 140285796738880] Epoch[119] Batch [5]#011Speed: 181.27 samples/sec#011loss=1.077693\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:24 INFO 140285796738880] Epoch[119] Batch[10] avg_epoch_loss=1.054874\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:24 INFO 140285796738880] #quality_metric: host=algo-1, epoch=119, batch=10 train loss <loss>=1.02749158144\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:24 INFO 140285796738880] Epoch[119] Batch [10]#011Speed: 179.51 samples/sec#011loss=1.027492\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:24 INFO 140285796738880] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4413.323163986206, \"sum\": 4413.323163986206, \"min\": 4413.323163986206}}, \"EndTime\": 1601447424.553615, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447420.139772}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:24 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=148.636321225 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:24 INFO 140285796738880] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:24 INFO 140285796738880] #quality_metric: host=algo-1, epoch=119, train loss <loss>=1.05487425761\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:24 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:24 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_3b1df5ed-6695-4bf0-9fce-961c5521f25a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 172.0120906829834, \"sum\": 172.0120906829834, \"min\": 172.0120906829834}}, \"EndTime\": 1601447424.72627, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447424.553705}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:25 INFO 140285796738880] Epoch[120] Batch[0] avg_epoch_loss=1.180782\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:25 INFO 140285796738880] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=1.1807820797\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:27 INFO 140285796738880] Epoch[120] Batch[5] avg_epoch_loss=1.092009\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:27 INFO 140285796738880] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=1.0920090874\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:27 INFO 140285796738880] Epoch[120] Batch [5]#011Speed: 181.97 samples/sec#011loss=1.092009\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:28 INFO 140285796738880] processed a total of 600 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4000.1370906829834, \"sum\": 4000.1370906829834, \"min\": 4000.1370906829834}}, \"EndTime\": 1601447428.726574, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447424.726358}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:28 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=149.989423902 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:28 INFO 140285796738880] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:28 INFO 140285796738880] #quality_metric: host=algo-1, epoch=120, train loss <loss>=1.11019800305\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:28 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:29 INFO 140285796738880] Epoch[121] Batch[0] avg_epoch_loss=1.335240\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:29 INFO 140285796738880] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=1.33523976803\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:31 INFO 140285796738880] Epoch[121] Batch[5] avg_epoch_loss=1.145721\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:31 INFO 140285796738880] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=1.14572064082\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:31 INFO 140285796738880] Epoch[121] Batch [5]#011Speed: 179.96 samples/sec#011loss=1.145721\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:32 INFO 140285796738880] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4068.7501430511475, \"sum\": 4068.7501430511475, \"min\": 4068.7501430511475}}, \"EndTime\": 1601447432.795972, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447428.726672}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:32 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=156.063367029 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:32 INFO 140285796738880] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:32 INFO 140285796738880] #quality_metric: host=algo-1, epoch=121, train loss <loss>=1.13308737278\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:32 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:33 INFO 140285796738880] Epoch[122] Batch[0] avg_epoch_loss=1.183943\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:33 INFO 140285796738880] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=1.18394255638\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:35 INFO 140285796738880] Epoch[122] Batch[5] avg_epoch_loss=1.054652\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:35 INFO 140285796738880] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=1.05465166767\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:35 INFO 140285796738880] Epoch[122] Batch [5]#011Speed: 178.39 samples/sec#011loss=1.054652\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:36 INFO 140285796738880] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4016.724109649658, \"sum\": 4016.724109649658, \"min\": 4016.724109649658}}, \"EndTime\": 1601447436.813297, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447432.796045}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:36 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=156.838616415 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:36 INFO 140285796738880] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:36 INFO 140285796738880] #quality_metric: host=algo-1, epoch=122, train loss <loss>=1.0806753099\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:36 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:37 INFO 140285796738880] Epoch[123] Batch[0] avg_epoch_loss=0.909379\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:37 INFO 140285796738880] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=0.909379422665\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:39 INFO 140285796738880] Epoch[123] Batch[5] avg_epoch_loss=1.061112\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:39 INFO 140285796738880] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=1.06111247341\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:39 INFO 140285796738880] Epoch[123] Batch [5]#011Speed: 179.44 samples/sec#011loss=1.061112\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:40 INFO 140285796738880] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4008.896827697754, \"sum\": 4008.896827697754, \"min\": 4008.896827697754}}, \"EndTime\": 1601447440.822811, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447436.813396}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:40 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=152.156204141 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:40 INFO 140285796738880] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:40 INFO 140285796738880] #quality_metric: host=algo-1, epoch=123, train loss <loss>=1.06095839143\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:40 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:41 INFO 140285796738880] Epoch[124] Batch[0] avg_epoch_loss=1.042997\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:41 INFO 140285796738880] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=1.04299712181\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:43 INFO 140285796738880] Epoch[124] Batch[5] avg_epoch_loss=1.098686\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:43 INFO 140285796738880] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=1.0986863176\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:43 INFO 140285796738880] Epoch[124] Batch [5]#011Speed: 181.72 samples/sec#011loss=1.098686\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:44 INFO 140285796738880] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4004.0690898895264, \"sum\": 4004.0690898895264, \"min\": 4004.0690898895264}}, \"EndTime\": 1601447444.827533, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447440.822907}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:44 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=158.333241202 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:44 INFO 140285796738880] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:44 INFO 140285796738880] #quality_metric: host=algo-1, epoch=124, train loss <loss>=1.0934302032\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:44 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:45 INFO 140285796738880] Epoch[125] Batch[0] avg_epoch_loss=1.132582\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:45 INFO 140285796738880] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=1.13258183002\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:47 INFO 140285796738880] Epoch[125] Batch[5] avg_epoch_loss=1.205391\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:47 INFO 140285796738880] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=1.20539089044\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:47 INFO 140285796738880] Epoch[125] Batch [5]#011Speed: 182.71 samples/sec#011loss=1.205391\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:49 INFO 140285796738880] Epoch[125] Batch[10] avg_epoch_loss=1.102444\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:49 INFO 140285796738880] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=0.978908360004\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:49 INFO 140285796738880] Epoch[125] Batch [10]#011Speed: 180.75 samples/sec#011loss=0.978908\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:49 INFO 140285796738880] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4345.212936401367, \"sum\": 4345.212936401367, \"min\": 4345.212936401367}}, \"EndTime\": 1601447449.173365, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447444.827631}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:49 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=152.117021748 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:49 INFO 140285796738880] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:49 INFO 140285796738880] #quality_metric: host=algo-1, epoch=125, train loss <loss>=1.1024442857\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:49 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:49 INFO 140285796738880] Epoch[126] Batch[0] avg_epoch_loss=1.345464\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:49 INFO 140285796738880] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=1.34546434879\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:51 INFO 140285796738880] Epoch[126] Batch[5] avg_epoch_loss=1.080199\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:51 INFO 140285796738880] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=1.08019883434\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:51 INFO 140285796738880] Epoch[126] Batch [5]#011Speed: 179.93 samples/sec#011loss=1.080199\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:53 INFO 140285796738880] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4008.702039718628, \"sum\": 4008.702039718628, \"min\": 4008.702039718628}}, \"EndTime\": 1601447453.182629, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447449.173445}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:53 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=159.647973946 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:53 INFO 140285796738880] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:53 INFO 140285796738880] #quality_metric: host=algo-1, epoch=126, train loss <loss>=1.05041180253\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:53 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:53 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_a913d751-6f62-4d7e-beaa-f5705e9304a3-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 106.80317878723145, \"sum\": 106.80317878723145, \"min\": 106.80317878723145}}, \"EndTime\": 1601447453.290086, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447453.182701}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:54 INFO 140285796738880] Epoch[127] Batch[0] avg_epoch_loss=0.976844\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:54 INFO 140285796738880] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=0.976843774319\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:55 INFO 140285796738880] Epoch[127] Batch[5] avg_epoch_loss=1.038987\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:55 INFO 140285796738880] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=1.03898690144\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:55 INFO 140285796738880] Epoch[127] Batch [5]#011Speed: 179.87 samples/sec#011loss=1.038987\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:57 INFO 140285796738880] Epoch[127] Batch[10] avg_epoch_loss=1.027090\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:57 INFO 140285796738880] #quality_metric: host=algo-1, epoch=127, batch=10 train loss <loss>=1.01281275749\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:57 INFO 140285796738880] Epoch[127] Batch [10]#011Speed: 178.46 samples/sec#011loss=1.012813\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:57 INFO 140285796738880] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4395.508050918579, \"sum\": 4395.508050918579, \"min\": 4395.508050918579}}, \"EndTime\": 1601447457.685752, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447453.290168}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:57 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=150.14881991 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:57 INFO 140285796738880] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:57 INFO 140285796738880] #quality_metric: host=algo-1, epoch=127, train loss <loss>=1.02708956328\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:57 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:57 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_ea409f34-c825-4c27-adc6-a728b8044542-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 107.99312591552734, \"sum\": 107.99312591552734, \"min\": 107.99312591552734}}, \"EndTime\": 1601447457.79433, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447457.685836}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:58 INFO 140285796738880] Epoch[128] Batch[0] avg_epoch_loss=1.024086\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:30:58 INFO 140285796738880] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=1.02408611774\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:00 INFO 140285796738880] Epoch[128] Batch[5] avg_epoch_loss=1.065892\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:00 INFO 140285796738880] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=1.0658924977\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:00 INFO 140285796738880] Epoch[128] Batch [5]#011Speed: 174.19 samples/sec#011loss=1.065892\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:02 INFO 140285796738880] Epoch[128] Batch[10] avg_epoch_loss=1.173524\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:02 INFO 140285796738880] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=1.30268093348\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:02 INFO 140285796738880] Epoch[128] Batch [10]#011Speed: 175.75 samples/sec#011loss=1.302681\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:02 INFO 140285796738880] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4476.729154586792, \"sum\": 4476.729154586792, \"min\": 4476.729154586792}}, \"EndTime\": 1601447462.271234, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447457.794423}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:02 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=146.754643476 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:02 INFO 140285796738880] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:02 INFO 140285796738880] #quality_metric: host=algo-1, epoch=128, train loss <loss>=1.17352360487\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:02 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:03 INFO 140285796738880] Epoch[129] Batch[0] avg_epoch_loss=0.915503\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:03 INFO 140285796738880] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=0.915502607822\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:04 INFO 140285796738880] Epoch[129] Batch[5] avg_epoch_loss=1.050520\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:04 INFO 140285796738880] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=1.05051959554\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:04 INFO 140285796738880] Epoch[129] Batch [5]#011Speed: 179.43 samples/sec#011loss=1.050520\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:06 INFO 140285796738880] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4006.270170211792, \"sum\": 4006.270170211792, \"min\": 4006.270170211792}}, \"EndTime\": 1601447466.278019, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447462.27132}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:06 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=154.753128723 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:06 INFO 140285796738880] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:06 INFO 140285796738880] #quality_metric: host=algo-1, epoch=129, train loss <loss>=1.00901166797\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:06 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:06 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_48cac57c-efc8-463d-b74f-8bc226078877-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 107.89084434509277, \"sum\": 107.89084434509277, \"min\": 107.89084434509277}}, \"EndTime\": 1601447466.386589, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447466.278092}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:07 INFO 140285796738880] Epoch[130] Batch[0] avg_epoch_loss=1.120415\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:07 INFO 140285796738880] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=1.12041497231\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:08 INFO 140285796738880] Epoch[130] Batch[5] avg_epoch_loss=1.068348\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:08 INFO 140285796738880] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=1.0683478415\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:08 INFO 140285796738880] Epoch[130] Batch [5]#011Speed: 180.05 samples/sec#011loss=1.068348\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:10 INFO 140285796738880] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4006.726026535034, \"sum\": 4006.726026535034, \"min\": 4006.726026535034}}, \"EndTime\": 1601447470.393473, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447466.386672}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:10 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=152.488862663 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:10 INFO 140285796738880] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:10 INFO 140285796738880] #quality_metric: host=algo-1, epoch=130, train loss <loss>=1.09120716453\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:10 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:11 INFO 140285796738880] Epoch[131] Batch[0] avg_epoch_loss=1.046731\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:11 INFO 140285796738880] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=1.0467312336\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:12 INFO 140285796738880] Epoch[131] Batch[5] avg_epoch_loss=1.060607\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:12 INFO 140285796738880] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=1.06060715516\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:12 INFO 140285796738880] Epoch[131] Batch [5]#011Speed: 179.72 samples/sec#011loss=1.060607\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:14 INFO 140285796738880] Epoch[131] Batch[10] avg_epoch_loss=1.083723\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:14 INFO 140285796738880] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=1.11146221161\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:14 INFO 140285796738880] Epoch[131] Batch [10]#011Speed: 178.60 samples/sec#011loss=1.111462\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:14 INFO 140285796738880] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4387.9711627960205, \"sum\": 4387.9711627960205, \"min\": 4387.9711627960205}}, \"EndTime\": 1601447474.78208, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447470.393549}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:14 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=149.723898853 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:14 INFO 140285796738880] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:14 INFO 140285796738880] #quality_metric: host=algo-1, epoch=131, train loss <loss>=1.08372308991\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:14 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:15 INFO 140285796738880] Epoch[132] Batch[0] avg_epoch_loss=1.077290\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:15 INFO 140285796738880] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=1.07728993893\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:17 INFO 140285796738880] Epoch[132] Batch[5] avg_epoch_loss=1.082091\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:17 INFO 140285796738880] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=1.08209091425\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:17 INFO 140285796738880] Epoch[132] Batch [5]#011Speed: 179.86 samples/sec#011loss=1.082091\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:18 INFO 140285796738880] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4017.1918869018555, \"sum\": 4017.1918869018555, \"min\": 4017.1918869018555}}, \"EndTime\": 1601447478.79985, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447474.782148}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:18 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=154.579889099 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:18 INFO 140285796738880] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:18 INFO 140285796738880] #quality_metric: host=algo-1, epoch=132, train loss <loss>=1.1266731739\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:18 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:19 INFO 140285796738880] Epoch[133] Batch[0] avg_epoch_loss=1.197034\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:19 INFO 140285796738880] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=1.19703423977\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:21 INFO 140285796738880] Epoch[133] Batch[5] avg_epoch_loss=1.051701\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:21 INFO 140285796738880] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=1.05170120796\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:21 INFO 140285796738880] Epoch[133] Batch [5]#011Speed: 180.98 samples/sec#011loss=1.051701\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:22 INFO 140285796738880] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4004.776954650879, \"sum\": 4004.776954650879, \"min\": 4004.776954650879}}, \"EndTime\": 1601447482.805328, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447478.799948}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:22 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=154.559808299 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:22 INFO 140285796738880] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:22 INFO 140285796738880] #quality_metric: host=algo-1, epoch=133, train loss <loss>=1.01181694865\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:22 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:23 INFO 140285796738880] Epoch[134] Batch[0] avg_epoch_loss=1.066399\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:23 INFO 140285796738880] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=1.06639897823\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:25 INFO 140285796738880] Epoch[134] Batch[5] avg_epoch_loss=1.184363\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:25 INFO 140285796738880] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=1.18436288834\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:25 INFO 140285796738880] Epoch[134] Batch [5]#011Speed: 181.52 samples/sec#011loss=1.184363\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:26 INFO 140285796738880] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3989.8669719696045, \"sum\": 3989.8669719696045, \"min\": 3989.8669719696045}}, \"EndTime\": 1601447486.795821, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447482.805425}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:26 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=155.638511471 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:26 INFO 140285796738880] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:26 INFO 140285796738880] #quality_metric: host=algo-1, epoch=134, train loss <loss>=1.1213346839\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:26 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:27 INFO 140285796738880] Epoch[135] Batch[0] avg_epoch_loss=1.148537\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:27 INFO 140285796738880] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=1.14853668213\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:29 INFO 140285796738880] Epoch[135] Batch[5] avg_epoch_loss=1.024294\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:29 INFO 140285796738880] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=1.02429410815\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:29 INFO 140285796738880] Epoch[135] Batch [5]#011Speed: 174.34 samples/sec#011loss=1.024294\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:31 INFO 140285796738880] Epoch[135] Batch[10] avg_epoch_loss=1.054924\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:31 INFO 140285796738880] #quality_metric: host=algo-1, epoch=135, batch=10 train loss <loss>=1.09167921543\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:31 INFO 140285796738880] Epoch[135] Batch [10]#011Speed: 181.28 samples/sec#011loss=1.091679\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:31 INFO 140285796738880] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4449.909925460815, \"sum\": 4449.909925460815, \"min\": 4449.909925460815}}, \"EndTime\": 1601447491.246362, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447486.795923}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:31 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=147.86377266 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:31 INFO 140285796738880] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:31 INFO 140285796738880] #quality_metric: host=algo-1, epoch=135, train loss <loss>=1.05492370237\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:31 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:32 INFO 140285796738880] Epoch[136] Batch[0] avg_epoch_loss=0.940275\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:32 INFO 140285796738880] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=0.94027453661\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:33 INFO 140285796738880] Epoch[136] Batch[5] avg_epoch_loss=1.073407\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:33 INFO 140285796738880] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=1.07340673606\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:33 INFO 140285796738880] Epoch[136] Batch [5]#011Speed: 174.81 samples/sec#011loss=1.073407\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:35 INFO 140285796738880] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4103.565216064453, \"sum\": 4103.565216064453, \"min\": 4103.565216064453}}, \"EndTime\": 1601447495.35047, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447491.246451}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:35 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=155.713519826 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:35 INFO 140285796738880] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:35 INFO 140285796738880] #quality_metric: host=algo-1, epoch=136, train loss <loss>=1.07692630291\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:35 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:36 INFO 140285796738880] Epoch[137] Batch[0] avg_epoch_loss=1.124957\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:36 INFO 140285796738880] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=1.12495732307\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:37 INFO 140285796738880] Epoch[137] Batch[5] avg_epoch_loss=1.132801\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:37 INFO 140285796738880] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=1.13280070821\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:37 INFO 140285796738880] Epoch[137] Batch [5]#011Speed: 179.36 samples/sec#011loss=1.132801\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:39 INFO 140285796738880] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4031.2159061431885, \"sum\": 4031.2159061431885, \"min\": 4031.2159061431885}}, \"EndTime\": 1601447499.382371, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447495.350547}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:39 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=151.56183089 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:39 INFO 140285796738880] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:39 INFO 140285796738880] #quality_metric: host=algo-1, epoch=137, train loss <loss>=1.2875657022\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:39 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:40 INFO 140285796738880] Epoch[138] Batch[0] avg_epoch_loss=0.961514\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:40 INFO 140285796738880] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=0.961514472961\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:41 INFO 140285796738880] Epoch[138] Batch[5] avg_epoch_loss=1.179447\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:41 INFO 140285796738880] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=1.17944731315\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:41 INFO 140285796738880] Epoch[138] Batch [5]#011Speed: 181.78 samples/sec#011loss=1.179447\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:43 INFO 140285796738880] Epoch[138] Batch[10] avg_epoch_loss=1.172494\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:43 INFO 140285796738880] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=1.16414904594\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:43 INFO 140285796738880] Epoch[138] Batch [10]#011Speed: 182.12 samples/sec#011loss=1.164149\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:43 INFO 140285796738880] processed a total of 684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4363.593816757202, \"sum\": 4363.593816757202, \"min\": 4363.593816757202}}, \"EndTime\": 1601447503.746578, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447499.382467}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:43 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=156.746740908 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:43 INFO 140285796738880] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:43 INFO 140285796738880] #quality_metric: host=algo-1, epoch=138, train loss <loss>=1.17249355533\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:43 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:44 INFO 140285796738880] Epoch[139] Batch[0] avg_epoch_loss=1.159989\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:44 INFO 140285796738880] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=1.15998876095\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:46 INFO 140285796738880] Epoch[139] Batch[5] avg_epoch_loss=1.073602\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:46 INFO 140285796738880] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=1.07360223929\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:46 INFO 140285796738880] Epoch[139] Batch [5]#011Speed: 182.82 samples/sec#011loss=1.073602\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:48 INFO 140285796738880] Epoch[139] Batch[10] avg_epoch_loss=1.088113\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:48 INFO 140285796738880] #quality_metric: host=algo-1, epoch=139, batch=10 train loss <loss>=1.10552617311\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:48 INFO 140285796738880] Epoch[139] Batch [10]#011Speed: 180.71 samples/sec#011loss=1.105526\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:48 INFO 140285796738880] processed a total of 682 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4373.669862747192, \"sum\": 4373.669862747192, \"min\": 4373.669862747192}}, \"EndTime\": 1601447508.120825, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447503.746668}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:48 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=155.928413842 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:48 INFO 140285796738880] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:48 INFO 140285796738880] #quality_metric: host=algo-1, epoch=139, train loss <loss>=1.0881131183\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:48 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:48 INFO 140285796738880] Epoch[140] Batch[0] avg_epoch_loss=1.090994\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:48 INFO 140285796738880] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=1.09099411964\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:50 INFO 140285796738880] Epoch[140] Batch[5] avg_epoch_loss=1.095204\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:50 INFO 140285796738880] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=1.09520375729\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:50 INFO 140285796738880] Epoch[140] Batch [5]#011Speed: 180.86 samples/sec#011loss=1.095204\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:52 INFO 140285796738880] Epoch[140] Batch[10] avg_epoch_loss=1.145842\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:52 INFO 140285796738880] #quality_metric: host=algo-1, epoch=140, batch=10 train loss <loss>=1.20660877228\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:52 INFO 140285796738880] Epoch[140] Batch [10]#011Speed: 181.17 samples/sec#011loss=1.206609\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:52 INFO 140285796738880] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4378.753900527954, \"sum\": 4378.753900527954, \"min\": 4378.753900527954}}, \"EndTime\": 1601447512.50014, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447508.120914}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:52 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=149.124516073 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:52 INFO 140285796738880] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:52 INFO 140285796738880] #quality_metric: host=algo-1, epoch=140, train loss <loss>=1.14584240046\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:52 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:53 INFO 140285796738880] Epoch[141] Batch[0] avg_epoch_loss=1.069225\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:53 INFO 140285796738880] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=1.06922519207\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:55 INFO 140285796738880] Epoch[141] Batch[5] avg_epoch_loss=1.062811\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:55 INFO 140285796738880] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=1.06281146407\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:55 INFO 140285796738880] Epoch[141] Batch [5]#011Speed: 180.87 samples/sec#011loss=1.062811\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:56 INFO 140285796738880] Epoch[141] Batch[10] avg_epoch_loss=1.025351\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:56 INFO 140285796738880] #quality_metric: host=algo-1, epoch=141, batch=10 train loss <loss>=0.980397474766\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:56 INFO 140285796738880] Epoch[141] Batch [10]#011Speed: 182.14 samples/sec#011loss=0.980397\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:56 INFO 140285796738880] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4375.661134719849, \"sum\": 4375.661134719849, \"min\": 4375.661134719849}}, \"EndTime\": 1601447516.876396, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447512.500232}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:56 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=155.400404699 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:56 INFO 140285796738880] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:56 INFO 140285796738880] #quality_metric: host=algo-1, epoch=141, train loss <loss>=1.02535055984\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:56 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:57 INFO 140285796738880] Epoch[142] Batch[0] avg_epoch_loss=1.147084\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:57 INFO 140285796738880] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=1.14708423615\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:59 INFO 140285796738880] Epoch[142] Batch[5] avg_epoch_loss=1.184087\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:59 INFO 140285796738880] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=1.18408725659\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:31:59 INFO 140285796738880] Epoch[142] Batch [5]#011Speed: 174.16 samples/sec#011loss=1.184087\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:00 INFO 140285796738880] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4117.048978805542, \"sum\": 4117.048978805542, \"min\": 4117.048978805542}}, \"EndTime\": 1601447520.993997, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447516.876486}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:00 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=149.617192143 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:00 INFO 140285796738880] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:00 INFO 140285796738880] #quality_metric: host=algo-1, epoch=142, train loss <loss>=1.14156447649\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:00 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:01 INFO 140285796738880] Epoch[143] Batch[0] avg_epoch_loss=1.048921\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:01 INFO 140285796738880] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=1.04892075062\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:03 INFO 140285796738880] Epoch[143] Batch[5] avg_epoch_loss=1.087321\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:03 INFO 140285796738880] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=1.08732066552\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:03 INFO 140285796738880] Epoch[143] Batch [5]#011Speed: 180.08 samples/sec#011loss=1.087321\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:05 INFO 140285796738880] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4021.312952041626, \"sum\": 4021.312952041626, \"min\": 4021.312952041626}}, \"EndTime\": 1601447525.015943, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447520.994077}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:05 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=157.654416758 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:05 INFO 140285796738880] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:05 INFO 140285796738880] #quality_metric: host=algo-1, epoch=143, train loss <loss>=1.08822332621\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:05 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:05 INFO 140285796738880] Epoch[144] Batch[0] avg_epoch_loss=0.927795\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:05 INFO 140285796738880] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=0.927794516087\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:07 INFO 140285796738880] Epoch[144] Batch[5] avg_epoch_loss=0.998975\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:07 INFO 140285796738880] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=0.998974601428\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:07 INFO 140285796738880] Epoch[144] Batch [5]#011Speed: 181.48 samples/sec#011loss=0.998975\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:09 INFO 140285796738880] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3990.7569885253906, \"sum\": 3990.7569885253906, \"min\": 3990.7569885253906}}, \"EndTime\": 1601447529.007355, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447525.016039}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:09 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=160.364828394 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:09 INFO 140285796738880] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:09 INFO 140285796738880] #quality_metric: host=algo-1, epoch=144, train loss <loss>=1.02034559846\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:09 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:09 INFO 140285796738880] Epoch[145] Batch[0] avg_epoch_loss=1.121497\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:09 INFO 140285796738880] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=1.1214966774\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:11 INFO 140285796738880] Epoch[145] Batch[5] avg_epoch_loss=1.060813\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:11 INFO 140285796738880] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=1.06081272165\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:11 INFO 140285796738880] Epoch[145] Batch [5]#011Speed: 181.71 samples/sec#011loss=1.060813\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:13 INFO 140285796738880] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4013.260841369629, \"sum\": 4013.260841369629, \"min\": 4013.260841369629}}, \"EndTime\": 1601447533.021216, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447529.007454}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:13 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=157.97063523 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:13 INFO 140285796738880] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:13 INFO 140285796738880] #quality_metric: host=algo-1, epoch=145, train loss <loss>=1.03993768692\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:13 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:13 INFO 140285796738880] Epoch[146] Batch[0] avg_epoch_loss=1.159983\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:13 INFO 140285796738880] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=1.1599830389\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:15 INFO 140285796738880] Epoch[146] Batch[5] avg_epoch_loss=0.983664\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:15 INFO 140285796738880] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=0.983663787444\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:15 INFO 140285796738880] Epoch[146] Batch [5]#011Speed: 177.23 samples/sec#011loss=0.983664\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:17 INFO 140285796738880] processed a total of 591 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4056.1230182647705, \"sum\": 4056.1230182647705, \"min\": 4056.1230182647705}}, \"EndTime\": 1601447537.077948, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447533.021313}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:17 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=145.700398602 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:17 INFO 140285796738880] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:17 INFO 140285796738880] #quality_metric: host=algo-1, epoch=146, train loss <loss>=0.915228042006\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:17 INFO 140285796738880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:17 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/state_99899e41-726a-45b2-a48b-d686a4d7b698-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 132.24196434020996, \"sum\": 132.24196434020996, \"min\": 132.24196434020996}}, \"EndTime\": 1601447537.210878, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447537.078046}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:18 INFO 140285796738880] Epoch[147] Batch[0] avg_epoch_loss=1.132580\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:18 INFO 140285796738880] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=1.1325802803\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:19 INFO 140285796738880] Epoch[147] Batch[5] avg_epoch_loss=1.130703\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:19 INFO 140285796738880] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=1.13070275386\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:19 INFO 140285796738880] Epoch[147] Batch [5]#011Speed: 178.91 samples/sec#011loss=1.130703\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:21 INFO 140285796738880] Epoch[147] Batch[10] avg_epoch_loss=1.090750\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:21 INFO 140285796738880] #quality_metric: host=algo-1, epoch=147, batch=10 train loss <loss>=1.04280669689\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:21 INFO 140285796738880] Epoch[147] Batch [10]#011Speed: 179.56 samples/sec#011loss=1.042807\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:21 INFO 140285796738880] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4397.2320556640625, \"sum\": 4397.2320556640625, \"min\": 4397.2320556640625}}, \"EndTime\": 1601447541.608305, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447537.210971}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:21 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=149.18075412 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:21 INFO 140285796738880] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:21 INFO 140285796738880] #quality_metric: host=algo-1, epoch=147, train loss <loss>=1.09075000069\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:21 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:22 INFO 140285796738880] Epoch[148] Batch[0] avg_epoch_loss=1.099431\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:22 INFO 140285796738880] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=1.09943127632\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:24 INFO 140285796738880] Epoch[148] Batch[5] avg_epoch_loss=1.069597\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:24 INFO 140285796738880] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=1.069597284\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:24 INFO 140285796738880] Epoch[148] Batch [5]#011Speed: 180.98 samples/sec#011loss=1.069597\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:25 INFO 140285796738880] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4009.6731185913086, \"sum\": 4009.6731185913086, \"min\": 4009.6731185913086}}, \"EndTime\": 1601447545.61858, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447541.60838}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:25 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=157.613135521 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:25 INFO 140285796738880] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:25 INFO 140285796738880] #quality_metric: host=algo-1, epoch=148, train loss <loss>=1.0580047965\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:25 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:26 INFO 140285796738880] Epoch[149] Batch[0] avg_epoch_loss=1.088717\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:26 INFO 140285796738880] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=1.0887169838\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:28 INFO 140285796738880] Epoch[149] Batch[5] avg_epoch_loss=1.095142\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:28 INFO 140285796738880] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=1.09514242411\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:28 INFO 140285796738880] Epoch[149] Batch [5]#011Speed: 178.65 samples/sec#011loss=1.095142\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:30 INFO 140285796738880] Epoch[149] Batch[10] avg_epoch_loss=1.077296\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:30 INFO 140285796738880] #quality_metric: host=algo-1, epoch=149, batch=10 train loss <loss>=1.0558812499\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:30 INFO 140285796738880] Epoch[149] Batch [10]#011Speed: 175.79 samples/sec#011loss=1.055881\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:30 INFO 140285796738880] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4496.055841445923, \"sum\": 4496.055841445923, \"min\": 4496.055841445923}}, \"EndTime\": 1601447550.115278, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447545.618678}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:30 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=142.787557876 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:30 INFO 140285796738880] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:30 INFO 140285796738880] #quality_metric: host=algo-1, epoch=149, train loss <loss>=1.07729643583\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:30 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:30 INFO 140285796738880] Epoch[150] Batch[0] avg_epoch_loss=1.385915\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:30 INFO 140285796738880] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=1.38591492176\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:32 INFO 140285796738880] Epoch[150] Batch[5] avg_epoch_loss=1.274863\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:32 INFO 140285796738880] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=1.27486328284\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:32 INFO 140285796738880] Epoch[150] Batch [5]#011Speed: 181.71 samples/sec#011loss=1.274863\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:33 INFO 140285796738880] processed a total of 557 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3665.019989013672, \"sum\": 3665.019989013672, \"min\": 3665.019989013672}}, \"EndTime\": 1601447553.78086, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447550.115368}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:33 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=151.971332253 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:33 INFO 140285796738880] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:33 INFO 140285796738880] #quality_metric: host=algo-1, epoch=150, train loss <loss>=1.35190852483\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:33 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:34 INFO 140285796738880] Epoch[151] Batch[0] avg_epoch_loss=1.244614\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:34 INFO 140285796738880] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=1.24461400509\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:36 INFO 140285796738880] Epoch[151] Batch[5] avg_epoch_loss=1.156348\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:36 INFO 140285796738880] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=1.15634806951\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:36 INFO 140285796738880] Epoch[151] Batch [5]#011Speed: 178.66 samples/sec#011loss=1.156348\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:38 INFO 140285796738880] Epoch[151] Batch[10] avg_epoch_loss=1.158609\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:38 INFO 140285796738880] #quality_metric: host=algo-1, epoch=151, batch=10 train loss <loss>=1.16132280827\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:38 INFO 140285796738880] Epoch[151] Batch [10]#011Speed: 181.59 samples/sec#011loss=1.161323\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:38 INFO 140285796738880] processed a total of 691 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4405.3449630737305, \"sum\": 4405.3449630737305, \"min\": 4405.3449630737305}}, \"EndTime\": 1601447558.186816, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447553.780958}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:38 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=156.850074191 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:38 INFO 140285796738880] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:38 INFO 140285796738880] #quality_metric: host=algo-1, epoch=151, train loss <loss>=1.1586093144\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:38 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:39 INFO 140285796738880] Epoch[152] Batch[0] avg_epoch_loss=1.007442\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:39 INFO 140285796738880] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=1.00744152069\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:40 INFO 140285796738880] Epoch[152] Batch[5] avg_epoch_loss=1.096902\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:40 INFO 140285796738880] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=1.09690192342\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:40 INFO 140285796738880] Epoch[152] Batch [5]#011Speed: 179.98 samples/sec#011loss=1.096902\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:42 INFO 140285796738880] Epoch[152] Batch[10] avg_epoch_loss=1.064343\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:42 INFO 140285796738880] #quality_metric: host=algo-1, epoch=152, batch=10 train loss <loss>=1.02527322769\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:42 INFO 140285796738880] Epoch[152] Batch [10]#011Speed: 181.89 samples/sec#011loss=1.025273\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:42 INFO 140285796738880] processed a total of 695 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4386.274099349976, \"sum\": 4386.274099349976, \"min\": 4386.274099349976}}, \"EndTime\": 1601447562.573677, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447558.186906}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:42 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=158.443998694 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:42 INFO 140285796738880] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:42 INFO 140285796738880] #quality_metric: host=algo-1, epoch=152, train loss <loss>=1.06434342536\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:42 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:43 INFO 140285796738880] Epoch[153] Batch[0] avg_epoch_loss=0.925913\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:43 INFO 140285796738880] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=0.925913095474\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:45 INFO 140285796738880] Epoch[153] Batch[5] avg_epoch_loss=1.030814\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:45 INFO 140285796738880] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=1.03081370393\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:45 INFO 140285796738880] Epoch[153] Batch [5]#011Speed: 180.57 samples/sec#011loss=1.030814\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:46 INFO 140285796738880] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4002.0079612731934, \"sum\": 4002.0079612731934, \"min\": 4002.0079612731934}}, \"EndTime\": 1601447566.576237, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447562.573767}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:46 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=155.666289969 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:46 INFO 140285796738880] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:46 INFO 140285796738880] #quality_metric: host=algo-1, epoch=153, train loss <loss>=1.09732971191\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:46 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:47 INFO 140285796738880] Epoch[154] Batch[0] avg_epoch_loss=1.139528\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:47 INFO 140285796738880] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=1.1395277977\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:49 INFO 140285796738880] Epoch[154] Batch[5] avg_epoch_loss=0.997586\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:49 INFO 140285796738880] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=0.997586290042\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:49 INFO 140285796738880] Epoch[154] Batch [5]#011Speed: 181.53 samples/sec#011loss=0.997586\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:50 INFO 140285796738880] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4018.9521312713623, \"sum\": 4018.9521312713623, \"min\": 4018.9521312713623}}, \"EndTime\": 1601447570.595822, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447566.576334}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:50 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=158.742168946 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:50 INFO 140285796738880] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:50 INFO 140285796738880] #quality_metric: host=algo-1, epoch=154, train loss <loss>=1.02505332232\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:50 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:51 INFO 140285796738880] Epoch[155] Batch[0] avg_epoch_loss=1.012086\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:51 INFO 140285796738880] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=1.01208567619\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:53 INFO 140285796738880] Epoch[155] Batch[5] avg_epoch_loss=1.070823\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:53 INFO 140285796738880] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=1.07082324227\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:53 INFO 140285796738880] Epoch[155] Batch [5]#011Speed: 179.56 samples/sec#011loss=1.070823\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:54 INFO 140285796738880] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4001.615047454834, \"sum\": 4001.615047454834, \"min\": 4001.615047454834}}, \"EndTime\": 1601447574.59804, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447570.59592}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:54 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=155.68188947 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:54 INFO 140285796738880] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:54 INFO 140285796738880] #quality_metric: host=algo-1, epoch=155, train loss <loss>=1.05345846415\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:54 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:55 INFO 140285796738880] Epoch[156] Batch[0] avg_epoch_loss=1.104367\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:55 INFO 140285796738880] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=1.10436749458\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:57 INFO 140285796738880] Epoch[156] Batch[5] avg_epoch_loss=1.086653\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:57 INFO 140285796738880] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=1.08665290475\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:57 INFO 140285796738880] Epoch[156] Batch [5]#011Speed: 181.72 samples/sec#011loss=1.086653\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:58 INFO 140285796738880] Epoch[156] Batch[10] avg_epoch_loss=1.015794\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:58 INFO 140285796738880] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=0.930762729049\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:58 INFO 140285796738880] Epoch[156] Batch [10]#011Speed: 181.18 samples/sec#011loss=0.930763\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:58 INFO 140285796738880] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4398.425102233887, \"sum\": 4398.425102233887, \"min\": 4398.425102233887}}, \"EndTime\": 1601447578.997054, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447574.598135}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:58 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=148.457683514 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:58 INFO 140285796738880] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:58 INFO 140285796738880] #quality_metric: host=algo-1, epoch=156, train loss <loss>=1.01579373398\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:58 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:59 INFO 140285796738880] Epoch[157] Batch[0] avg_epoch_loss=1.047126\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:32:59 INFO 140285796738880] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=1.04712569714\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:01 INFO 140285796738880] Epoch[157] Batch[5] avg_epoch_loss=1.140628\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:01 INFO 140285796738880] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=1.14062774181\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:01 INFO 140285796738880] Epoch[157] Batch [5]#011Speed: 176.32 samples/sec#011loss=1.140628\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:03 INFO 140285796738880] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4130.36322593689, \"sum\": 4130.36322593689, \"min\": 4130.36322593689}}, \"EndTime\": 1601447583.128064, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447578.997145}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:03 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=153.250138171 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:03 INFO 140285796738880] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:03 INFO 140285796738880] #quality_metric: host=algo-1, epoch=157, train loss <loss>=1.07388403416\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:03 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:03 INFO 140285796738880] Epoch[158] Batch[0] avg_epoch_loss=1.057393\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:03 INFO 140285796738880] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=1.05739307404\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:05 INFO 140285796738880] Epoch[158] Batch[5] avg_epoch_loss=1.009291\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:05 INFO 140285796738880] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=1.00929145018\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:05 INFO 140285796738880] Epoch[158] Batch [5]#011Speed: 172.99 samples/sec#011loss=1.009291\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:07 INFO 140285796738880] processed a total of 605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4146.339893341064, \"sum\": 4146.339893341064, \"min\": 4146.339893341064}}, \"EndTime\": 1601447587.275008, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447583.128159}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:07 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=145.906081374 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:07 INFO 140285796738880] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:07 INFO 140285796738880] #quality_metric: host=algo-1, epoch=158, train loss <loss>=0.9969414711\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:07 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:08 INFO 140285796738880] Epoch[159] Batch[0] avg_epoch_loss=0.891133\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:08 INFO 140285796738880] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=0.891132950783\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:09 INFO 140285796738880] Epoch[159] Batch[5] avg_epoch_loss=1.031365\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:09 INFO 140285796738880] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=1.03136458\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:09 INFO 140285796738880] Epoch[159] Batch [5]#011Speed: 182.24 samples/sec#011loss=1.031365\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:11 INFO 140285796738880] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4031.0537815093994, \"sum\": 4031.0537815093994, \"min\": 4031.0537815093994}}, \"EndTime\": 1601447591.306698, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447587.275105}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:11 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=152.063940103 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:11 INFO 140285796738880] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:11 INFO 140285796738880] #quality_metric: host=algo-1, epoch=159, train loss <loss>=1.07431001067\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:11 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:12 INFO 140285796738880] Epoch[160] Batch[0] avg_epoch_loss=1.140331\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:12 INFO 140285796738880] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=1.14033055305\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:13 INFO 140285796738880] Epoch[160] Batch[5] avg_epoch_loss=1.103186\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:13 INFO 140285796738880] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=1.10318562388\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:13 INFO 140285796738880] Epoch[160] Batch [5]#011Speed: 181.31 samples/sec#011loss=1.103186\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:15 INFO 140285796738880] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4098.152875900269, \"sum\": 4098.152875900269, \"min\": 4098.152875900269}}, \"EndTime\": 1601447595.405493, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447591.306797}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:15 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=150.795522046 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:15 INFO 140285796738880] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:15 INFO 140285796738880] #quality_metric: host=algo-1, epoch=160, train loss <loss>=1.0980715692\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:15 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:16 INFO 140285796738880] Epoch[161] Batch[0] avg_epoch_loss=1.167138\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:16 INFO 140285796738880] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=1.16713809967\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:18 INFO 140285796738880] Epoch[161] Batch[5] avg_epoch_loss=1.068634\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:18 INFO 140285796738880] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=1.06863371531\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:18 INFO 140285796738880] Epoch[161] Batch [5]#011Speed: 177.37 samples/sec#011loss=1.068634\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:19 INFO 140285796738880] Epoch[161] Batch[10] avg_epoch_loss=1.061316\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:19 INFO 140285796738880] #quality_metric: host=algo-1, epoch=161, batch=10 train loss <loss>=1.05253537893\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:19 INFO 140285796738880] Epoch[161] Batch [10]#011Speed: 181.87 samples/sec#011loss=1.052535\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:19 INFO 140285796738880] processed a total of 698 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4388.7269496917725, \"sum\": 4388.7269496917725, \"min\": 4388.7269496917725}}, \"EndTime\": 1601447599.794868, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447595.405567}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:19 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=159.039021984 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:19 INFO 140285796738880] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:19 INFO 140285796738880] #quality_metric: host=algo-1, epoch=161, train loss <loss>=1.06131628968\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:19 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:20 INFO 140285796738880] Epoch[162] Batch[0] avg_epoch_loss=1.020900\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:20 INFO 140285796738880] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=1.02089989185\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:22 INFO 140285796738880] Epoch[162] Batch[5] avg_epoch_loss=1.103106\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:22 INFO 140285796738880] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=1.1031062603\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:22 INFO 140285796738880] Epoch[162] Batch [5]#011Speed: 178.90 samples/sec#011loss=1.103106\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:23 INFO 140285796738880] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4081.645965576172, \"sum\": 4081.645965576172, \"min\": 4081.645965576172}}, \"EndTime\": 1601447603.877101, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447599.794957}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:23 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=154.589077832 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:23 INFO 140285796738880] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:23 INFO 140285796738880] #quality_metric: host=algo-1, epoch=162, train loss <loss>=1.04058642387\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:23 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:24 INFO 140285796738880] Epoch[163] Batch[0] avg_epoch_loss=1.234313\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:24 INFO 140285796738880] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=1.23431253433\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:26 INFO 140285796738880] Epoch[163] Batch[5] avg_epoch_loss=1.137338\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:26 INFO 140285796738880] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=1.13733780384\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:26 INFO 140285796738880] Epoch[163] Batch [5]#011Speed: 175.28 samples/sec#011loss=1.137338\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:27 INFO 140285796738880] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4120.68510055542, \"sum\": 4120.68510055542, \"min\": 4120.68510055542}}, \"EndTime\": 1601447607.998414, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447603.8772}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:27 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=153.609455558 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:27 INFO 140285796738880] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:27 INFO 140285796738880] #quality_metric: host=algo-1, epoch=163, train loss <loss>=1.08653622866\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:27 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:28 INFO 140285796738880] Epoch[164] Batch[0] avg_epoch_loss=1.159740\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:28 INFO 140285796738880] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=1.15974020958\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:30 INFO 140285796738880] Epoch[164] Batch[5] avg_epoch_loss=1.124955\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:30 INFO 140285796738880] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=1.12495521704\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:30 INFO 140285796738880] Epoch[164] Batch [5]#011Speed: 176.57 samples/sec#011loss=1.124955\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:32 INFO 140285796738880] Epoch[164] Batch[10] avg_epoch_loss=1.144574\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:32 INFO 140285796738880] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=1.1681173563\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:32 INFO 140285796738880] Epoch[164] Batch [10]#011Speed: 179.47 samples/sec#011loss=1.168117\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:32 INFO 140285796738880] processed a total of 698 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4460.179090499878, \"sum\": 4460.179090499878, \"min\": 4460.179090499878}}, \"EndTime\": 1601447612.459212, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447607.998509}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:32 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=156.490562536 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:32 INFO 140285796738880] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:32 INFO 140285796738880] #quality_metric: host=algo-1, epoch=164, train loss <loss>=1.14457437125\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:32 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:33 INFO 140285796738880] Epoch[165] Batch[0] avg_epoch_loss=0.873009\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:33 INFO 140285796738880] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=0.873009324074\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:35 INFO 140285796738880] Epoch[165] Batch[5] avg_epoch_loss=1.061018\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:35 INFO 140285796738880] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=1.06101810932\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:35 INFO 140285796738880] Epoch[165] Batch [5]#011Speed: 179.92 samples/sec#011loss=1.061018\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:36 INFO 140285796738880] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4033.5750579833984, \"sum\": 4033.5750579833984, \"min\": 4033.5750579833984}}, \"EndTime\": 1601447616.493335, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447612.459301}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:36 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=151.473045488 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:36 INFO 140285796738880] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:36 INFO 140285796738880] #quality_metric: host=algo-1, epoch=165, train loss <loss>=1.04461375475\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:36 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:37 INFO 140285796738880] Epoch[166] Batch[0] avg_epoch_loss=1.113651\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:37 INFO 140285796738880] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=1.11365127563\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:39 INFO 140285796738880] Epoch[166] Batch[5] avg_epoch_loss=1.087068\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:39 INFO 140285796738880] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=1.08706771334\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:39 INFO 140285796738880] Epoch[166] Batch [5]#011Speed: 179.82 samples/sec#011loss=1.087068\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:40 INFO 140285796738880] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4040.052890777588, \"sum\": 4040.052890777588, \"min\": 4040.052890777588}}, \"EndTime\": 1601447620.534054, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447616.493434}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:40 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=156.923082225 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:40 INFO 140285796738880] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:40 INFO 140285796738880] #quality_metric: host=algo-1, epoch=166, train loss <loss>=1.0914352715\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:40 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:41 INFO 140285796738880] Epoch[167] Batch[0] avg_epoch_loss=1.034011\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:41 INFO 140285796738880] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=1.03401064873\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:43 INFO 140285796738880] Epoch[167] Batch[5] avg_epoch_loss=1.084699\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:43 INFO 140285796738880] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=1.08469883601\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:43 INFO 140285796738880] Epoch[167] Batch [5]#011Speed: 180.64 samples/sec#011loss=1.084699\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:44 INFO 140285796738880] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4022.678852081299, \"sum\": 4022.678852081299, \"min\": 4022.678852081299}}, \"EndTime\": 1601447624.557339, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447620.53415}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:44 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=155.363687365 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:44 INFO 140285796738880] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:44 INFO 140285796738880] #quality_metric: host=algo-1, epoch=167, train loss <loss>=1.08500334024\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:44 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:45 INFO 140285796738880] Epoch[168] Batch[0] avg_epoch_loss=1.115118\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:45 INFO 140285796738880] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=1.11511766911\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:47 INFO 140285796738880] Epoch[168] Batch[5] avg_epoch_loss=1.070822\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:47 INFO 140285796738880] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=1.07082242767\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:47 INFO 140285796738880] Epoch[168] Batch [5]#011Speed: 180.51 samples/sec#011loss=1.070822\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:49 INFO 140285796738880] Epoch[168] Batch[10] avg_epoch_loss=0.990739\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:49 INFO 140285796738880] #quality_metric: host=algo-1, epoch=168, batch=10 train loss <loss>=0.894639098644\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:49 INFO 140285796738880] Epoch[168] Batch [10]#011Speed: 179.72 samples/sec#011loss=0.894639\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:49 INFO 140285796738880] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4444.212913513184, \"sum\": 4444.212913513184, \"min\": 4444.212913513184}}, \"EndTime\": 1601447629.002162, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447624.557435}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:49 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=150.528335859 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:49 INFO 140285796738880] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:49 INFO 140285796738880] #quality_metric: host=algo-1, epoch=168, train loss <loss>=0.990739096295\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:49 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:49 INFO 140285796738880] Epoch[169] Batch[0] avg_epoch_loss=0.989885\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:49 INFO 140285796738880] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=0.9898853302\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:51 INFO 140285796738880] Epoch[169] Batch[5] avg_epoch_loss=1.031644\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:51 INFO 140285796738880] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=1.0316444238\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:51 INFO 140285796738880] Epoch[169] Batch [5]#011Speed: 180.77 samples/sec#011loss=1.031644\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:53 INFO 140285796738880] Epoch[169] Batch[10] avg_epoch_loss=0.965312\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:53 INFO 140285796738880] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=0.885712662339\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:53 INFO 140285796738880] Epoch[169] Batch [10]#011Speed: 181.58 samples/sec#011loss=0.885713\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:53 INFO 140285796738880] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4382.066965103149, \"sum\": 4382.066965103149, \"min\": 4382.066965103149}}, \"EndTime\": 1601447633.384782, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447629.002252}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:53 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=148.783812988 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:53 INFO 140285796738880] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:53 INFO 140285796738880] #quality_metric: host=algo-1, epoch=169, train loss <loss>=0.965311804956\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:53 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:54 INFO 140285796738880] Epoch[170] Batch[0] avg_epoch_loss=1.003602\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:54 INFO 140285796738880] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=1.00360226631\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:56 INFO 140285796738880] Epoch[170] Batch[5] avg_epoch_loss=0.986430\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:56 INFO 140285796738880] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=0.986429780722\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:56 INFO 140285796738880] Epoch[170] Batch [5]#011Speed: 180.03 samples/sec#011loss=0.986430\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:57 INFO 140285796738880] Epoch[170] Batch[10] avg_epoch_loss=1.063001\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:57 INFO 140285796738880] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=1.15488743782\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:57 INFO 140285796738880] Epoch[170] Batch [10]#011Speed: 178.72 samples/sec#011loss=1.154887\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:57 INFO 140285796738880] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4427.120923995972, \"sum\": 4427.120923995972, \"min\": 4427.120923995972}}, \"EndTime\": 1601447637.81245, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447633.384869}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:57 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=147.495690288 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:57 INFO 140285796738880] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:57 INFO 140285796738880] #quality_metric: host=algo-1, epoch=170, train loss <loss>=1.06300144304\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:57 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:58 INFO 140285796738880] Epoch[171] Batch[0] avg_epoch_loss=0.849719\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:33:58 INFO 140285796738880] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=0.849719464779\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:00 INFO 140285796738880] Epoch[171] Batch[5] avg_epoch_loss=1.036741\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:00 INFO 140285796738880] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=1.03674094876\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:00 INFO 140285796738880] Epoch[171] Batch [5]#011Speed: 174.77 samples/sec#011loss=1.036741\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:01 INFO 140285796738880] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4086.6379737854004, \"sum\": 4086.6379737854004, \"min\": 4086.6379737854004}}, \"EndTime\": 1601447641.899671, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447637.812537}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:01 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=154.155411827 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:01 INFO 140285796738880] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:01 INFO 140285796738880] #quality_metric: host=algo-1, epoch=171, train loss <loss>=0.994146043062\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:01 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:02 INFO 140285796738880] Epoch[172] Batch[0] avg_epoch_loss=1.163975\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:02 INFO 140285796738880] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=1.16397535801\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:04 INFO 140285796738880] Epoch[172] Batch[5] avg_epoch_loss=1.043335\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:04 INFO 140285796738880] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=1.0433349212\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:04 INFO 140285796738880] Epoch[172] Batch [5]#011Speed: 178.63 samples/sec#011loss=1.043335\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:05 INFO 140285796738880] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4038.3238792419434, \"sum\": 4038.3238792419434, \"min\": 4038.3238792419434}}, \"EndTime\": 1601447645.938675, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447641.89977}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:05 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=154.266342302 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:05 INFO 140285796738880] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:05 INFO 140285796738880] #quality_metric: host=algo-1, epoch=172, train loss <loss>=1.05626969337\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:05 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:06 INFO 140285796738880] Epoch[173] Batch[0] avg_epoch_loss=1.007747\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:06 INFO 140285796738880] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=1.00774741173\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:08 INFO 140285796738880] Epoch[173] Batch[5] avg_epoch_loss=1.027758\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:08 INFO 140285796738880] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=1.02775806189\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:08 INFO 140285796738880] Epoch[173] Batch [5]#011Speed: 179.47 samples/sec#011loss=1.027758\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:09 INFO 140285796738880] processed a total of 594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4014.3020153045654, \"sum\": 4014.3020153045654, \"min\": 4014.3020153045654}}, \"EndTime\": 1601447649.953639, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447645.938774}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:09 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=147.965665352 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:09 INFO 140285796738880] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:09 INFO 140285796738880] #quality_metric: host=algo-1, epoch=173, train loss <loss>=1.01858640313\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:09 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:10 INFO 140285796738880] Epoch[174] Batch[0] avg_epoch_loss=1.106811\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:10 INFO 140285796738880] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=1.10681068897\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:12 INFO 140285796738880] Epoch[174] Batch[5] avg_epoch_loss=1.050044\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:12 INFO 140285796738880] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=1.05004379153\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:12 INFO 140285796738880] Epoch[174] Batch [5]#011Speed: 178.55 samples/sec#011loss=1.050044\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:14 INFO 140285796738880] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4064.677953720093, \"sum\": 4064.677953720093, \"min\": 4064.677953720093}}, \"EndTime\": 1601447654.019002, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447649.953738}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:14 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=154.249384605 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:14 INFO 140285796738880] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:14 INFO 140285796738880] #quality_metric: host=algo-1, epoch=174, train loss <loss>=1.01059756279\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:14 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:14 INFO 140285796738880] Epoch[175] Batch[0] avg_epoch_loss=1.208033\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:14 INFO 140285796738880] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=1.20803260803\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:16 INFO 140285796738880] Epoch[175] Batch[5] avg_epoch_loss=1.092666\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:16 INFO 140285796738880] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=1.09266571204\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:16 INFO 140285796738880] Epoch[175] Batch [5]#011Speed: 178.34 samples/sec#011loss=1.092666\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:18 INFO 140285796738880] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4031.2628746032715, \"sum\": 4031.2628746032715, \"min\": 4031.2628746032715}}, \"EndTime\": 1601447658.050879, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447654.019101}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:18 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=151.809356548 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:18 INFO 140285796738880] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:18 INFO 140285796738880] #quality_metric: host=algo-1, epoch=175, train loss <loss>=1.00221838951\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:18 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:18 INFO 140285796738880] Epoch[176] Batch[0] avg_epoch_loss=1.403354\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:18 INFO 140285796738880] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=1.40335381031\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:20 INFO 140285796738880] Epoch[176] Batch[5] avg_epoch_loss=1.104374\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:20 INFO 140285796738880] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=1.10437421004\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:20 INFO 140285796738880] Epoch[176] Batch [5]#011Speed: 178.86 samples/sec#011loss=1.104374\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:22 INFO 140285796738880] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4016.4670944213867, \"sum\": 4016.4670944213867, \"min\": 4016.4670944213867}}, \"EndTime\": 1601447662.067982, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447658.05095}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:22 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=153.612010664 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:22 INFO 140285796738880] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:22 INFO 140285796738880] #quality_metric: host=algo-1, epoch=176, train loss <loss>=1.12418904305\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:22 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:22 INFO 140285796738880] Epoch[177] Batch[0] avg_epoch_loss=1.163167\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:22 INFO 140285796738880] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=1.16316711903\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:24 INFO 140285796738880] Epoch[177] Batch[5] avg_epoch_loss=1.050494\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:24 INFO 140285796738880] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=1.05049426357\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:24 INFO 140285796738880] Epoch[177] Batch [5]#011Speed: 182.01 samples/sec#011loss=1.050494\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:26 INFO 140285796738880] Epoch[177] Batch[10] avg_epoch_loss=1.022427\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:26 INFO 140285796738880] #quality_metric: host=algo-1, epoch=177, batch=10 train loss <loss>=0.988746285439\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:26 INFO 140285796738880] Epoch[177] Batch [10]#011Speed: 180.28 samples/sec#011loss=0.988746\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:26 INFO 140285796738880] processed a total of 682 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4360.461950302124, \"sum\": 4360.461950302124, \"min\": 4360.461950302124}}, \"EndTime\": 1601447666.429103, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447662.068079}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:26 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=156.400606703 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:26 INFO 140285796738880] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:26 INFO 140285796738880] #quality_metric: host=algo-1, epoch=177, train loss <loss>=1.02242700078\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:26 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:27 INFO 140285796738880] Epoch[178] Batch[0] avg_epoch_loss=1.110255\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:27 INFO 140285796738880] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=1.11025547981\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:29 INFO 140285796738880] Epoch[178] Batch[5] avg_epoch_loss=1.055615\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:29 INFO 140285796738880] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=1.0556153059\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:29 INFO 140285796738880] Epoch[178] Batch [5]#011Speed: 178.18 samples/sec#011loss=1.055615\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:30 INFO 140285796738880] Epoch[178] Batch[10] avg_epoch_loss=0.965580\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:30 INFO 140285796738880] #quality_metric: host=algo-1, epoch=178, batch=10 train loss <loss>=0.857537323236\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:30 INFO 140285796738880] Epoch[178] Batch [10]#011Speed: 177.28 samples/sec#011loss=0.857537\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:30 INFO 140285796738880] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4451.184034347534, \"sum\": 4451.184034347534, \"min\": 4451.184034347534}}, \"EndTime\": 1601447670.880852, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447666.429194}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:30 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=147.372017712 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:30 INFO 140285796738880] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:30 INFO 140285796738880] #quality_metric: host=algo-1, epoch=178, train loss <loss>=0.965579859235\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:30 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:31 INFO 140285796738880] Epoch[179] Batch[0] avg_epoch_loss=1.148512\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:31 INFO 140285796738880] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=1.14851212502\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:33 INFO 140285796738880] Epoch[179] Batch[5] avg_epoch_loss=1.081266\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:33 INFO 140285796738880] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=1.08126562834\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:33 INFO 140285796738880] Epoch[179] Batch [5]#011Speed: 180.05 samples/sec#011loss=1.081266\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:34 INFO 140285796738880] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4029.3140411376953, \"sum\": 4029.3140411376953, \"min\": 4029.3140411376953}}, \"EndTime\": 1601447674.910742, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447670.880944}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:34 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=156.100313707 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:34 INFO 140285796738880] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:34 INFO 140285796738880] #quality_metric: host=algo-1, epoch=179, train loss <loss>=1.06990204453\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:34 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:35 INFO 140285796738880] Epoch[180] Batch[0] avg_epoch_loss=1.107671\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:35 INFO 140285796738880] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=1.10767102242\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:37 INFO 140285796738880] Epoch[180] Batch[5] avg_epoch_loss=1.036623\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:37 INFO 140285796738880] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=1.03662347794\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:37 INFO 140285796738880] Epoch[180] Batch [5]#011Speed: 179.59 samples/sec#011loss=1.036623\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:39 INFO 140285796738880] Epoch[180] Batch[10] avg_epoch_loss=1.031653\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:39 INFO 140285796738880] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=1.02568762302\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:39 INFO 140285796738880] Epoch[180] Batch [10]#011Speed: 179.55 samples/sec#011loss=1.025688\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:39 INFO 140285796738880] processed a total of 687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4413.712978363037, \"sum\": 4413.712978363037, \"min\": 4413.712978363037}}, \"EndTime\": 1601447679.325103, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447674.910842}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:39 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=155.646537982 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:39 INFO 140285796738880] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:39 INFO 140285796738880] #quality_metric: host=algo-1, epoch=180, train loss <loss>=1.03165263479\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:39 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:40 INFO 140285796738880] Epoch[181] Batch[0] avg_epoch_loss=1.046347\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:40 INFO 140285796738880] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=1.04634749889\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:41 INFO 140285796738880] Epoch[181] Batch[5] avg_epoch_loss=1.072959\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:41 INFO 140285796738880] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=1.07295850913\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:41 INFO 140285796738880] Epoch[181] Batch [5]#011Speed: 178.47 samples/sec#011loss=1.072959\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:43 INFO 140285796738880] Epoch[181] Batch[10] avg_epoch_loss=0.930140\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:43 INFO 140285796738880] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=0.758757642657\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:43 INFO 140285796738880] Epoch[181] Batch [10]#011Speed: 179.68 samples/sec#011loss=0.758758\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:43 INFO 140285796738880] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4390.30909538269, \"sum\": 4390.30909538269, \"min\": 4390.30909538269}}, \"EndTime\": 1601447683.716003, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447679.32519}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:43 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=148.276879832 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:43 INFO 140285796738880] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:43 INFO 140285796738880] #quality_metric: host=algo-1, epoch=181, train loss <loss>=0.930139933459\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:43 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:44 INFO 140285796738880] Epoch[182] Batch[0] avg_epoch_loss=1.126989\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:44 INFO 140285796738880] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=1.12698888779\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:46 INFO 140285796738880] Epoch[182] Batch[5] avg_epoch_loss=1.169565\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:46 INFO 140285796738880] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=1.16956510146\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:46 INFO 140285796738880] Epoch[182] Batch [5]#011Speed: 180.73 samples/sec#011loss=1.169565\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:47 INFO 140285796738880] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3994.252920150757, \"sum\": 3994.252920150757, \"min\": 3994.252920150757}}, \"EndTime\": 1601447687.710855, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447683.716089}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:47 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=152.713989805 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:47 INFO 140285796738880] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:47 INFO 140285796738880] #quality_metric: host=algo-1, epoch=182, train loss <loss>=1.16431759\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:47 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:48 INFO 140285796738880] Epoch[183] Batch[0] avg_epoch_loss=1.033570\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:48 INFO 140285796738880] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=1.03356969357\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:50 INFO 140285796738880] Epoch[183] Batch[5] avg_epoch_loss=1.099588\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:50 INFO 140285796738880] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=1.0995880266\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:50 INFO 140285796738880] Epoch[183] Batch [5]#011Speed: 179.96 samples/sec#011loss=1.099588\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:52 INFO 140285796738880] Epoch[183] Batch[10] avg_epoch_loss=1.094031\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:52 INFO 140285796738880] #quality_metric: host=algo-1, epoch=183, batch=10 train loss <loss>=1.08736165762\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:52 INFO 140285796738880] Epoch[183] Batch [10]#011Speed: 178.21 samples/sec#011loss=1.087362\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:52 INFO 140285796738880] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4389.187812805176, \"sum\": 4389.187812805176, \"min\": 4389.187812805176}}, \"EndTime\": 1601447692.100761, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447687.710951}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:52 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=148.542269633 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:52 INFO 140285796738880] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:52 INFO 140285796738880] #quality_metric: host=algo-1, epoch=183, train loss <loss>=1.09403058616\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:52 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:52 INFO 140285796738880] Epoch[184] Batch[0] avg_epoch_loss=1.154827\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:52 INFO 140285796738880] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=1.15482699871\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:54 INFO 140285796738880] Epoch[184] Batch[5] avg_epoch_loss=1.095740\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:54 INFO 140285796738880] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=1.09573961298\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:54 INFO 140285796738880] Epoch[184] Batch [5]#011Speed: 181.98 samples/sec#011loss=1.095740\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:56 INFO 140285796738880] Epoch[184] Batch[10] avg_epoch_loss=1.085221\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:56 INFO 140285796738880] #quality_metric: host=algo-1, epoch=184, batch=10 train loss <loss>=1.07259905338\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:56 INFO 140285796738880] Epoch[184] Batch [10]#011Speed: 179.30 samples/sec#011loss=1.072599\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:56 INFO 140285796738880] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4393.105030059814, \"sum\": 4393.105030059814, \"min\": 4393.105030059814}}, \"EndTime\": 1601447696.494424, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447692.10085}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:56 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=153.872660481 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:56 INFO 140285796738880] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:56 INFO 140285796738880] #quality_metric: host=algo-1, epoch=184, train loss <loss>=1.0852211768\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:56 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:57 INFO 140285796738880] Epoch[185] Batch[0] avg_epoch_loss=0.961353\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:57 INFO 140285796738880] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=0.961353361607\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:59 INFO 140285796738880] Epoch[185] Batch[5] avg_epoch_loss=1.048869\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:59 INFO 140285796738880] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=1.04886932174\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:34:59 INFO 140285796738880] Epoch[185] Batch [5]#011Speed: 180.99 samples/sec#011loss=1.048869\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:00 INFO 140285796738880] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4069.5409774780273, \"sum\": 4069.5409774780273, \"min\": 4069.5409774780273}}, \"EndTime\": 1601447700.564527, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447696.494516}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:00 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=156.523125544 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:00 INFO 140285796738880] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:00 INFO 140285796738880] #quality_metric: host=algo-1, epoch=185, train loss <loss>=1.05978735685\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:00 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:01 INFO 140285796738880] Epoch[186] Batch[0] avg_epoch_loss=0.924576\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:01 INFO 140285796738880] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=0.924576282501\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:03 INFO 140285796738880] Epoch[186] Batch[5] avg_epoch_loss=1.026208\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:03 INFO 140285796738880] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=1.02620778481\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:03 INFO 140285796738880] Epoch[186] Batch [5]#011Speed: 178.94 samples/sec#011loss=1.026208\u001b[0m\n",
      "\n",
      "2020-09-30 06:35:11 Uploading - Uploading generated training model\u001b[34m[09/30/2020 06:35:04 INFO 140285796738880] Epoch[186] Batch[10] avg_epoch_loss=1.155129\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:04 INFO 140285796738880] #quality_metric: host=algo-1, epoch=186, batch=10 train loss <loss>=1.3098344326\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:04 INFO 140285796738880] Epoch[186] Batch [10]#011Speed: 181.18 samples/sec#011loss=1.309834\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:04 INFO 140285796738880] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4418.594837188721, \"sum\": 4418.594837188721, \"min\": 4418.594837188721}}, \"EndTime\": 1601447704.983748, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447700.564626}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:04 INFO 140285796738880] #throughput_metric: host=algo-1, train throughput=150.495827417 records/second\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:04 INFO 140285796738880] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:04 INFO 140285796738880] #quality_metric: host=algo-1, epoch=186, train loss <loss>=1.15512898835\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:04 INFO 140285796738880] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:04 INFO 140285796738880] Loading parameters from best epoch (146)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 48.03919792175293, \"sum\": 48.03919792175293, \"min\": 48.03919792175293}}, \"EndTime\": 1601447705.032402, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447704.983837}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:05 INFO 140285796738880] stopping training now\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:05 INFO 140285796738880] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:05 INFO 140285796738880] Final loss: 0.915228042006 (occurred at epoch 146)\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:05 INFO 140285796738880] #quality_metric: host=algo-1, train final_loss <loss>=0.915228042006\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:05 WARNING 140285796738880] You are using large values for `context_length` and/or `prediction_length`. The following step may take some time. If the step crashes, use an instance with more memory or reduce these two parameters.\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:05 INFO 140285796738880] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:05 WARNING 140285796738880] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:05 INFO 140285796738880] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 3137.0649337768555, \"sum\": 3137.0649337768555, \"min\": 3137.0649337768555}}, \"EndTime\": 1601447708.170493, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447705.032473}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:08 INFO 140285796738880] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 3610.10479927063, \"sum\": 3610.10479927063, \"min\": 3610.10479927063}}, \"EndTime\": 1601447708.643488, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447708.170619}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:08 INFO 140285796738880] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:08 INFO 140285796738880] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 71.2740421295166, \"sum\": 71.2740421295166, \"min\": 71.2740421295166}}, \"EndTime\": 1601447708.714897, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447708.643566}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:08 INFO 140285796738880] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[09/30/2020 06:35:08 INFO 140285796738880] No test data passed, skipping evaluation.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 801574.7501850128, \"sum\": 801574.7501850128, \"min\": 801574.7501850128}, \"setuptime\": {\"count\": 1, \"max\": 9.582042694091797, \"sum\": 9.582042694091797, \"min\": 9.582042694091797}}, \"EndTime\": 1601447708.833631, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601447708.714958}\n",
      "\u001b[0m\n",
      "\n",
      "2020-09-30 06:35:22 Completed - Training job completed\n",
      "Training seconds: 856\n",
      "Billable seconds: 856\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session.logs_for_job(estimator.latest_training_job.name, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prediction\n",
    "\n",
    "When deploying trained model to SageMaker endpoint, we will pass below utility class together: this allows to return a dcitionary encoding for requests using pandas.Series objects rather than raw JSON strings.\n",
    "\n",
    "In generel, you may copy this code to your system but slightly change some numbsers such as time delta, prediction lengths, etc. For more information, you can refer to the [RealTimePredictor in SageMaker SDK](https://sagemaker.readthedocs.io/en/v1.2.3/predictors.html) which is the parent of this utility class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepARPredictor(sagemaker.predictor.RealTimePredictor):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, content_type=sagemaker.content_types.CONTENT_TYPE_JSON, **kwargs)\n",
    "        \n",
    "    def predict(self, ts, cat=None, dynamic_feat=None, \n",
    "                num_samples=100, return_samples=False, quantiles=[\"0.1\", \"0.5\", \"0.9\"]):\n",
    "        \"\"\"Requests the prediction of for the time series listed in `ts`, each with the (optional)\n",
    "        corresponding category listed in `cat`.\n",
    "        \n",
    "        ts -- `pandas.Series` object, the time series to predict\n",
    "        cat -- integer, the group associated to the time series (default: None)\n",
    "        num_samples -- integer, number of samples to compute at prediction time (default: 100)\n",
    "        return_samples -- boolean indicating whether to include samples in the response (default: False)\n",
    "        quantiles -- list of strings specifying the quantiles to compute (default: [\"0.1\", \"0.5\", \"0.9\"])\n",
    "        \n",
    "        Return value: list of `pandas.DataFrame` objects, each containing the predictions\n",
    "        \"\"\"\n",
    "        prediction_time = ts.index[-1] + datetime.timedelta(minutes=10)\n",
    "#         prediction_time = 144\n",
    "        quantiles = [str(q) for q in quantiles]\n",
    "        req = self.__encode_request(ts, cat, dynamic_feat, num_samples, return_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req)\n",
    "        return self.__decode_response(res, ts.index.freq, prediction_time, return_samples)\n",
    "    \n",
    "    def __encode_request(self, ts, cat, dynamic_feat, num_samples, return_samples, quantiles):\n",
    "        instance = series_to_dict(ts, cat if cat is not None else None, dynamic_feat if dynamic_feat else None)\n",
    "\n",
    "        configuration = {\n",
    "            \"num_samples\": num_samples,\n",
    "            \"output_types\": [\"quantiles\", \"samples\"] if return_samples else [\"quantiles\"],\n",
    "            \"quantiles\": quantiles\n",
    "        }\n",
    "        \n",
    "        http_request_data = {\n",
    "            \"instances\": [instance],\n",
    "            \"configuration\": configuration\n",
    "        }\n",
    "        \n",
    "        return json.dumps(http_request_data).encode('utf-8')\n",
    "    \n",
    "    def __decode_response(self, response, freq, prediction_time, return_samples):\n",
    "        # we only sent one time series so we only receive one in return\n",
    "        # however, if possible one will pass multiple time series as predictions will then be faster\n",
    "        predictions = json.loads(response.decode('utf-8'))['predictions'][0]\n",
    "        prediction_length = len(next(iter(predictions['quantiles'].values())))\n",
    "        \n",
    "        prediction_index = pd.date_range(prediction_time, prediction_time + freq * (prediction_length-1), freq=freq)\n",
    "        \n",
    "        if return_samples:\n",
    "            dict_of_samples = {'sample_' + str(i): s for i, s in enumerate(predictions['samples'])}\n",
    "        else:\n",
    "            dict_of_samples = {}\n",
    "        return pd.DataFrame(data={**predictions['quantiles'], **dict_of_samples}, index=prediction_index)\n",
    "\n",
    "    def set_frequency(self, freq):\n",
    "        self.freq = freq\n",
    "        \n",
    "def encode_target(ts):\n",
    "    return [x if np.isfinite(x) else \"NaN\" for x in ts]        \n",
    "\n",
    "def series_to_dict(ts, cat=None, dynamic_feat=None):\n",
    "    \"\"\"Given a pandas.Series object, returns a dictionary encoding the time series.\n",
    "\n",
    "    ts -- a pands.Series object with the target time series\n",
    "    cat -- an integer indicating the time series category\n",
    "\n",
    "    Return value: a dictionary\n",
    "    \"\"\"\n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": encode_target(ts)}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    if dynamic_feat is not None:\n",
    "        obj[\"dynamic_feat\"] = dynamic_feat        \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's deploy the model with below code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "# predictor.delete_endpoint()\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    predictor_cls=DeepARPredictor, \n",
    "    wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the test dataset in CSV format to the inference endpoint. Note that the serializer and deserializer will automatically take care of the datatype conversion from Numpy NDArrays.\n",
    "\n",
    "Here, we pass only the first six datapoints first so that we can see what the output looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-01 00:00:00    24.0\n",
       "2012-03-01 00:10:00    22.0\n",
       "2012-03-01 00:20:00    20.0\n",
       "2012-03-01 00:30:00    17.0\n",
       "2012-03-01 00:40:00    15.0\n",
       "                       ... \n",
       "2012-03-14 23:10:00    60.0\n",
       "2012-03-14 23:20:00    60.0\n",
       "2012-03-14 23:30:00    38.0\n",
       "2012-03-14 23:40:00    36.0\n",
       "2012-03-14 23:50:00    29.0\n",
       "Freq: 10T, Length: 2016, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.Series(training_data[0]['target'][:-144])\n",
    "test_data.index=pd.date_range(training_data[0]['start'], \n",
    "                              datetime.datetime.strptime(training_data[0]['start'],'%Y-%m-%d %H:%M:%S')+datetime.timedelta(minutes=10*2015), \n",
    "                              freq='10T')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predictor.predict(ts=test_data, \n",
    "                               dynamic_feat=training_data[0]['dynamic_feat'],\n",
    "                               quantiles=[0.10, 0.5, 0.90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-01 00:00:00    24.0\n",
       "2012-03-01 00:10:00    22.0\n",
       "2012-03-01 00:20:00    20.0\n",
       "2012-03-01 00:30:00    17.0\n",
       "2012-03-01 00:40:00    15.0\n",
       "                       ... \n",
       "2012-03-15 23:10:00    68.0\n",
       "2012-03-15 23:20:00    70.0\n",
       "2012-03-15 23:30:00    50.0\n",
       "2012-03-15 23:40:00    45.0\n",
       "2012-03-15 23:50:00    37.0\n",
       "Freq: 10T, Length: 2160, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.Series(training_data[0]['target'])\n",
    "full_data.index=pd.date_range(training_data[0]['start'], \n",
    "                              datetime.datetime.strptime(training_data[0]['start'],'%Y-%m-%d %H:%M:%S')+datetime.timedelta(minutes=10*2159), \n",
    "                              freq='10T')\n",
    "full_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plotting the Prediction\n",
    "\n",
    "Now we can use the previously created predictor object. To check the result, we will predict data after March 15, 2012 00:00 used for training, and compare the results with the original training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "anomalies = full_data['2012-03-15 00:00:00':][full_data['2012-03-15 00:00:00':].values-prediction['0.9'].values > 0]\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(full_data['2012-03-14 14:20:00':])\n",
    "plt.plot(prediction)\n",
    "plt.fill_between(prediction.index, prediction['0.9'],prediction['0.1'], alpha=0.5)\n",
    "plt.scatter(anomalies.index, anomalies.values, color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can aggregate values to smooth out the noisy result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_prediction = prediction.resample('2H').sum()\n",
    "resample_full_data = full_data['2012-03-13 23:20:00':].resample('2H').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure is the result of resampling the prediction results from 10 minutes to 2 hours. Depending on the business case, the forecasting unit may be different from the one used in the training. If you resample them with larger units of time, the prediction results will be smoother. This kind of manipulation can be used to prevent too much frequent noise alarms when setting the upper/lower monitoring limit with the prediction range of time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resample_anomalies = resample_full_data['2012-03-15 00:00:00':][resample_full_data['2012-03-15 00:00:00':].values-resample_prediction['0.9'].values > 0]\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(resample_full_data['2012-03-14 14:20:00':])\n",
    "plt.plot(resample_prediction)\n",
    "plt.fill_between(resample_prediction.index, resample_prediction['0.9'],resample_prediction['0.1'], alpha=0.5)\n",
    "plt.scatter(resample_anomalies.index, resample_anomalies.values, color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop and Delete the Endpoint\n",
    "\n",
    "Finally, we should delete the endpoint before we close the notebook.\n",
    "\n",
    "To do so execute the cell below. Alternately, you can navigate to the \"Endpoints\" tab in the SageMaker console, select the endpoint with the name stored in the variable endpoint_name, and select \"Delete\" from the \"Actions\" dropdown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
