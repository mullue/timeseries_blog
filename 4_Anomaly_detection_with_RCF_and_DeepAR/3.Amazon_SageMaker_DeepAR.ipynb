{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Amazon_SageMaker_DeepAR\n",
    "\n",
    "This notebook shows how to apply the SageMaker [DeepAR built-in algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html). DeepAR forecasting algorithm is a supervised learning algorithm for forecasting scalar (one-dimensional) time series using recurrent neural networks (RNN) to produce both point and probabilistic forecasts.The DeepAR forecasting algorithm can provide better forecast accuracies compared to classical forecasting techniques such as Autoregressive Integrated Moving Average (ARIMA) or Exponential Smoothing (ES), both of which are implemented in many open-source and commercial software packages for forecasting. \n",
    "\n",
    "## Table Of Contents\n",
    "The overall process for this is:\n",
    "\n",
    "* 1) Setup\n",
    "* 2) Data Preparation\n",
    "* 3) Training the DeepAR Model\n",
    "* 4) Predicting the Model\n",
    "* 5) Plotting the Prediction\n",
    "\n",
    "To get started, simply execute the cells below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data Preparation\n",
    "\n",
    "We will divide our clikstream events by page. In other words, each page has its own clickstream timesereis. We can consider it as separated product sales in retail store. And we will predict the number of clicks in 10 minutes by referring to the number of visitors. To do this, we use the number of clicks as the target feature and the number of users as the dynamic feature.\n",
    "\n",
    "Change the data to the format that DeepAR algorithm use. The records in your input files should contain the following fields:\n",
    "\n",
    "* **start** : The start timestamp. A string with the format YYYY-MM-DD HH:MM:SS.\n",
    "* **target** : An array of floating-point values or integers that represent the time series. Here, we will use clickstream counts in 10 minutes for forecasting value.\n",
    "* **dynamic_feat (optional)** : An array of arrays of floating-point values or integers that represents the vector of custom feature time series. Here, we will use the number of visitors in 10 minutes for dynamic features.\n",
    "* **cat (optional)** : An array of categorical features that can be used to encode the groups that the record belongs to. We do not use categorical values in this example.\n",
    "\n",
    "```python\n",
    "# example:\n",
    "{\"start\": \"2012-03-01 00:00:00\", \"target\": [24.0, 22.0, 20.0, 17.0, ...], \"dynamic_feat\": [[13, 14, 8, ...]]}\n",
    "```\n",
    "\n",
    "For more information regarding input/outpot format of DeepAR : https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html#deepar-inputoutput\n",
    "\n",
    "\n",
    "We use variables and dataframes that we stored via `1.Exploratory_Data_Analysis.ipynb` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "for index, url in zip(range(len(urls)), urls):\n",
    "    agg_click_users = filtered_clickstream[filtered_clickstream['url'] == url].set_index('timestamp').resample('10T')\n",
    "    clicks = agg_click_users.sum()['clickstream_id']\n",
    "    users  = agg_click_users.nunique()['user_session_id']\n",
    "    \n",
    "    data = {'start' : str(agg_click_users.nunique().index[0]),\n",
    "            'target': list(clicks.values.astype('float')),\n",
    "            'dynamic_feat': [list(users.values.astype('float'))]\n",
    "            }\n",
    "    training_data.append(data)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the dict type above into a json file for preparation to train the DeepAR model. *JSON Lines* format is JSON, but with newline-separated records instead of a parent `[... , ...]` array: So a whole JSON Lines file is *not* valid JSON, but each line of the file *is*.\n",
    "\n",
    "Write our training and test files in JSON Lines, and upload to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def write_dicts_to_file(path, data):\n",
    "    with open(path, 'wb') as fp:\n",
    "        for row in training_data:\n",
    "            fp.write(json.dumps(row).encode(\"utf-8\"))\n",
    "            fp.write(\"\\n\".encode('utf-8'))\n",
    "            \n",
    "write_dicts_to_file(\"train.json\", training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-2-322537213286/deepar-clickstream/train.json'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "s3_bucket = sagemaker.Session().default_bucket()  # replace with an existing bucket if needed\n",
    "s3_prefix = 'deepar-clickstream'    # prefix used for all data stored within the bucket\n",
    "\n",
    "role = sagemaker.get_execution_role()             # IAM role to use by SageMaker\n",
    "\n",
    "train_s3 = sagemaker_session.upload_data(path='train.json', key_prefix=s3_prefix)\n",
    "train_s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"start\": \"2012-03-01 00:00:00\", \"target\": [24.0, 22.0, 20.0, 17.0, 15.0, 12.0, 15.0, 10.0, 14.0, 9....\n"
     ]
    }
   ],
   "source": [
    "import s3fs\n",
    "\n",
    "s3filesystem = s3fs.S3FileSystem()\n",
    "with s3filesystem.open(train_s3, 'rb') as fp:\n",
    "    print(fp.readline().decode(\"utf-8\")[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Training the DeepAR Model\n",
    "\n",
    "Training a model is almost identical to using any other built-in algorithm. We need to define Estimator with algorhtim and hyperparameters and fit the model with the training data that we prepared above.\n",
    "\n",
    "Now the useful part - we'll be using the [Python SageMaker SDK](https://sagemaker.readthedocs.io/en/stable/index.html) to:\n",
    "\n",
    "1. Create our [Estimator](https://sagemaker.readthedocs.io/en/stable/estimators.html) defining the algorithm and fitting/hyper-parameters\n",
    "2. Define our [data channels](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo-running-container.html#your-algorithms-training-algo-running-container-inputdataconfig) to fit and validate on\n",
    "3. [Fit](https://sagemaker.readthedocs.io/en/stable/estimators.html#sagemaker.estimator.Estimator.fit) a model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "# we use 10 minutes frequency for the time series\n",
    "freq = datetime.timedelta(minutes=10)\n",
    "\n",
    "# we predict for 24 hours and use same context length with prediction length.\n",
    "prediction_length = 24 * 6\n",
    "context_length = 24 * 6\n",
    "\n",
    "image_name = sagemaker.amazon.amazon_estimator.get_image_uri(region, \"forecasting-deepar\", \"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    base_job_name='deepar-clickstream'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to set some hyperparameters: for example, frequency of the time series used, number of data points the model will look at in the past, number of predicted data points. The other hyperparameters concern the model to train (number of layers, number of cells per layer, likelihood function) and the training options such as early stopping patience, number of epochs, batch size, and learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"time_freq\": '10min',\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"mini_batch_size\": \"64\",\n",
    "    \"learning_rate\": \"5E-4\"\n",
    "}\n",
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to launch the training job. SageMaker will start an EC2 instance, download the data from S3, start training the model and save the trained model. Training will take about 20 minutes in c4.2xlarge instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.3 ms, sys: 0 ns, total: 17.3 ms\n",
      "Wall time: 158 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\n",
    "    \"train\": train_s3\n",
    "}\n",
    "\n",
    "estimator.fit(data_channels, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-21 06:14:42 Starting - Starting the training job...\n",
      "2020-08-21 06:14:43 Starting - Launching requested ML instances......\n",
      "2020-08-21 06:16:05 Starting - Preparing the instances for training......\n",
      "2020-08-21 06:17:07 Downloading - Downloading input data\n",
      "2020-08-21 06:17:07 Training - Downloading the training image...\n",
      "2020-08-21 06:17:42 Training - Training image download completed. Training in progress..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:44 INFO 140166612858688] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:44 INFO 140166612858688] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'5E-4', u'prediction_length': u'144', u'epochs': u'400', u'time_freq': u'10min', u'context_length': u'144', u'mini_batch_size': u'64', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:44 INFO 140166612858688] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'5E-4', u'num_layers': u'2', u'epochs': u'400', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'64', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'144', u'time_freq': u'10min', u'context_length': u'144', u'_kvstore': u'auto', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:44 INFO 140166612858688] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:44 INFO 140166612858688] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:44 INFO 140166612858688] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:44 INFO 140166612858688] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:44 INFO 140166612858688] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=1 from dataset.\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:44 INFO 140166612858688] Training set statistics:\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:44 INFO 140166612858688] Integer time series\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:44 INFO 140166612858688] number of time series: 16\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:44 INFO 140166612858688] number of observations: 34556\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:44 INFO 140166612858688] mean target length: 2159\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:44 INFO 140166612858688] min/mean/max target: 0.0/12.1908206968/477.0\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:44 INFO 140166612858688] mean abs(target): 12.1908206968\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:44 INFO 140166612858688] contains missing values: no\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:44 INFO 140166612858688] Small number of time series. Doing 40 passes over dataset with prob 1.0 per epoch.\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:44 INFO 140166612858688] No test channel found not running evaluations\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:44 INFO 140166612858688] nvidia-smi took: 0.0251898765564 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:44 INFO 140166612858688] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:44 INFO 140166612858688] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 2236.1981868743896, \"sum\": 2236.1981868743896, \"min\": 2236.1981868743896}}, \"EndTime\": 1597990666.885874, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990664.648786}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:46 INFO 140166612858688] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 3681.766986846924, \"sum\": 3681.766986846924, \"min\": 3681.766986846924}}, \"EndTime\": 1597990668.33068, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990666.885957}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:49 INFO 140166612858688] Epoch[0] Batch[0] avg_epoch_loss=4.227736\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:49 INFO 140166612858688] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=4.22773647308\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:50 INFO 140166612858688] Epoch[0] Batch[5] avg_epoch_loss=3.682466\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:50 INFO 140166612858688] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=3.6824657917\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:50 INFO 140166612858688] Epoch[0] Batch [5]#011Speed: 192.20 samples/sec#011loss=3.682466\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:52 INFO 140166612858688] processed a total of 594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 400, \"sum\": 400.0, \"min\": 400}, \"update.time\": {\"count\": 1, \"max\": 3999.263048171997, \"sum\": 3999.263048171997, \"min\": 3999.263048171997}}, \"EndTime\": 1597990672.330165, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990668.330788}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:52 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=148.522981504 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:52 INFO 140166612858688] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:52 INFO 140166612858688] #quality_metric: host=algo-1, epoch=0, train loss <loss>=3.56035630703\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:52 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:52 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_27abbcf9-9370-448e-8348-f3e0e6383108-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 118.92104148864746, \"sum\": 118.92104148864746, \"min\": 118.92104148864746}}, \"EndTime\": 1597990672.44979, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990672.330243}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:53 INFO 140166612858688] Epoch[1] Batch[0] avg_epoch_loss=3.176122\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:53 INFO 140166612858688] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=3.17612218857\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:55 INFO 140166612858688] Epoch[1] Batch[5] avg_epoch_loss=3.250252\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:55 INFO 140166612858688] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=3.25025173028\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:55 INFO 140166612858688] Epoch[1] Batch [5]#011Speed: 177.24 samples/sec#011loss=3.250252\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:56 INFO 140166612858688] Epoch[1] Batch[10] avg_epoch_loss=3.224990\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:56 INFO 140166612858688] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=3.19467639923\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:56 INFO 140166612858688] Epoch[1] Batch [10]#011Speed: 189.47 samples/sec#011loss=3.194676\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:56 INFO 140166612858688] processed a total of 687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4394.999027252197, \"sum\": 4394.999027252197, \"min\": 4394.999027252197}}, \"EndTime\": 1597990676.844935, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990672.449861}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:56 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=156.309364088 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:56 INFO 140166612858688] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:56 INFO 140166612858688] #quality_metric: host=algo-1, epoch=1, train loss <loss>=3.22499021617\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:56 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:56 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_d977febf-8c8e-4677-ac91-6ae302e2f7a4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 109.36498641967773, \"sum\": 109.36498641967773, \"min\": 109.36498641967773}}, \"EndTime\": 1597990676.954919, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990676.845023}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:57 INFO 140166612858688] Epoch[2] Batch[0] avg_epoch_loss=3.019698\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:57 INFO 140166612858688] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=3.01969838142\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:59 INFO 140166612858688] Epoch[2] Batch[5] avg_epoch_loss=3.093563\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:59 INFO 140166612858688] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=3.09356284142\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:17:59 INFO 140166612858688] Epoch[2] Batch [5]#011Speed: 187.07 samples/sec#011loss=3.093563\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:01 INFO 140166612858688] Epoch[2] Batch[10] avg_epoch_loss=3.050333\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:01 INFO 140166612858688] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=2.99845814705\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:01 INFO 140166612858688] Epoch[2] Batch [10]#011Speed: 191.44 samples/sec#011loss=2.998458\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:01 INFO 140166612858688] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4178.328990936279, \"sum\": 4178.328990936279, \"min\": 4178.328990936279}}, \"EndTime\": 1597990681.133423, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990676.954998}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:01 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=158.909798812 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:01 INFO 140166612858688] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:01 INFO 140166612858688] #quality_metric: host=algo-1, epoch=2, train loss <loss>=3.05033343489\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:01 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:01 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_a5a47152-2d4e-493a-8ac8-8cd113b032de-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 133.7130069732666, \"sum\": 133.7130069732666, \"min\": 133.7130069732666}}, \"EndTime\": 1597990681.267721, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990681.133506}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:02 INFO 140166612858688] Epoch[3] Batch[0] avg_epoch_loss=3.114263\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:02 INFO 140166612858688] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=3.11426305771\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:18:03 INFO 140166612858688] Epoch[3] Batch[5] avg_epoch_loss=3.012879\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:03 INFO 140166612858688] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=3.01287853718\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:03 INFO 140166612858688] Epoch[3] Batch [5]#011Speed: 189.38 samples/sec#011loss=3.012879\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:05 INFO 140166612858688] Epoch[3] Batch[10] avg_epoch_loss=3.025354\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:05 INFO 140166612858688] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=3.04032406807\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:05 INFO 140166612858688] Epoch[3] Batch [10]#011Speed: 190.74 samples/sec#011loss=3.040324\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:05 INFO 140166612858688] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4159.163951873779, \"sum\": 4159.163951873779, \"min\": 4159.163951873779}}, \"EndTime\": 1597990685.427022, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990681.267796}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:05 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=163.729986402 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:05 INFO 140166612858688] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:05 INFO 140166612858688] #quality_metric: host=algo-1, epoch=3, train loss <loss>=3.02535377849\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:05 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:05 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_ae73dcf8-737a-4932-8f24-0f8b35be8a68-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 121.70696258544922, \"sum\": 121.70696258544922, \"min\": 121.70696258544922}}, \"EndTime\": 1597990685.549307, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990685.427107}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:06 INFO 140166612858688] Epoch[4] Batch[0] avg_epoch_loss=2.832758\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:06 INFO 140166612858688] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=2.83275794983\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:08 INFO 140166612858688] Epoch[4] Batch[5] avg_epoch_loss=2.739877\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:08 INFO 140166612858688] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=2.7398771445\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:08 INFO 140166612858688] Epoch[4] Batch [5]#011Speed: 190.54 samples/sec#011loss=2.739877\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:09 INFO 140166612858688] Epoch[4] Batch[10] avg_epoch_loss=2.722051\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:09 INFO 140166612858688] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=2.70065927505\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:09 INFO 140166612858688] Epoch[4] Batch [10]#011Speed: 189.08 samples/sec#011loss=2.700659\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:09 INFO 140166612858688] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4162.163972854614, \"sum\": 4162.163972854614, \"min\": 4162.163972854614}}, \"EndTime\": 1597990689.711611, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990685.549387}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:09 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=155.203217251 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:09 INFO 140166612858688] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:09 INFO 140166612858688] #quality_metric: host=algo-1, epoch=4, train loss <loss>=2.7220508402\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:09 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:09 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_99b9b6bf-4176-46a7-9540-f148ffb60d45-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 129.1329860687256, \"sum\": 129.1329860687256, \"min\": 129.1329860687256}}, \"EndTime\": 1597990689.841345, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990689.711694}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:10 INFO 140166612858688] Epoch[5] Batch[0] avg_epoch_loss=2.660605\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:10 INFO 140166612858688] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=2.66060495377\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:12 INFO 140166612858688] Epoch[5] Batch[5] avg_epoch_loss=2.675762\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:12 INFO 140166612858688] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=2.67576221625\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:12 INFO 140166612858688] Epoch[5] Batch [5]#011Speed: 188.88 samples/sec#011loss=2.675762\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:13 INFO 140166612858688] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3827.6491165161133, \"sum\": 3827.6491165161133, \"min\": 3827.6491165161133}}, \"EndTime\": 1597990693.669152, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990689.841429}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:13 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=163.802557841 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:13 INFO 140166612858688] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:13 INFO 140166612858688] #quality_metric: host=algo-1, epoch=5, train loss <loss>=2.66728408337\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:13 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:13 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_fe2c201c-d55c-46be-8894-10e3d67462b2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 113.77692222595215, \"sum\": 113.77692222595215, \"min\": 113.77692222595215}}, \"EndTime\": 1597990693.783538, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990693.66924}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:14 INFO 140166612858688] Epoch[6] Batch[0] avg_epoch_loss=2.589858\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:14 INFO 140166612858688] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=2.5898578167\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:16 INFO 140166612858688] Epoch[6] Batch[5] avg_epoch_loss=2.536933\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:16 INFO 140166612858688] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=2.53693326314\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:16 INFO 140166612858688] Epoch[6] Batch [5]#011Speed: 189.99 samples/sec#011loss=2.536933\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:17 INFO 140166612858688] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3810.6579780578613, \"sum\": 3810.6579780578613, \"min\": 3810.6579780578613}}, \"EndTime\": 1597990697.594359, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990693.783623}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:17 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=167.419435066 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:17 INFO 140166612858688] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:17 INFO 140166612858688] #quality_metric: host=algo-1, epoch=6, train loss <loss>=2.50383696556\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:17 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:17 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_898479e6-c85e-4164-8e24-60a4b7b520fb-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 112.24198341369629, \"sum\": 112.24198341369629, \"min\": 112.24198341369629}}, \"EndTime\": 1597990697.707282, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990697.594447}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:18 INFO 140166612858688] Epoch[7] Batch[0] avg_epoch_loss=2.563288\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:18 INFO 140166612858688] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=2.56328821182\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:20 INFO 140166612858688] Epoch[7] Batch[5] avg_epoch_loss=2.534242\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:20 INFO 140166612858688] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=2.53424215317\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:20 INFO 140166612858688] Epoch[7] Batch [5]#011Speed: 188.51 samples/sec#011loss=2.534242\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:21 INFO 140166612858688] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3827.7530670166016, \"sum\": 3827.7530670166016, \"min\": 3827.7530670166016}}, \"EndTime\": 1597990701.535166, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990697.707348}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:21 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=159.618213763 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:21 INFO 140166612858688] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:21 INFO 140166612858688] #quality_metric: host=algo-1, epoch=7, train loss <loss>=2.48989405632\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:21 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:21 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_dfa04289-6273-4587-b565-fb6cd99df7d1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 109.09295082092285, \"sum\": 109.09295082092285, \"min\": 109.09295082092285}}, \"EndTime\": 1597990701.644933, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990701.535255}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:22 INFO 140166612858688] Epoch[8] Batch[0] avg_epoch_loss=2.441902\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:22 INFO 140166612858688] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=2.44190216064\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:24 INFO 140166612858688] Epoch[8] Batch[5] avg_epoch_loss=2.363479\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:24 INFO 140166612858688] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=2.36347862085\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:24 INFO 140166612858688] Epoch[8] Batch [5]#011Speed: 189.53 samples/sec#011loss=2.363479\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:25 INFO 140166612858688] Epoch[8] Batch[10] avg_epoch_loss=2.352307\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:25 INFO 140166612858688] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=2.33890023232\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:25 INFO 140166612858688] Epoch[8] Batch [10]#011Speed: 189.27 samples/sec#011loss=2.338900\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:25 INFO 140166612858688] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4153.442859649658, \"sum\": 4153.442859649658, \"min\": 4153.442859649658}}, \"EndTime\": 1597990705.798535, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990701.645014}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:25 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=164.436935946 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:25 INFO 140166612858688] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:25 INFO 140166612858688] #quality_metric: host=algo-1, epoch=8, train loss <loss>=2.35230662606\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:25 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:25 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_f027d96a-5d7c-4138-b2ce-0e07b348a1bd-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 145.08485794067383, \"sum\": 145.08485794067383, \"min\": 145.08485794067383}}, \"EndTime\": 1597990705.944219, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990705.79862}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:26 INFO 140166612858688] Epoch[9] Batch[0] avg_epoch_loss=2.358948\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:26 INFO 140166612858688] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=2.35894799232\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:28 INFO 140166612858688] Epoch[9] Batch[5] avg_epoch_loss=2.323060\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:28 INFO 140166612858688] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=2.32306047281\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:28 INFO 140166612858688] Epoch[9] Batch [5]#011Speed: 191.52 samples/sec#011loss=2.323060\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:30 INFO 140166612858688] Epoch[9] Batch[10] avg_epoch_loss=2.289340\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:30 INFO 140166612858688] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=2.2488758564\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:30 INFO 140166612858688] Epoch[9] Batch [10]#011Speed: 189.98 samples/sec#011loss=2.248876\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:30 INFO 140166612858688] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4142.565011978149, \"sum\": 4142.565011978149, \"min\": 4142.565011978149}}, \"EndTime\": 1597990710.086946, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990705.944306}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:30 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=155.695929868 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:30 INFO 140166612858688] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:30 INFO 140166612858688] #quality_metric: host=algo-1, epoch=9, train loss <loss>=2.28934019262\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:30 INFO 140166612858688] best epoch loss so far\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:18:30 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_a6bd2ee4-2b55-4c25-b87f-4e865a6061e0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 123.6410140991211, \"sum\": 123.6410140991211, \"min\": 123.6410140991211}}, \"EndTime\": 1597990710.211169, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990710.087031}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:30 INFO 140166612858688] Epoch[10] Batch[0] avg_epoch_loss=2.145450\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:30 INFO 140166612858688] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=2.14544963837\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:32 INFO 140166612858688] Epoch[10] Batch[5] avg_epoch_loss=2.160316\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:32 INFO 140166612858688] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=2.16031618913\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:32 INFO 140166612858688] Epoch[10] Batch [5]#011Speed: 189.05 samples/sec#011loss=2.160316\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:34 INFO 140166612858688] processed a total of 604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3824.620008468628, \"sum\": 3824.620008468628, \"min\": 3824.620008468628}}, \"EndTime\": 1597990714.035942, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990710.211254}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:34 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=157.919558731 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:34 INFO 140166612858688] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:34 INFO 140166612858688] #quality_metric: host=algo-1, epoch=10, train loss <loss>=2.12197537422\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:34 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:34 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_16743bce-9fe3-4b57-8910-8096e52f44a6-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 110.1541519165039, \"sum\": 110.1541519165039, \"min\": 110.1541519165039}}, \"EndTime\": 1597990714.146733, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990714.03602}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:34 INFO 140166612858688] Epoch[11] Batch[0] avg_epoch_loss=2.285740\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:34 INFO 140166612858688] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=2.28573989868\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:36 INFO 140166612858688] Epoch[11] Batch[5] avg_epoch_loss=2.200077\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:36 INFO 140166612858688] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=2.20007737478\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:36 INFO 140166612858688] Epoch[11] Batch [5]#011Speed: 189.45 samples/sec#011loss=2.200077\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:38 INFO 140166612858688] Epoch[11] Batch[10] avg_epoch_loss=2.186032\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:38 INFO 140166612858688] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=2.16917824745\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:38 INFO 140166612858688] Epoch[11] Batch [10]#011Speed: 189.17 samples/sec#011loss=2.169178\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:38 INFO 140166612858688] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4211.88497543335, \"sum\": 4211.88497543335, \"min\": 4211.88497543335}}, \"EndTime\": 1597990718.358768, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990714.146805}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:38 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=157.882200535 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:38 INFO 140166612858688] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:38 INFO 140166612858688] #quality_metric: host=algo-1, epoch=11, train loss <loss>=2.1860323169\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:38 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:39 INFO 140166612858688] Epoch[12] Batch[0] avg_epoch_loss=2.132642\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:39 INFO 140166612858688] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=2.13264203072\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:40 INFO 140166612858688] Epoch[12] Batch[5] avg_epoch_loss=2.118140\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:40 INFO 140166612858688] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=2.11814030011\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:40 INFO 140166612858688] Epoch[12] Batch [5]#011Speed: 191.46 samples/sec#011loss=2.118140\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:42 INFO 140166612858688] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3793.247938156128, \"sum\": 3793.247938156128, \"min\": 3793.247938156128}}, \"EndTime\": 1597990722.152538, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990718.358842}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:42 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=161.860965892 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:42 INFO 140166612858688] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:42 INFO 140166612858688] #quality_metric: host=algo-1, epoch=12, train loss <loss>=2.10640546083\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:42 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:42 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_c7498a68-0520-4f16-97e7-7069ae053c0b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 117.10500717163086, \"sum\": 117.10500717163086, \"min\": 117.10500717163086}}, \"EndTime\": 1597990722.2703, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990722.152625}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:43 INFO 140166612858688] Epoch[13] Batch[0] avg_epoch_loss=2.102275\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:43 INFO 140166612858688] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=2.10227537155\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:44 INFO 140166612858688] Epoch[13] Batch[5] avg_epoch_loss=2.086064\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:44 INFO 140166612858688] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=2.08606376251\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:44 INFO 140166612858688] Epoch[13] Batch [5]#011Speed: 190.41 samples/sec#011loss=2.086064\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:46 INFO 140166612858688] Epoch[13] Batch[10] avg_epoch_loss=2.080905\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:46 INFO 140166612858688] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=2.07471468449\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:46 INFO 140166612858688] Epoch[13] Batch [10]#011Speed: 192.73 samples/sec#011loss=2.074715\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:46 INFO 140166612858688] processed a total of 718 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4492.613077163696, \"sum\": 4492.613077163696, \"min\": 4492.613077163696}}, \"EndTime\": 1597990726.763044, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990722.270365}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:46 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=159.813246639 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:46 INFO 140166612858688] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:46 INFO 140166612858688] #quality_metric: host=algo-1, epoch=13, train loss <loss>=2.06641816099\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:46 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:46 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_09497bcf-e1f7-4da1-a7ba-be32789c86ca-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 118.37601661682129, \"sum\": 118.37601661682129, \"min\": 118.37601661682129}}, \"EndTime\": 1597990726.882054, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990726.763133}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:47 INFO 140166612858688] Epoch[14] Batch[0] avg_epoch_loss=2.229299\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:47 INFO 140166612858688] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=2.22929930687\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:49 INFO 140166612858688] Epoch[14] Batch[5] avg_epoch_loss=2.087723\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:49 INFO 140166612858688] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=2.08772305648\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:49 INFO 140166612858688] Epoch[14] Batch [5]#011Speed: 185.60 samples/sec#011loss=2.087723\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:51 INFO 140166612858688] Epoch[14] Batch[10] avg_epoch_loss=2.018341\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:51 INFO 140166612858688] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=1.93508265018\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:51 INFO 140166612858688] Epoch[14] Batch [10]#011Speed: 188.05 samples/sec#011loss=1.935083\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:51 INFO 140166612858688] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4191.083908081055, \"sum\": 4191.083908081055, \"min\": 4191.083908081055}}, \"EndTime\": 1597990731.073292, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990726.882137}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:51 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=154.84832329 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:51 INFO 140166612858688] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:51 INFO 140166612858688] #quality_metric: host=algo-1, epoch=14, train loss <loss>=2.01834105362\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:51 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:51 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_97d6fab7-6ab1-4304-9e9a-dec03b9d48e5-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 109.33208465576172, \"sum\": 109.33208465576172, \"min\": 109.33208465576172}}, \"EndTime\": 1597990731.183208, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990731.073368}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:18:51 INFO 140166612858688] Epoch[15] Batch[0] avg_epoch_loss=2.079784\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:51 INFO 140166612858688] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=2.07978367805\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:53 INFO 140166612858688] Epoch[15] Batch[5] avg_epoch_loss=2.065309\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:53 INFO 140166612858688] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=2.06530918678\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:53 INFO 140166612858688] Epoch[15] Batch [5]#011Speed: 188.76 samples/sec#011loss=2.065309\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:54 INFO 140166612858688] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3800.717830657959, \"sum\": 3800.717830657959, \"min\": 3800.717830657959}}, \"EndTime\": 1597990734.984064, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990731.183282}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:54 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=167.329662496 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:54 INFO 140166612858688] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:54 INFO 140166612858688] #quality_metric: host=algo-1, epoch=15, train loss <loss>=2.04841612577\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:54 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:55 INFO 140166612858688] Epoch[16] Batch[0] avg_epoch_loss=1.801830\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:55 INFO 140166612858688] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=1.80183029175\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:57 INFO 140166612858688] Epoch[16] Batch[5] avg_epoch_loss=1.954053\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:57 INFO 140166612858688] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=1.95405344168\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:57 INFO 140166612858688] Epoch[16] Batch [5]#011Speed: 192.99 samples/sec#011loss=1.954053\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:59 INFO 140166612858688] Epoch[16] Batch[10] avg_epoch_loss=1.957375\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:59 INFO 140166612858688] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=1.96136174202\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:59 INFO 140166612858688] Epoch[16] Batch [10]#011Speed: 188.75 samples/sec#011loss=1.961362\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:59 INFO 140166612858688] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4177.455186843872, \"sum\": 4177.455186843872, \"min\": 4177.455186843872}}, \"EndTime\": 1597990739.162141, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990734.984186}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:59 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=157.507568873 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:59 INFO 140166612858688] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:59 INFO 140166612858688] #quality_metric: host=algo-1, epoch=16, train loss <loss>=1.95737539638\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:59 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:18:59 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_989ccaae-302e-46c0-861b-0bc2c265308a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 122.61676788330078, \"sum\": 122.61676788330078, \"min\": 122.61676788330078}}, \"EndTime\": 1597990739.285334, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990739.162223}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:00 INFO 140166612858688] Epoch[17] Batch[0] avg_epoch_loss=2.122168\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:00 INFO 140166612858688] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=2.12216758728\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:01 INFO 140166612858688] Epoch[17] Batch[5] avg_epoch_loss=1.968061\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:01 INFO 140166612858688] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=1.96806130807\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:01 INFO 140166612858688] Epoch[17] Batch [5]#011Speed: 184.20 samples/sec#011loss=1.968061\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:03 INFO 140166612858688] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3868.5898780822754, \"sum\": 3868.5898780822754, \"min\": 3868.5898780822754}}, \"EndTime\": 1597990743.154087, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990739.28542}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:03 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=163.361522952 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:03 INFO 140166612858688] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:03 INFO 140166612858688] #quality_metric: host=algo-1, epoch=17, train loss <loss>=1.96099822521\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:03 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:03 INFO 140166612858688] Epoch[18] Batch[0] avg_epoch_loss=1.826265\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:03 INFO 140166612858688] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=1.82626473904\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:05 INFO 140166612858688] Epoch[18] Batch[5] avg_epoch_loss=1.903950\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:05 INFO 140166612858688] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=1.90394967794\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:05 INFO 140166612858688] Epoch[18] Batch [5]#011Speed: 188.75 samples/sec#011loss=1.903950\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:07 INFO 140166612858688] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3859.360933303833, \"sum\": 3859.360933303833, \"min\": 3859.360933303833}}, \"EndTime\": 1597990747.014028, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990743.154175}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:07 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=163.2348126 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:07 INFO 140166612858688] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:07 INFO 140166612858688] #quality_metric: host=algo-1, epoch=18, train loss <loss>=1.91459441185\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:07 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:07 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_0eec761d-dc5c-46bf-a8e6-bf53703efae1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 108.72292518615723, \"sum\": 108.72292518615723, \"min\": 108.72292518615723}}, \"EndTime\": 1597990747.123378, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990747.014097}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:07 INFO 140166612858688] Epoch[19] Batch[0] avg_epoch_loss=1.935909\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:07 INFO 140166612858688] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=1.93590927124\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:09 INFO 140166612858688] Epoch[19] Batch[5] avg_epoch_loss=1.913596\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:09 INFO 140166612858688] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=1.91359591484\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:09 INFO 140166612858688] Epoch[19] Batch [5]#011Speed: 187.00 samples/sec#011loss=1.913596\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:10 INFO 140166612858688] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3831.882953643799, \"sum\": 3831.882953643799, \"min\": 3831.882953643799}}, \"EndTime\": 1597990750.955386, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990747.123446}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:10 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=162.317327039 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:10 INFO 140166612858688] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:10 INFO 140166612858688] #quality_metric: host=algo-1, epoch=19, train loss <loss>=1.87005155087\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:10 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:11 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_6c0f31ca-92e4-403b-bfba-d3e444ae0375-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 110.68582534790039, \"sum\": 110.68582534790039, \"min\": 110.68582534790039}}, \"EndTime\": 1597990751.066767, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990750.955469}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:11 INFO 140166612858688] Epoch[20] Batch[0] avg_epoch_loss=1.864102\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:11 INFO 140166612858688] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=1.86410152912\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:19:13 INFO 140166612858688] Epoch[20] Batch[5] avg_epoch_loss=1.839258\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:13 INFO 140166612858688] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=1.83925809463\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:13 INFO 140166612858688] Epoch[20] Batch [5]#011Speed: 190.98 samples/sec#011loss=1.839258\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:15 INFO 140166612858688] Epoch[20] Batch[10] avg_epoch_loss=1.830511\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:15 INFO 140166612858688] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=1.82001342773\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:15 INFO 140166612858688] Epoch[20] Batch [10]#011Speed: 191.22 samples/sec#011loss=1.820013\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:15 INFO 140166612858688] processed a total of 729 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4488.264083862305, \"sum\": 4488.264083862305, \"min\": 4488.264083862305}}, \"EndTime\": 1597990755.555178, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990751.066835}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:15 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=162.418852447 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:15 INFO 140166612858688] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:15 INFO 140166612858688] #quality_metric: host=algo-1, epoch=20, train loss <loss>=1.98563878735\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:15 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:16 INFO 140166612858688] Epoch[21] Batch[0] avg_epoch_loss=1.959623\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:16 INFO 140166612858688] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=1.95962297916\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:18 INFO 140166612858688] Epoch[21] Batch[5] avg_epoch_loss=1.831425\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:18 INFO 140166612858688] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=1.83142544826\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:18 INFO 140166612858688] Epoch[21] Batch [5]#011Speed: 190.33 samples/sec#011loss=1.831425\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:19 INFO 140166612858688] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3845.350980758667, \"sum\": 3845.350980758667, \"min\": 3845.350980758667}}, \"EndTime\": 1597990759.401108, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990755.555265}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:19 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=166.429283717 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:19 INFO 140166612858688] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:19 INFO 140166612858688] #quality_metric: host=algo-1, epoch=21, train loss <loss>=1.81587263346\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:19 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:19 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_056391ad-d875-451e-98ab-e464812e6a72-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 121.48189544677734, \"sum\": 121.48189544677734, \"min\": 121.48189544677734}}, \"EndTime\": 1597990759.523218, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990759.401195}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:20 INFO 140166612858688] Epoch[22] Batch[0] avg_epoch_loss=1.743976\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:20 INFO 140166612858688] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=1.74397623539\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:21 INFO 140166612858688] Epoch[22] Batch[5] avg_epoch_loss=1.751236\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:21 INFO 140166612858688] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=1.7512362202\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:21 INFO 140166612858688] Epoch[22] Batch [5]#011Speed: 191.59 samples/sec#011loss=1.751236\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:23 INFO 140166612858688] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3794.4037914276123, \"sum\": 3794.4037914276123, \"min\": 3794.4037914276123}}, \"EndTime\": 1597990763.31778, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990759.523295}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:23 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=167.609473396 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:23 INFO 140166612858688] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:23 INFO 140166612858688] #quality_metric: host=algo-1, epoch=22, train loss <loss>=1.75969452858\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:23 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:23 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_ba2a8882-7d19-45c3-97e8-3c1d7cd2648f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 120.6960678100586, \"sum\": 120.6960678100586, \"min\": 120.6960678100586}}, \"EndTime\": 1597990763.43911, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990763.317868}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:24 INFO 140166612858688] Epoch[23] Batch[0] avg_epoch_loss=1.902116\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:24 INFO 140166612858688] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=1.90211570263\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:25 INFO 140166612858688] Epoch[23] Batch[5] avg_epoch_loss=1.831873\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:25 INFO 140166612858688] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=1.83187288046\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:25 INFO 140166612858688] Epoch[23] Batch [5]#011Speed: 189.43 samples/sec#011loss=1.831873\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:27 INFO 140166612858688] Epoch[23] Batch[10] avg_epoch_loss=1.820276\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:27 INFO 140166612858688] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=1.80635967255\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:27 INFO 140166612858688] Epoch[23] Batch [10]#011Speed: 187.77 samples/sec#011loss=1.806360\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:27 INFO 140166612858688] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4176.067113876343, \"sum\": 4176.067113876343, \"min\": 4176.067113876343}}, \"EndTime\": 1597990767.615342, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990763.439193}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:27 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=160.912020804 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:27 INFO 140166612858688] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:27 INFO 140166612858688] #quality_metric: host=algo-1, epoch=23, train loss <loss>=1.82027596777\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:27 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:28 INFO 140166612858688] Epoch[24] Batch[0] avg_epoch_loss=1.761545\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:28 INFO 140166612858688] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=1.76154506207\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:30 INFO 140166612858688] Epoch[24] Batch[5] avg_epoch_loss=1.769645\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:30 INFO 140166612858688] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=1.76964479685\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:30 INFO 140166612858688] Epoch[24] Batch [5]#011Speed: 185.62 samples/sec#011loss=1.769645\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:31 INFO 140166612858688] Epoch[24] Batch[10] avg_epoch_loss=1.738369\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:31 INFO 140166612858688] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=1.70083806515\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:31 INFO 140166612858688] Epoch[24] Batch [10]#011Speed: 188.01 samples/sec#011loss=1.700838\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:31 INFO 140166612858688] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4189.4471645355225, \"sum\": 4189.4471645355225, \"min\": 4189.4471645355225}}, \"EndTime\": 1597990771.805357, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990767.615423}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:31 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=155.386062469 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:31 INFO 140166612858688] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:31 INFO 140166612858688] #quality_metric: host=algo-1, epoch=24, train loss <loss>=1.73836900971\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:31 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:31 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_c75b3ee0-0c45-4748-aab1-263dd4759b96-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 110.69202423095703, \"sum\": 110.69202423095703, \"min\": 110.69202423095703}}, \"EndTime\": 1597990771.916663, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990771.805432}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:32 INFO 140166612858688] Epoch[25] Batch[0] avg_epoch_loss=1.610122\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:32 INFO 140166612858688] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=1.61012196541\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:34 INFO 140166612858688] Epoch[25] Batch[5] avg_epoch_loss=1.674372\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:34 INFO 140166612858688] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=1.6743721962\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:34 INFO 140166612858688] Epoch[25] Batch [5]#011Speed: 187.96 samples/sec#011loss=1.674372\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:35 INFO 140166612858688] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3812.708854675293, \"sum\": 3812.708854675293, \"min\": 3812.708854675293}}, \"EndTime\": 1597990775.72953, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990771.916751}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:35 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=161.036128884 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:35 INFO 140166612858688] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:35 INFO 140166612858688] #quality_metric: host=algo-1, epoch=25, train loss <loss>=1.65980935097\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:35 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:35 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_46157e9c-6a1b-4533-8a4f-53355af5d095-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 109.46178436279297, \"sum\": 109.46178436279297, \"min\": 109.46178436279297}}, \"EndTime\": 1597990775.839619, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990775.729593}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:36 INFO 140166612858688] Epoch[26] Batch[0] avg_epoch_loss=1.916599\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:36 INFO 140166612858688] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=1.91659879684\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:38 INFO 140166612858688] Epoch[26] Batch[5] avg_epoch_loss=1.694695\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:38 INFO 140166612858688] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=1.69469473759\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:38 INFO 140166612858688] Epoch[26] Batch [5]#011Speed: 190.75 samples/sec#011loss=1.694695\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:39 INFO 140166612858688] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3827.249050140381, \"sum\": 3827.249050140381, \"min\": 3827.249050140381}}, \"EndTime\": 1597990779.667024, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990775.839703}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:39 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=166.433045464 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:39 INFO 140166612858688] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:39 INFO 140166612858688] #quality_metric: host=algo-1, epoch=26, train loss <loss>=1.70861854553\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:39 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:40 INFO 140166612858688] Epoch[27] Batch[0] avg_epoch_loss=1.733434\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:40 INFO 140166612858688] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=1.73343360424\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:42 INFO 140166612858688] Epoch[27] Batch[5] avg_epoch_loss=1.741988\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:42 INFO 140166612858688] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=1.74198846022\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:42 INFO 140166612858688] Epoch[27] Batch [5]#011Speed: 190.51 samples/sec#011loss=1.741988\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:43 INFO 140166612858688] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3779.1290283203125, \"sum\": 3779.1290283203125, \"min\": 3779.1290283203125}}, \"EndTime\": 1597990783.446779, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990779.667103}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:43 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=162.465876303 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:43 INFO 140166612858688] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:43 INFO 140166612858688] #quality_metric: host=algo-1, epoch=27, train loss <loss>=1.68341810703\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:43 INFO 140166612858688] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:19:44 INFO 140166612858688] Epoch[28] Batch[0] avg_epoch_loss=1.640810\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:44 INFO 140166612858688] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=1.64080989361\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:45 INFO 140166612858688] Epoch[28] Batch[5] avg_epoch_loss=1.662596\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:45 INFO 140166612858688] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=1.66259590785\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:45 INFO 140166612858688] Epoch[28] Batch [5]#011Speed: 193.28 samples/sec#011loss=1.662596\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:47 INFO 140166612858688] Epoch[28] Batch[10] avg_epoch_loss=1.622225\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:47 INFO 140166612858688] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=1.57378082275\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:47 INFO 140166612858688] Epoch[28] Batch [10]#011Speed: 190.01 samples/sec#011loss=1.573781\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:47 INFO 140166612858688] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4140.050888061523, \"sum\": 4140.050888061523, \"min\": 4140.050888061523}}, \"EndTime\": 1597990787.587406, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990783.446864}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:47 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=158.689013423 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:47 INFO 140166612858688] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:47 INFO 140166612858688] #quality_metric: host=algo-1, epoch=28, train loss <loss>=1.62222541462\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:47 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:47 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_992bc150-c1e7-44f8-91fb-b8d2be63309d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 123.0618953704834, \"sum\": 123.0618953704834, \"min\": 123.0618953704834}}, \"EndTime\": 1597990787.711047, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990787.587488}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:48 INFO 140166612858688] Epoch[29] Batch[0] avg_epoch_loss=1.478327\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:48 INFO 140166612858688] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=1.4783270359\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:50 INFO 140166612858688] Epoch[29] Batch[5] avg_epoch_loss=1.623419\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:50 INFO 140166612858688] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=1.62341862917\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:50 INFO 140166612858688] Epoch[29] Batch [5]#011Speed: 187.87 samples/sec#011loss=1.623419\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:51 INFO 140166612858688] Epoch[29] Batch[10] avg_epoch_loss=1.656333\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:51 INFO 140166612858688] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=1.69582922459\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:51 INFO 140166612858688] Epoch[29] Batch [10]#011Speed: 188.39 samples/sec#011loss=1.695829\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:51 INFO 140166612858688] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4170.630931854248, \"sum\": 4170.630931854248, \"min\": 4170.630931854248}}, \"EndTime\": 1597990791.881832, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990787.711129}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:51 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=157.526078806 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:51 INFO 140166612858688] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:51 INFO 140166612858688] #quality_metric: host=algo-1, epoch=29, train loss <loss>=1.65633253618\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:51 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:52 INFO 140166612858688] Epoch[30] Batch[0] avg_epoch_loss=1.813203\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:52 INFO 140166612858688] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=1.81320345402\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:54 INFO 140166612858688] Epoch[30] Batch[5] avg_epoch_loss=1.688490\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:54 INFO 140166612858688] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=1.68848969539\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:54 INFO 140166612858688] Epoch[30] Batch [5]#011Speed: 187.10 samples/sec#011loss=1.688490\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:56 INFO 140166612858688] Epoch[30] Batch[10] avg_epoch_loss=1.701483\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:56 INFO 140166612858688] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=1.71707444191\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:56 INFO 140166612858688] Epoch[30] Batch [10]#011Speed: 191.31 samples/sec#011loss=1.717074\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:56 INFO 140166612858688] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4145.145893096924, \"sum\": 4145.145893096924, \"min\": 4145.145893096924}}, \"EndTime\": 1597990796.027489, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990791.881896}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:56 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=157.04642474 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:56 INFO 140166612858688] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:56 INFO 140166612858688] #quality_metric: host=algo-1, epoch=30, train loss <loss>=1.70148276199\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:56 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:56 INFO 140166612858688] Epoch[31] Batch[0] avg_epoch_loss=1.721113\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:56 INFO 140166612858688] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=1.72111308575\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:58 INFO 140166612858688] Epoch[31] Batch[5] avg_epoch_loss=1.615195\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:58 INFO 140166612858688] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=1.61519457897\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:58 INFO 140166612858688] Epoch[31] Batch [5]#011Speed: 190.07 samples/sec#011loss=1.615195\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:59 INFO 140166612858688] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3836.289882659912, \"sum\": 3836.289882659912, \"min\": 3836.289882659912}}, \"EndTime\": 1597990799.864324, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990796.027574}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:59 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=166.302256581 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:59 INFO 140166612858688] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:59 INFO 140166612858688] #quality_metric: host=algo-1, epoch=31, train loss <loss>=1.66187831163\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:19:59 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:00 INFO 140166612858688] Epoch[32] Batch[0] avg_epoch_loss=1.591355\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:00 INFO 140166612858688] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=1.59135520458\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:02 INFO 140166612858688] Epoch[32] Batch[5] avg_epoch_loss=1.585070\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:02 INFO 140166612858688] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=1.58507029215\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:02 INFO 140166612858688] Epoch[32] Batch [5]#011Speed: 188.90 samples/sec#011loss=1.585070\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:04 INFO 140166612858688] Epoch[32] Batch[10] avg_epoch_loss=1.620809\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:04 INFO 140166612858688] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=1.66369488239\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:04 INFO 140166612858688] Epoch[32] Batch [10]#011Speed: 189.79 samples/sec#011loss=1.663695\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:04 INFO 140166612858688] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4154.6790599823, \"sum\": 4154.6790599823, \"min\": 4154.6790599823}}, \"EndTime\": 1597990804.019549, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990799.864388}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:04 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=156.686163828 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:04 INFO 140166612858688] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:04 INFO 140166612858688] #quality_metric: host=algo-1, epoch=32, train loss <loss>=1.62080874226\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:04 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:04 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_bf6dfcf5-d276-4c82-b92b-99a67f9ad8da-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 118.90482902526855, \"sum\": 118.90482902526855, \"min\": 118.90482902526855}}, \"EndTime\": 1597990804.139053, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990804.019631}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:20:04 INFO 140166612858688] Epoch[33] Batch[0] avg_epoch_loss=1.480381\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:04 INFO 140166612858688] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=1.48038113117\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:06 INFO 140166612858688] Epoch[33] Batch[5] avg_epoch_loss=1.552085\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:06 INFO 140166612858688] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=1.5520846645\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:06 INFO 140166612858688] Epoch[33] Batch [5]#011Speed: 189.28 samples/sec#011loss=1.552085\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:07 INFO 140166612858688] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3833.6730003356934, \"sum\": 3833.6730003356934, \"min\": 3833.6730003356934}}, \"EndTime\": 1597990807.972864, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990804.13913}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:07 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=157.286429344 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:07 INFO 140166612858688] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:07 INFO 140166612858688] #quality_metric: host=algo-1, epoch=33, train loss <loss>=1.71751638651\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:07 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:08 INFO 140166612858688] Epoch[34] Batch[0] avg_epoch_loss=1.532808\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:08 INFO 140166612858688] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=1.53280770779\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:10 INFO 140166612858688] Epoch[34] Batch[5] avg_epoch_loss=1.498204\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:10 INFO 140166612858688] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=1.498204271\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:10 INFO 140166612858688] Epoch[34] Batch [5]#011Speed: 186.95 samples/sec#011loss=1.498204\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:11 INFO 140166612858688] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3817.8529739379883, \"sum\": 3817.8529739379883, \"min\": 3817.8529739379883}}, \"EndTime\": 1597990811.791289, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990807.972927}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:11 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=162.651665556 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:11 INFO 140166612858688] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:11 INFO 140166612858688] #quality_metric: host=algo-1, epoch=34, train loss <loss>=1.50350311995\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:11 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:11 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_f1911b39-650e-4e2b-af3a-7868d83e30e9-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 110.55302619934082, \"sum\": 110.55302619934082, \"min\": 110.55302619934082}}, \"EndTime\": 1597990811.902445, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990811.791365}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:12 INFO 140166612858688] Epoch[35] Batch[0] avg_epoch_loss=1.610937\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:12 INFO 140166612858688] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=1.61093699932\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:14 INFO 140166612858688] Epoch[35] Batch[5] avg_epoch_loss=1.575193\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:14 INFO 140166612858688] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=1.5751931866\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:14 INFO 140166612858688] Epoch[35] Batch [5]#011Speed: 183.17 samples/sec#011loss=1.575193\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:16 INFO 140166612858688] Epoch[35] Batch[10] avg_epoch_loss=1.556527\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:16 INFO 140166612858688] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=1.53412737846\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:16 INFO 140166612858688] Epoch[35] Batch [10]#011Speed: 190.54 samples/sec#011loss=1.534127\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:16 INFO 140166612858688] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4189.8651123046875, \"sum\": 4189.8651123046875, \"min\": 4189.8651123046875}}, \"EndTime\": 1597990816.092462, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990811.90252}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:16 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=153.699684217 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:16 INFO 140166612858688] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:16 INFO 140166612858688] #quality_metric: host=algo-1, epoch=35, train loss <loss>=1.55652691017\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:16 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:16 INFO 140166612858688] Epoch[36] Batch[0] avg_epoch_loss=1.588087\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:16 INFO 140166612858688] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=1.58808684349\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:18 INFO 140166612858688] Epoch[36] Batch[5] avg_epoch_loss=1.570882\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:18 INFO 140166612858688] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=1.57088174423\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:18 INFO 140166612858688] Epoch[36] Batch [5]#011Speed: 190.65 samples/sec#011loss=1.570882\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:20 INFO 140166612858688] Epoch[36] Batch[10] avg_epoch_loss=1.553855\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:20 INFO 140166612858688] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=1.53342187405\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:20 INFO 140166612858688] Epoch[36] Batch [10]#011Speed: 183.83 samples/sec#011loss=1.533422\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:20 INFO 140166612858688] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4214.672088623047, \"sum\": 4214.672088623047, \"min\": 4214.672088623047}}, \"EndTime\": 1597990820.307656, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990816.092545}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:20 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=157.065947148 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:20 INFO 140166612858688] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:20 INFO 140166612858688] #quality_metric: host=algo-1, epoch=36, train loss <loss>=1.55385453051\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:20 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:21 INFO 140166612858688] Epoch[37] Batch[0] avg_epoch_loss=1.453537\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:21 INFO 140166612858688] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=1.45353710651\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:22 INFO 140166612858688] Epoch[37] Batch[5] avg_epoch_loss=1.497870\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:22 INFO 140166612858688] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=1.49787038565\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:22 INFO 140166612858688] Epoch[37] Batch [5]#011Speed: 191.71 samples/sec#011loss=1.497870\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:24 INFO 140166612858688] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3821.0980892181396, \"sum\": 3821.0980892181396, \"min\": 3821.0980892181396}}, \"EndTime\": 1597990824.129258, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990820.307736}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:24 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=167.223687242 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:24 INFO 140166612858688] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:24 INFO 140166612858688] #quality_metric: host=algo-1, epoch=37, train loss <loss>=1.51647399664\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:24 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:24 INFO 140166612858688] Epoch[38] Batch[0] avg_epoch_loss=1.467756\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:24 INFO 140166612858688] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=1.46775639057\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:26 INFO 140166612858688] Epoch[38] Batch[5] avg_epoch_loss=1.489114\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:26 INFO 140166612858688] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=1.48911388715\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:26 INFO 140166612858688] Epoch[38] Batch [5]#011Speed: 189.92 samples/sec#011loss=1.489114\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:27 INFO 140166612858688] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3824.8298168182373, \"sum\": 3824.8298168182373, \"min\": 3824.8298168182373}}, \"EndTime\": 1597990827.954764, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990824.129348}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:27 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=164.446933205 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:27 INFO 140166612858688] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:27 INFO 140166612858688] #quality_metric: host=algo-1, epoch=38, train loss <loss>=1.50378323793\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:27 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:28 INFO 140166612858688] Epoch[39] Batch[0] avg_epoch_loss=1.446271\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:28 INFO 140166612858688] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=1.44627141953\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:30 INFO 140166612858688] Epoch[39] Batch[5] avg_epoch_loss=1.517091\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:30 INFO 140166612858688] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=1.51709145308\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:30 INFO 140166612858688] Epoch[39] Batch [5]#011Speed: 188.10 samples/sec#011loss=1.517091\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:20:31 INFO 140166612858688] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3810.6439113616943, \"sum\": 3810.6439113616943, \"min\": 3810.6439113616943}}, \"EndTime\": 1597990831.765977, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990827.954842}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:31 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=165.583114489 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:31 INFO 140166612858688] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:31 INFO 140166612858688] #quality_metric: host=algo-1, epoch=39, train loss <loss>=1.4506909132\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:31 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:31 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_24879673-04b3-4dbf-88c4-084fd40eb44d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 118.06893348693848, \"sum\": 118.06893348693848, \"min\": 118.06893348693848}}, \"EndTime\": 1597990831.884671, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990831.766066}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:32 INFO 140166612858688] Epoch[40] Batch[0] avg_epoch_loss=1.319557\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:32 INFO 140166612858688] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=1.31955718994\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:34 INFO 140166612858688] Epoch[40] Batch[5] avg_epoch_loss=1.495661\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:34 INFO 140166612858688] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=1.49566111962\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:34 INFO 140166612858688] Epoch[40] Batch [5]#011Speed: 186.46 samples/sec#011loss=1.495661\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:36 INFO 140166612858688] Epoch[40] Batch[10] avg_epoch_loss=1.452583\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:36 INFO 140166612858688] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=1.40088877678\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:36 INFO 140166612858688] Epoch[40] Batch [10]#011Speed: 190.59 samples/sec#011loss=1.400889\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:36 INFO 140166612858688] processed a total of 685 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4187.870025634766, \"sum\": 4187.870025634766, \"min\": 4187.870025634766}}, \"EndTime\": 1597990836.072699, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990831.88475}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:36 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=163.562719405 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:36 INFO 140166612858688] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:36 INFO 140166612858688] #quality_metric: host=algo-1, epoch=40, train loss <loss>=1.45258278197\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:36 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:36 INFO 140166612858688] Epoch[41] Batch[0] avg_epoch_loss=1.411004\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:36 INFO 140166612858688] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=1.41100430489\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:38 INFO 140166612858688] Epoch[41] Batch[5] avg_epoch_loss=1.449458\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:38 INFO 140166612858688] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=1.44945822159\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:38 INFO 140166612858688] Epoch[41] Batch [5]#011Speed: 187.36 samples/sec#011loss=1.449458\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:39 INFO 140166612858688] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3869.70591545105, \"sum\": 3869.70591545105, \"min\": 3869.70591545105}}, \"EndTime\": 1597990839.942974, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990836.072784}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:39 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=164.348086486 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:39 INFO 140166612858688] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:39 INFO 140166612858688] #quality_metric: host=algo-1, epoch=41, train loss <loss>=1.49483480453\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:39 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:40 INFO 140166612858688] Epoch[42] Batch[0] avg_epoch_loss=1.401303\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:40 INFO 140166612858688] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=1.40130293369\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:42 INFO 140166612858688] Epoch[42] Batch[5] avg_epoch_loss=1.443055\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:42 INFO 140166612858688] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=1.44305549065\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:42 INFO 140166612858688] Epoch[42] Batch [5]#011Speed: 192.55 samples/sec#011loss=1.443055\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:44 INFO 140166612858688] Epoch[42] Batch[10] avg_epoch_loss=1.442998\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:44 INFO 140166612858688] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=1.44292981625\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:44 INFO 140166612858688] Epoch[42] Batch [10]#011Speed: 191.86 samples/sec#011loss=1.442930\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:44 INFO 140166612858688] processed a total of 693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4120.002031326294, \"sum\": 4120.002031326294, \"min\": 4120.002031326294}}, \"EndTime\": 1597990844.063545, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990839.943061}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:44 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=168.198700254 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:44 INFO 140166612858688] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:44 INFO 140166612858688] #quality_metric: host=algo-1, epoch=42, train loss <loss>=1.44299836592\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:44 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:44 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_56d80872-450f-4fc8-b7e5-814129e391a9-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 170.45307159423828, \"sum\": 170.45307159423828, \"min\": 170.45307159423828}}, \"EndTime\": 1597990844.234656, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990844.063631}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:44 INFO 140166612858688] Epoch[43] Batch[0] avg_epoch_loss=1.472642\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:44 INFO 140166612858688] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=1.47264194489\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:46 INFO 140166612858688] Epoch[43] Batch[5] avg_epoch_loss=1.433162\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:46 INFO 140166612858688] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=1.43316225211\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:46 INFO 140166612858688] Epoch[43] Batch [5]#011Speed: 189.83 samples/sec#011loss=1.433162\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:48 INFO 140166612858688] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3800.448179244995, \"sum\": 3800.448179244995, \"min\": 3800.448179244995}}, \"EndTime\": 1597990848.035258, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990844.234737}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:48 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=162.869917565 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:48 INFO 140166612858688] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:48 INFO 140166612858688] #quality_metric: host=algo-1, epoch=43, train loss <loss>=1.42645900249\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:48 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:48 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_3d1891f4-2f7b-499a-903f-bd4b9e527535-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 116.7299747467041, \"sum\": 116.7299747467041, \"min\": 116.7299747467041}}, \"EndTime\": 1597990848.152612, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990848.035349}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:48 INFO 140166612858688] Epoch[44] Batch[0] avg_epoch_loss=1.363085\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:48 INFO 140166612858688] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=1.36308503151\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:50 INFO 140166612858688] Epoch[44] Batch[5] avg_epoch_loss=1.506359\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:50 INFO 140166612858688] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=1.5063586235\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:50 INFO 140166612858688] Epoch[44] Batch [5]#011Speed: 189.10 samples/sec#011loss=1.506359\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:51 INFO 140166612858688] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3794.806957244873, \"sum\": 3794.806957244873, \"min\": 3794.806957244873}}, \"EndTime\": 1597990851.947553, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990848.152681}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:51 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=166.010707342 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:51 INFO 140166612858688] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:51 INFO 140166612858688] #quality_metric: host=algo-1, epoch=44, train loss <loss>=1.46128104925\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:51 INFO 140166612858688] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:20:52 INFO 140166612858688] Epoch[45] Batch[0] avg_epoch_loss=1.513856\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:52 INFO 140166612858688] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=1.51385593414\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:54 INFO 140166612858688] Epoch[45] Batch[5] avg_epoch_loss=1.396161\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:54 INFO 140166612858688] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=1.39616117875\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:54 INFO 140166612858688] Epoch[45] Batch [5]#011Speed: 188.27 samples/sec#011loss=1.396161\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:56 INFO 140166612858688] Epoch[45] Batch[10] avg_epoch_loss=1.383478\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:56 INFO 140166612858688] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=1.36825795174\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:56 INFO 140166612858688] Epoch[45] Batch [10]#011Speed: 190.12 samples/sec#011loss=1.368258\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:56 INFO 140166612858688] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4162.346839904785, \"sum\": 4162.346839904785, \"min\": 4162.346839904785}}, \"EndTime\": 1597990856.110475, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990851.947643}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:56 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=158.079177284 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:56 INFO 140166612858688] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:56 INFO 140166612858688] #quality_metric: host=algo-1, epoch=45, train loss <loss>=1.38347789374\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:56 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:56 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_a748008c-faac-4c86-9f23-d171b852db55-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 125.03695487976074, \"sum\": 125.03695487976074, \"min\": 125.03695487976074}}, \"EndTime\": 1597990856.236095, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990856.110558}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:57 INFO 140166612858688] Epoch[46] Batch[0] avg_epoch_loss=1.634877\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:57 INFO 140166612858688] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=1.6348772049\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:58 INFO 140166612858688] Epoch[46] Batch[5] avg_epoch_loss=1.504390\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:58 INFO 140166612858688] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=1.5043904384\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:20:58 INFO 140166612858688] Epoch[46] Batch [5]#011Speed: 190.21 samples/sec#011loss=1.504390\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:00 INFO 140166612858688] Epoch[46] Batch[10] avg_epoch_loss=1.597740\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:00 INFO 140166612858688] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=1.70975861549\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:00 INFO 140166612858688] Epoch[46] Batch [10]#011Speed: 184.85 samples/sec#011loss=1.709759\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:00 INFO 140166612858688] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4190.451860427856, \"sum\": 4190.451860427856, \"min\": 4190.451860427856}}, \"EndTime\": 1597990860.426723, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990856.236193}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:00 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=156.780211106 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:00 INFO 140166612858688] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:00 INFO 140166612858688] #quality_metric: host=algo-1, epoch=46, train loss <loss>=1.59773960981\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:00 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:01 INFO 140166612858688] Epoch[47] Batch[0] avg_epoch_loss=1.621102\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:01 INFO 140166612858688] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=1.62110197544\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:02 INFO 140166612858688] Epoch[47] Batch[5] avg_epoch_loss=1.448315\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:02 INFO 140166612858688] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=1.448315382\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:02 INFO 140166612858688] Epoch[47] Batch [5]#011Speed: 184.27 samples/sec#011loss=1.448315\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:04 INFO 140166612858688] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3861.182928085327, \"sum\": 3861.182928085327, \"min\": 3861.182928085327}}, \"EndTime\": 1597990864.288489, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990860.426807}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:04 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=163.41591135 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:04 INFO 140166612858688] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:04 INFO 140166612858688] #quality_metric: host=algo-1, epoch=47, train loss <loss>=1.45760023594\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:04 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:05 INFO 140166612858688] Epoch[48] Batch[0] avg_epoch_loss=1.551017\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:05 INFO 140166612858688] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=1.55101692677\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:06 INFO 140166612858688] Epoch[48] Batch[5] avg_epoch_loss=1.473600\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:06 INFO 140166612858688] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=1.47359953324\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:06 INFO 140166612858688] Epoch[48] Batch [5]#011Speed: 187.59 samples/sec#011loss=1.473600\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:08 INFO 140166612858688] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3886.229991912842, \"sum\": 3886.229991912842, \"min\": 3886.229991912842}}, \"EndTime\": 1597990868.175315, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990864.288578}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:08 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=160.561507382 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:08 INFO 140166612858688] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:08 INFO 140166612858688] #quality_metric: host=algo-1, epoch=48, train loss <loss>=1.44508577585\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:08 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:08 INFO 140166612858688] Epoch[49] Batch[0] avg_epoch_loss=1.515157\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:08 INFO 140166612858688] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=1.51515710354\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:10 INFO 140166612858688] Epoch[49] Batch[5] avg_epoch_loss=1.420206\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:10 INFO 140166612858688] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=1.42020626863\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:10 INFO 140166612858688] Epoch[49] Batch [5]#011Speed: 186.61 samples/sec#011loss=1.420206\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:12 INFO 140166612858688] processed a total of 602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3837.038040161133, \"sum\": 3837.038040161133, \"min\": 3837.038040161133}}, \"EndTime\": 1597990872.013001, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990868.175402}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:12 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=156.886538042 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:12 INFO 140166612858688] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:12 INFO 140166612858688] #quality_metric: host=algo-1, epoch=49, train loss <loss>=1.34422130585\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:12 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:12 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_0d7f0ac7-523b-46c0-a958-e1494b3ed671-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 111.63997650146484, \"sum\": 111.63997650146484, \"min\": 111.63997650146484}}, \"EndTime\": 1597990872.125339, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990872.013087}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:12 INFO 140166612858688] Epoch[50] Batch[0] avg_epoch_loss=1.301001\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:12 INFO 140166612858688] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=1.30100095272\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:14 INFO 140166612858688] Epoch[50] Batch[5] avg_epoch_loss=1.357267\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:14 INFO 140166612858688] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=1.35726706187\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:14 INFO 140166612858688] Epoch[50] Batch [5]#011Speed: 188.03 samples/sec#011loss=1.357267\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:16 INFO 140166612858688] Epoch[50] Batch[10] avg_epoch_loss=1.258413\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:16 INFO 140166612858688] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=1.13978898525\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:16 INFO 140166612858688] Epoch[50] Batch [10]#011Speed: 189.78 samples/sec#011loss=1.139789\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:16 INFO 140166612858688] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4147.665977478027, \"sum\": 4147.665977478027, \"min\": 4147.665977478027}}, \"EndTime\": 1597990876.273149, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990872.12541}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:16 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=155.504499258 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:16 INFO 140166612858688] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:16 INFO 140166612858688] #quality_metric: host=algo-1, epoch=50, train loss <loss>=1.25841339068\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:16 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:16 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_6de6007c-aea1-4e30-9a51-e8c44bda7269-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 117.73991584777832, \"sum\": 117.73991584777832, \"min\": 117.73991584777832}}, \"EndTime\": 1597990876.391482, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990876.273231}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:17 INFO 140166612858688] Epoch[51] Batch[0] avg_epoch_loss=1.435836\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:17 INFO 140166612858688] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=1.43583595753\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:18 INFO 140166612858688] Epoch[51] Batch[5] avg_epoch_loss=1.369436\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:18 INFO 140166612858688] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=1.36943612496\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:18 INFO 140166612858688] Epoch[51] Batch [5]#011Speed: 189.63 samples/sec#011loss=1.369436\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:20 INFO 140166612858688] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3830.7719230651855, \"sum\": 3830.7719230651855, \"min\": 3830.7719230651855}}, \"EndTime\": 1597990880.222414, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990876.391566}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:20 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=166.540377251 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:20 INFO 140166612858688] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:20 INFO 140166612858688] #quality_metric: host=algo-1, epoch=51, train loss <loss>=1.36741631031\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:20 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:21 INFO 140166612858688] Epoch[52] Batch[0] avg_epoch_loss=1.168873\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:21 INFO 140166612858688] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=1.16887259483\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:21:22 INFO 140166612858688] Epoch[52] Batch[5] avg_epoch_loss=1.355521\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:22 INFO 140166612858688] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=1.35552128156\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:22 INFO 140166612858688] Epoch[52] Batch [5]#011Speed: 192.10 samples/sec#011loss=1.355521\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:24 INFO 140166612858688] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3812.9830360412598, \"sum\": 3812.9830360412598, \"min\": 3812.9830360412598}}, \"EndTime\": 1597990884.035964, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990880.222501}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:24 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=167.57982347 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:24 INFO 140166612858688] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:24 INFO 140166612858688] #quality_metric: host=algo-1, epoch=52, train loss <loss>=1.36338887215\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:24 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:24 INFO 140166612858688] Epoch[53] Batch[0] avg_epoch_loss=1.422344\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:24 INFO 140166612858688] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=1.42234408855\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:26 INFO 140166612858688] Epoch[53] Batch[5] avg_epoch_loss=1.300025\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:26 INFO 140166612858688] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=1.30002520482\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:26 INFO 140166612858688] Epoch[53] Batch [5]#011Speed: 189.62 samples/sec#011loss=1.300025\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:27 INFO 140166612858688] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3825.2711296081543, \"sum\": 3825.2711296081543, \"min\": 3825.2711296081543}}, \"EndTime\": 1597990887.861835, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990884.036048}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:27 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=163.904903532 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:27 INFO 140166612858688] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:27 INFO 140166612858688] #quality_metric: host=algo-1, epoch=53, train loss <loss>=1.30641604662\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:27 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:28 INFO 140166612858688] Epoch[54] Batch[0] avg_epoch_loss=1.498420\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:28 INFO 140166612858688] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=1.49841952324\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:30 INFO 140166612858688] Epoch[54] Batch[5] avg_epoch_loss=1.363367\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:30 INFO 140166612858688] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=1.36336678267\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:30 INFO 140166612858688] Epoch[54] Batch [5]#011Speed: 188.42 samples/sec#011loss=1.363367\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:31 INFO 140166612858688] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3828.719139099121, \"sum\": 3828.719139099121, \"min\": 3828.719139099121}}, \"EndTime\": 1597990891.691135, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990887.861911}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:31 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=161.928434424 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:31 INFO 140166612858688] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:31 INFO 140166612858688] #quality_metric: host=algo-1, epoch=54, train loss <loss>=1.32367795706\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:31 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:32 INFO 140166612858688] Epoch[55] Batch[0] avg_epoch_loss=1.331012\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:32 INFO 140166612858688] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=1.3310123682\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:34 INFO 140166612858688] Epoch[55] Batch[5] avg_epoch_loss=1.289493\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:34 INFO 140166612858688] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=1.28949284554\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:34 INFO 140166612858688] Epoch[55] Batch [5]#011Speed: 192.43 samples/sec#011loss=1.289493\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:35 INFO 140166612858688] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3791.90993309021, \"sum\": 3791.90993309021, \"min\": 3791.90993309021}}, \"EndTime\": 1597990895.483673, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990891.691224}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:35 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=166.664819949 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:35 INFO 140166612858688] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:35 INFO 140166612858688] #quality_metric: host=algo-1, epoch=55, train loss <loss>=1.31765911579\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:35 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:36 INFO 140166612858688] Epoch[56] Batch[0] avg_epoch_loss=1.334564\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:36 INFO 140166612858688] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=1.3345644474\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:38 INFO 140166612858688] Epoch[56] Batch[5] avg_epoch_loss=1.289308\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:38 INFO 140166612858688] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=1.28930813074\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:38 INFO 140166612858688] Epoch[56] Batch [5]#011Speed: 186.39 samples/sec#011loss=1.289308\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:39 INFO 140166612858688] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3894.0658569335938, \"sum\": 3894.0658569335938, \"min\": 3894.0658569335938}}, \"EndTime\": 1597990899.378361, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990895.483762}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:39 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=163.063132969 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:39 INFO 140166612858688] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:39 INFO 140166612858688] #quality_metric: host=algo-1, epoch=56, train loss <loss>=1.3305742979\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:39 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:40 INFO 140166612858688] Epoch[57] Batch[0] avg_epoch_loss=1.282130\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:40 INFO 140166612858688] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=1.28213012218\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:41 INFO 140166612858688] Epoch[57] Batch[5] avg_epoch_loss=1.350787\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:41 INFO 140166612858688] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=1.35078660647\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:41 INFO 140166612858688] Epoch[57] Batch [5]#011Speed: 187.23 samples/sec#011loss=1.350787\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:43 INFO 140166612858688] Epoch[57] Batch[10] avg_epoch_loss=1.364088\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:43 INFO 140166612858688] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=1.38005023003\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:43 INFO 140166612858688] Epoch[57] Batch [10]#011Speed: 190.62 samples/sec#011loss=1.380050\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:43 INFO 140166612858688] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4169.116020202637, \"sum\": 4169.116020202637, \"min\": 4169.116020202637}}, \"EndTime\": 1597990903.548091, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990899.378449}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:43 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=154.463719438 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:43 INFO 140166612858688] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:43 INFO 140166612858688] #quality_metric: host=algo-1, epoch=57, train loss <loss>=1.36408825354\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:43 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:44 INFO 140166612858688] Epoch[58] Batch[0] avg_epoch_loss=1.301858\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:44 INFO 140166612858688] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=1.30185818672\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:46 INFO 140166612858688] Epoch[58] Batch[5] avg_epoch_loss=1.335137\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:46 INFO 140166612858688] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=1.33513742685\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:46 INFO 140166612858688] Epoch[58] Batch [5]#011Speed: 192.43 samples/sec#011loss=1.335137\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:47 INFO 140166612858688] Epoch[58] Batch[10] avg_epoch_loss=1.305570\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:47 INFO 140166612858688] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=1.2700889349\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:47 INFO 140166612858688] Epoch[58] Batch [10]#011Speed: 190.73 samples/sec#011loss=1.270089\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:47 INFO 140166612858688] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4148.34189414978, \"sum\": 4148.34189414978, \"min\": 4148.34189414978}}, \"EndTime\": 1597990907.696998, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990903.548199}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:47 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=160.78275294 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:47 INFO 140166612858688] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:47 INFO 140166612858688] #quality_metric: host=algo-1, epoch=58, train loss <loss>=1.30556993051\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:47 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:48 INFO 140166612858688] Epoch[59] Batch[0] avg_epoch_loss=1.296320\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:48 INFO 140166612858688] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=1.29631984234\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:50 INFO 140166612858688] Epoch[59] Batch[5] avg_epoch_loss=1.260740\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:50 INFO 140166612858688] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=1.26074026028\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:50 INFO 140166612858688] Epoch[59] Batch [5]#011Speed: 189.52 samples/sec#011loss=1.260740\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:51 INFO 140166612858688] Epoch[59] Batch[10] avg_epoch_loss=1.238025\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:51 INFO 140166612858688] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=1.21076724529\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:51 INFO 140166612858688] Epoch[59] Batch [10]#011Speed: 188.83 samples/sec#011loss=1.210767\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:51 INFO 140166612858688] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4149.4598388671875, \"sum\": 4149.4598388671875, \"min\": 4149.4598388671875}}, \"EndTime\": 1597990911.847046, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990907.697071}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:51 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=155.437185493 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:51 INFO 140166612858688] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:51 INFO 140166612858688] #quality_metric: host=algo-1, epoch=59, train loss <loss>=1.23802525347\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:51 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:51 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_e13ebca2-2a3c-4a29-816c-c6eab7837f83-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 113.84391784667969, \"sum\": 113.84391784667969, \"min\": 113.84391784667969}}, \"EndTime\": 1597990911.961497, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990911.847129}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:52 INFO 140166612858688] Epoch[60] Batch[0] avg_epoch_loss=1.242627\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:52 INFO 140166612858688] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=1.24262726307\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:21:54 INFO 140166612858688] Epoch[60] Batch[5] avg_epoch_loss=1.288134\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:54 INFO 140166612858688] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=1.2881338199\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:54 INFO 140166612858688] Epoch[60] Batch [5]#011Speed: 192.02 samples/sec#011loss=1.288134\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:56 INFO 140166612858688] Epoch[60] Batch[10] avg_epoch_loss=1.322885\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:56 INFO 140166612858688] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=1.36458699703\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:56 INFO 140166612858688] Epoch[60] Batch [10]#011Speed: 190.18 samples/sec#011loss=1.364587\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:56 INFO 140166612858688] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4118.653059005737, \"sum\": 4118.653059005737, \"min\": 4118.653059005737}}, \"EndTime\": 1597990916.080293, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990911.96157}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:56 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=160.97003724 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:56 INFO 140166612858688] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:56 INFO 140166612858688] #quality_metric: host=algo-1, epoch=60, train loss <loss>=1.32288526405\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:56 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:56 INFO 140166612858688] Epoch[61] Batch[0] avg_epoch_loss=1.362415\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:56 INFO 140166612858688] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=1.36241471767\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:58 INFO 140166612858688] Epoch[61] Batch[5] avg_epoch_loss=1.275426\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:58 INFO 140166612858688] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=1.27542563279\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:21:58 INFO 140166612858688] Epoch[61] Batch [5]#011Speed: 192.89 samples/sec#011loss=1.275426\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:00 INFO 140166612858688] Epoch[61] Batch[10] avg_epoch_loss=1.403794\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:00 INFO 140166612858688] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=1.55783531666\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:00 INFO 140166612858688] Epoch[61] Batch [10]#011Speed: 189.69 samples/sec#011loss=1.557835\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:00 INFO 140166612858688] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4135.992050170898, \"sum\": 4135.992050170898, \"min\": 4135.992050170898}}, \"EndTime\": 1597990920.216827, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990916.080377}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:00 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=155.459819651 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:00 INFO 140166612858688] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:00 INFO 140166612858688] #quality_metric: host=algo-1, epoch=61, train loss <loss>=1.40379367091\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:00 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:00 INFO 140166612858688] Epoch[62] Batch[0] avg_epoch_loss=1.431903\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:00 INFO 140166612858688] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=1.43190324306\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:02 INFO 140166612858688] Epoch[62] Batch[5] avg_epoch_loss=1.358223\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:02 INFO 140166612858688] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=1.35822274288\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:02 INFO 140166612858688] Epoch[62] Batch [5]#011Speed: 188.32 samples/sec#011loss=1.358223\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:04 INFO 140166612858688] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3819.999933242798, \"sum\": 3819.999933242798, \"min\": 3819.999933242798}}, \"EndTime\": 1597990924.037366, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990920.21691}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:04 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=163.607677099 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:04 INFO 140166612858688] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:04 INFO 140166612858688] #quality_metric: host=algo-1, epoch=62, train loss <loss>=1.35044262409\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:04 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:04 INFO 140166612858688] Epoch[63] Batch[0] avg_epoch_loss=1.319991\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:04 INFO 140166612858688] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=1.31999075413\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:06 INFO 140166612858688] Epoch[63] Batch[5] avg_epoch_loss=1.350416\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:06 INFO 140166612858688] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=1.35041562716\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:06 INFO 140166612858688] Epoch[63] Batch [5]#011Speed: 189.96 samples/sec#011loss=1.350416\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:07 INFO 140166612858688] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3837.244987487793, \"sum\": 3837.244987487793, \"min\": 3837.244987487793}}, \"EndTime\": 1597990927.875214, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990924.037438}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:07 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=158.180923546 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:07 INFO 140166612858688] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:07 INFO 140166612858688] #quality_metric: host=algo-1, epoch=63, train loss <loss>=1.31825530529\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:07 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:08 INFO 140166612858688] Epoch[64] Batch[0] avg_epoch_loss=1.152012\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:08 INFO 140166612858688] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=1.15201151371\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:10 INFO 140166612858688] Epoch[64] Batch[5] avg_epoch_loss=1.233199\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:10 INFO 140166612858688] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=1.23319876194\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:10 INFO 140166612858688] Epoch[64] Batch [5]#011Speed: 190.30 samples/sec#011loss=1.233199\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:12 INFO 140166612858688] Epoch[64] Batch[10] avg_epoch_loss=1.274559\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:12 INFO 140166612858688] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=1.32419037819\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:12 INFO 140166612858688] Epoch[64] Batch [10]#011Speed: 190.65 samples/sec#011loss=1.324190\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:12 INFO 140166612858688] processed a total of 706 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4491.752147674561, \"sum\": 4491.752147674561, \"min\": 4491.752147674561}}, \"EndTime\": 1597990932.367557, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990927.875302}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:12 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=157.172500028 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:12 INFO 140166612858688] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:12 INFO 140166612858688] #quality_metric: host=algo-1, epoch=64, train loss <loss>=1.29288321733\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:12 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:13 INFO 140166612858688] Epoch[65] Batch[0] avg_epoch_loss=1.235538\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:13 INFO 140166612858688] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=1.23553752899\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:14 INFO 140166612858688] Epoch[65] Batch[5] avg_epoch_loss=1.317352\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:14 INFO 140166612858688] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=1.31735229492\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:14 INFO 140166612858688] Epoch[65] Batch [5]#011Speed: 191.95 samples/sec#011loss=1.317352\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:22:16 INFO 140166612858688] Epoch[65] Batch[10] avg_epoch_loss=1.232087\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:16 INFO 140166612858688] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=1.12976833582\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:16 INFO 140166612858688] Epoch[65] Batch [10]#011Speed: 190.43 samples/sec#011loss=1.129768\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:16 INFO 140166612858688] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4126.322984695435, \"sum\": 4126.322984695435, \"min\": 4126.322984695435}}, \"EndTime\": 1597990936.494533, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990932.367645}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:16 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=158.974648363 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:16 INFO 140166612858688] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:16 INFO 140166612858688] #quality_metric: host=algo-1, epoch=65, train loss <loss>=1.23208685897\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:16 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:16 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_ddef83c5-a91d-4a4f-80d9-609cb3998d49-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 120.73087692260742, \"sum\": 120.73087692260742, \"min\": 120.73087692260742}}, \"EndTime\": 1597990936.615842, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990936.494615}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:17 INFO 140166612858688] Epoch[66] Batch[0] avg_epoch_loss=1.268803\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:17 INFO 140166612858688] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=1.26880300045\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:19 INFO 140166612858688] Epoch[66] Batch[5] avg_epoch_loss=1.299790\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:19 INFO 140166612858688] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=1.29979014397\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:19 INFO 140166612858688] Epoch[66] Batch [5]#011Speed: 191.80 samples/sec#011loss=1.299790\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:20 INFO 140166612858688] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3791.476011276245, \"sum\": 3791.476011276245, \"min\": 3791.476011276245}}, \"EndTime\": 1597990940.407478, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990936.615924}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:20 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=166.947686345 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:20 INFO 140166612858688] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:20 INFO 140166612858688] #quality_metric: host=algo-1, epoch=66, train loss <loss>=1.27903220654\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:20 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:21 INFO 140166612858688] Epoch[67] Batch[0] avg_epoch_loss=1.253542\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:21 INFO 140166612858688] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=1.2535418272\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:22 INFO 140166612858688] Epoch[67] Batch[5] avg_epoch_loss=1.243806\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:22 INFO 140166612858688] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=1.24380642176\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:22 INFO 140166612858688] Epoch[67] Batch [5]#011Speed: 191.34 samples/sec#011loss=1.243806\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:24 INFO 140166612858688] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3819.157838821411, \"sum\": 3819.157838821411, \"min\": 3819.157838821411}}, \"EndTime\": 1597990944.227214, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990940.407567}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:24 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=167.570583062 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:24 INFO 140166612858688] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:24 INFO 140166612858688] #quality_metric: host=algo-1, epoch=67, train loss <loss>=1.27568807602\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:24 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:25 INFO 140166612858688] Epoch[68] Batch[0] avg_epoch_loss=1.314054\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:25 INFO 140166612858688] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=1.31405377388\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:26 INFO 140166612858688] Epoch[68] Batch[5] avg_epoch_loss=1.245057\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:26 INFO 140166612858688] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=1.24505742391\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:26 INFO 140166612858688] Epoch[68] Batch [5]#011Speed: 190.13 samples/sec#011loss=1.245057\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:28 INFO 140166612858688] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3829.6151161193848, \"sum\": 3829.6151161193848, \"min\": 3829.6151161193848}}, \"EndTime\": 1597990948.057415, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990944.227301}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:28 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=165.023998639 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:28 INFO 140166612858688] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:28 INFO 140166612858688] #quality_metric: host=algo-1, epoch=68, train loss <loss>=1.2629326582\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:28 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:28 INFO 140166612858688] Epoch[69] Batch[0] avg_epoch_loss=1.247912\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:28 INFO 140166612858688] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=1.2479121685\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:30 INFO 140166612858688] Epoch[69] Batch[5] avg_epoch_loss=1.263684\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:30 INFO 140166612858688] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=1.26368353764\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:30 INFO 140166612858688] Epoch[69] Batch [5]#011Speed: 191.01 samples/sec#011loss=1.263684\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:31 INFO 140166612858688] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3803.50399017334, \"sum\": 3803.50399017334, \"min\": 3803.50399017334}}, \"EndTime\": 1597990951.861489, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990948.057505}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:31 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=166.419936235 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:31 INFO 140166612858688] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:31 INFO 140166612858688] #quality_metric: host=algo-1, epoch=69, train loss <loss>=1.25523488522\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:31 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:32 INFO 140166612858688] Epoch[70] Batch[0] avg_epoch_loss=1.104585\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:32 INFO 140166612858688] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=1.1045845747\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:34 INFO 140166612858688] Epoch[70] Batch[5] avg_epoch_loss=1.225107\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:34 INFO 140166612858688] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=1.22510693471\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:34 INFO 140166612858688] Epoch[70] Batch [5]#011Speed: 189.88 samples/sec#011loss=1.225107\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:36 INFO 140166612858688] Epoch[70] Batch[10] avg_epoch_loss=1.313004\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:36 INFO 140166612858688] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=1.41847975254\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:36 INFO 140166612858688] Epoch[70] Batch [10]#011Speed: 190.75 samples/sec#011loss=1.418480\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:36 INFO 140166612858688] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4144.904851913452, \"sum\": 4144.904851913452, \"min\": 4144.904851913452}}, \"EndTime\": 1597990956.006972, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990951.861572}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:36 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=156.57320483 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:36 INFO 140166612858688] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:36 INFO 140166612858688] #quality_metric: host=algo-1, epoch=70, train loss <loss>=1.31300367009\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:36 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:36 INFO 140166612858688] Epoch[71] Batch[0] avg_epoch_loss=1.372631\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:36 INFO 140166612858688] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=1.37263071537\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:38 INFO 140166612858688] Epoch[71] Batch[5] avg_epoch_loss=1.326226\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:38 INFO 140166612858688] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=1.32622607549\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:38 INFO 140166612858688] Epoch[71] Batch [5]#011Speed: 188.74 samples/sec#011loss=1.326226\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:40 INFO 140166612858688] Epoch[71] Batch[10] avg_epoch_loss=1.292361\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:40 INFO 140166612858688] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=1.25172219276\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:40 INFO 140166612858688] Epoch[71] Batch [10]#011Speed: 191.01 samples/sec#011loss=1.251722\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:40 INFO 140166612858688] processed a total of 701 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4169.341087341309, \"sum\": 4169.341087341309, \"min\": 4169.341087341309}}, \"EndTime\": 1597990960.176882, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990956.007054}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:40 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=168.127169753 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:40 INFO 140166612858688] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:40 INFO 140166612858688] #quality_metric: host=algo-1, epoch=71, train loss <loss>=1.29236067425\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:40 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:40 INFO 140166612858688] Epoch[72] Batch[0] avg_epoch_loss=1.356209\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:40 INFO 140166612858688] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=1.35620939732\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:42 INFO 140166612858688] Epoch[72] Batch[5] avg_epoch_loss=1.271284\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:42 INFO 140166612858688] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=1.27128380537\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:42 INFO 140166612858688] Epoch[72] Batch [5]#011Speed: 189.38 samples/sec#011loss=1.271284\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:22:44 INFO 140166612858688] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3830.5258750915527, \"sum\": 3830.5258750915527, \"min\": 3830.5258750915527}}, \"EndTime\": 1597990964.007945, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990960.176964}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:44 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=161.591501732 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:44 INFO 140166612858688] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:44 INFO 140166612858688] #quality_metric: host=algo-1, epoch=72, train loss <loss>=1.23688052893\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:44 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:44 INFO 140166612858688] Epoch[73] Batch[0] avg_epoch_loss=1.329775\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:44 INFO 140166612858688] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=1.32977497578\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:46 INFO 140166612858688] Epoch[73] Batch[5] avg_epoch_loss=1.342618\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:46 INFO 140166612858688] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=1.34261846542\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:46 INFO 140166612858688] Epoch[73] Batch [5]#011Speed: 188.05 samples/sec#011loss=1.342618\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:48 INFO 140166612858688] Epoch[73] Batch[10] avg_epoch_loss=1.274561\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:48 INFO 140166612858688] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=1.19289222956\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:48 INFO 140166612858688] Epoch[73] Batch [10]#011Speed: 188.52 samples/sec#011loss=1.192892\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:48 INFO 140166612858688] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4167.926073074341, \"sum\": 4167.926073074341, \"min\": 4167.926073074341}}, \"EndTime\": 1597990968.17651, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990964.008023}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:48 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=154.029230592 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:48 INFO 140166612858688] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:48 INFO 140166612858688] #quality_metric: host=algo-1, epoch=73, train loss <loss>=1.27456108548\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:48 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:48 INFO 140166612858688] Epoch[74] Batch[0] avg_epoch_loss=1.294181\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:48 INFO 140166612858688] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=1.29418051243\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:50 INFO 140166612858688] Epoch[74] Batch[5] avg_epoch_loss=1.322264\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:50 INFO 140166612858688] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=1.3222643137\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:50 INFO 140166612858688] Epoch[74] Batch [5]#011Speed: 187.38 samples/sec#011loss=1.322264\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:52 INFO 140166612858688] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3826.33900642395, \"sum\": 3826.33900642395, \"min\": 3826.33900642395}}, \"EndTime\": 1597990972.003386, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990968.17658}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:52 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=166.472752617 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:52 INFO 140166612858688] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:52 INFO 140166612858688] #quality_metric: host=algo-1, epoch=74, train loss <loss>=1.2873634696\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:52 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:52 INFO 140166612858688] Epoch[75] Batch[0] avg_epoch_loss=1.312295\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:52 INFO 140166612858688] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=1.31229543686\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:54 INFO 140166612858688] Epoch[75] Batch[5] avg_epoch_loss=1.286156\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:54 INFO 140166612858688] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=1.28615585963\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:54 INFO 140166612858688] Epoch[75] Batch [5]#011Speed: 191.00 samples/sec#011loss=1.286156\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:55 INFO 140166612858688] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3806.283950805664, \"sum\": 3806.283950805664, \"min\": 3806.283950805664}}, \"EndTime\": 1597990975.810268, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990972.003454}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:55 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=168.137206893 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:55 INFO 140166612858688] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:55 INFO 140166612858688] #quality_metric: host=algo-1, epoch=75, train loss <loss>=1.28649312258\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:55 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:56 INFO 140166612858688] Epoch[76] Batch[0] avg_epoch_loss=1.339974\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:56 INFO 140166612858688] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=1.33997416496\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:58 INFO 140166612858688] Epoch[76] Batch[5] avg_epoch_loss=1.231053\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:58 INFO 140166612858688] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=1.23105339209\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:58 INFO 140166612858688] Epoch[76] Batch [5]#011Speed: 192.28 samples/sec#011loss=1.231053\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:59 INFO 140166612858688] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3832.973003387451, \"sum\": 3832.973003387451, \"min\": 3832.973003387451}}, \"EndTime\": 1597990979.643844, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990975.810355}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:59 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=160.444545429 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:59 INFO 140166612858688] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:59 INFO 140166612858688] #quality_metric: host=algo-1, epoch=76, train loss <loss>=1.17148228884\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:59 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:22:59 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_8b10503d-fcc6-41a9-931e-5c60d109498c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 118.3462142944336, \"sum\": 118.3462142944336, \"min\": 118.3462142944336}}, \"EndTime\": 1597990979.762854, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990979.643932}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:00 INFO 140166612858688] Epoch[77] Batch[0] avg_epoch_loss=1.378883\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:00 INFO 140166612858688] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=1.37888336182\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:02 INFO 140166612858688] Epoch[77] Batch[5] avg_epoch_loss=1.202533\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:02 INFO 140166612858688] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=1.20253272851\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:02 INFO 140166612858688] Epoch[77] Batch [5]#011Speed: 187.60 samples/sec#011loss=1.202533\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:03 INFO 140166612858688] processed a total of 577 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3823.992967605591, \"sum\": 3823.992967605591, \"min\": 3823.992967605591}}, \"EndTime\": 1597990983.587007, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990979.762935}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:03 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=150.884309453 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:03 INFO 140166612858688] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:03 INFO 140166612858688] #quality_metric: host=algo-1, epoch=77, train loss <loss>=1.28858298063\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:03 INFO 140166612858688] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:23:04 INFO 140166612858688] Epoch[78] Batch[0] avg_epoch_loss=1.191289\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:04 INFO 140166612858688] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=1.19128930569\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:06 INFO 140166612858688] Epoch[78] Batch[5] avg_epoch_loss=1.269067\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:06 INFO 140166612858688] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=1.26906724771\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:06 INFO 140166612858688] Epoch[78] Batch [5]#011Speed: 185.22 samples/sec#011loss=1.269067\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:07 INFO 140166612858688] Epoch[78] Batch[10] avg_epoch_loss=1.290163\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:07 INFO 140166612858688] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=1.31547801495\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:07 INFO 140166612858688] Epoch[78] Batch [10]#011Speed: 183.02 samples/sec#011loss=1.315478\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:07 INFO 140166612858688] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4284.101963043213, \"sum\": 4284.101963043213, \"min\": 4284.101963043213}}, \"EndTime\": 1597990987.871693, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990983.587096}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:07 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=151.952871709 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:07 INFO 140166612858688] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:07 INFO 140166612858688] #quality_metric: host=algo-1, epoch=78, train loss <loss>=1.290163051\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:07 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:08 INFO 140166612858688] Epoch[79] Batch[0] avg_epoch_loss=1.407559\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:08 INFO 140166612858688] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=1.40755915642\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:10 INFO 140166612858688] Epoch[79] Batch[5] avg_epoch_loss=1.281679\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:10 INFO 140166612858688] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=1.28167937199\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:10 INFO 140166612858688] Epoch[79] Batch [5]#011Speed: 189.18 samples/sec#011loss=1.281679\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:12 INFO 140166612858688] Epoch[79] Batch[10] avg_epoch_loss=1.187201\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:12 INFO 140166612858688] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=1.07382777929\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:12 INFO 140166612858688] Epoch[79] Batch [10]#011Speed: 188.89 samples/sec#011loss=1.073828\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:12 INFO 140166612858688] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4172.752857208252, \"sum\": 4172.752857208252, \"min\": 4172.752857208252}}, \"EndTime\": 1597990992.045006, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990987.871775}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:12 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=156.008068449 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:12 INFO 140166612858688] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:12 INFO 140166612858688] #quality_metric: host=algo-1, epoch=79, train loss <loss>=1.18720137531\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:12 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:12 INFO 140166612858688] Epoch[80] Batch[0] avg_epoch_loss=1.243842\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:12 INFO 140166612858688] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=1.24384200573\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:14 INFO 140166612858688] Epoch[80] Batch[5] avg_epoch_loss=1.209378\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:14 INFO 140166612858688] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=1.2093783021\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:14 INFO 140166612858688] Epoch[80] Batch [5]#011Speed: 190.86 samples/sec#011loss=1.209378\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:16 INFO 140166612858688] Epoch[80] Batch[10] avg_epoch_loss=1.178444\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:16 INFO 140166612858688] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=1.14132223129\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:16 INFO 140166612858688] Epoch[80] Batch [10]#011Speed: 186.40 samples/sec#011loss=1.141322\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:16 INFO 140166612858688] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4165.149927139282, \"sum\": 4165.149927139282, \"min\": 4165.149927139282}}, \"EndTime\": 1597990996.210683, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990992.045071}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:16 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=157.25289673 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:16 INFO 140166612858688] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:16 INFO 140166612858688] #quality_metric: host=algo-1, epoch=80, train loss <loss>=1.17844372446\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:16 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:16 INFO 140166612858688] Epoch[81] Batch[0] avg_epoch_loss=1.261829\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:16 INFO 140166612858688] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=1.2618291378\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:18 INFO 140166612858688] Epoch[81] Batch[5] avg_epoch_loss=1.212889\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:18 INFO 140166612858688] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=1.2128889362\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:18 INFO 140166612858688] Epoch[81] Batch [5]#011Speed: 189.14 samples/sec#011loss=1.212889\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:20 INFO 140166612858688] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3795.097827911377, \"sum\": 3795.097827911377, \"min\": 3795.097827911377}}, \"EndTime\": 1597991000.006338, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597990996.210759}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:20 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=162.309089013 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:20 INFO 140166612858688] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:20 INFO 140166612858688] #quality_metric: host=algo-1, epoch=81, train loss <loss>=1.27441494465\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:20 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:20 INFO 140166612858688] Epoch[82] Batch[0] avg_epoch_loss=1.268792\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:20 INFO 140166612858688] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=1.26879179478\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:22 INFO 140166612858688] Epoch[82] Batch[5] avg_epoch_loss=1.261221\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:22 INFO 140166612858688] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=1.26122121016\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:22 INFO 140166612858688] Epoch[82] Batch [5]#011Speed: 191.93 samples/sec#011loss=1.261221\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:23 INFO 140166612858688] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3789.428949356079, \"sum\": 3789.428949356079, \"min\": 3789.428949356079}}, \"EndTime\": 1597991003.796351, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991000.006427}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:23 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=160.176944028 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:23 INFO 140166612858688] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:23 INFO 140166612858688] #quality_metric: host=algo-1, epoch=82, train loss <loss>=1.30622751713\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:23 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:24 INFO 140166612858688] Epoch[83] Batch[0] avg_epoch_loss=1.312677\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:24 INFO 140166612858688] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=1.31267690659\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:26 INFO 140166612858688] Epoch[83] Batch[5] avg_epoch_loss=1.241457\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:26 INFO 140166612858688] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=1.24145714442\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:26 INFO 140166612858688] Epoch[83] Batch [5]#011Speed: 187.01 samples/sec#011loss=1.241457\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:27 INFO 140166612858688] Epoch[83] Batch[10] avg_epoch_loss=1.235674\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:27 INFO 140166612858688] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=1.22873522043\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:27 INFO 140166612858688] Epoch[83] Batch [10]#011Speed: 191.34 samples/sec#011loss=1.228735\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:27 INFO 140166612858688] processed a total of 684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4168.910980224609, \"sum\": 4168.910980224609, \"min\": 4168.910980224609}}, \"EndTime\": 1597991007.965857, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991003.796439}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:27 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=164.066821181 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:27 INFO 140166612858688] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:27 INFO 140166612858688] #quality_metric: host=algo-1, epoch=83, train loss <loss>=1.2356744517\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:27 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:28 INFO 140166612858688] Epoch[84] Batch[0] avg_epoch_loss=1.060875\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:28 INFO 140166612858688] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=1.06087505817\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:30 INFO 140166612858688] Epoch[84] Batch[5] avg_epoch_loss=1.192262\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:30 INFO 140166612858688] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=1.1922617356\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:30 INFO 140166612858688] Epoch[84] Batch [5]#011Speed: 188.48 samples/sec#011loss=1.192262\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:32 INFO 140166612858688] Epoch[84] Batch[10] avg_epoch_loss=1.265011\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:32 INFO 140166612858688] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=1.35230972767\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:32 INFO 140166612858688] Epoch[84] Batch [10]#011Speed: 190.30 samples/sec#011loss=1.352310\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:32 INFO 140166612858688] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4155.467987060547, \"sum\": 4155.467987060547, \"min\": 4155.467987060547}}, \"EndTime\": 1597991012.121882, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991007.96594}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:32 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=155.212499314 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:32 INFO 140166612858688] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:32 INFO 140166612858688] #quality_metric: host=algo-1, epoch=84, train loss <loss>=1.2650108229\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:32 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:32 INFO 140166612858688] Epoch[85] Batch[0] avg_epoch_loss=1.070948\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:32 INFO 140166612858688] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=1.07094788551\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:34 INFO 140166612858688] Epoch[85] Batch[5] avg_epoch_loss=1.171144\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:34 INFO 140166612858688] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=1.17114382982\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:34 INFO 140166612858688] Epoch[85] Batch [5]#011Speed: 192.28 samples/sec#011loss=1.171144\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:23:36 INFO 140166612858688] Epoch[85] Batch[10] avg_epoch_loss=1.156991\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:36 INFO 140166612858688] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=1.14000818729\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:36 INFO 140166612858688] Epoch[85] Batch [10]#011Speed: 188.09 samples/sec#011loss=1.140008\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:36 INFO 140166612858688] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4160.481929779053, \"sum\": 4160.481929779053, \"min\": 4160.481929779053}}, \"EndTime\": 1597991016.282894, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991012.121965}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:36 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=164.879708443 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:36 INFO 140166612858688] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:36 INFO 140166612858688] #quality_metric: host=algo-1, epoch=85, train loss <loss>=1.15699126504\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:36 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:36 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_603736fa-d0cf-470b-8be6-93b194e27c0a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 112.80012130737305, \"sum\": 112.80012130737305, \"min\": 112.80012130737305}}, \"EndTime\": 1597991016.396323, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991016.28298}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:37 INFO 140166612858688] Epoch[86] Batch[0] avg_epoch_loss=1.136678\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:37 INFO 140166612858688] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=1.13667821884\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:38 INFO 140166612858688] Epoch[86] Batch[5] avg_epoch_loss=1.185640\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:38 INFO 140166612858688] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=1.18564033508\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:38 INFO 140166612858688] Epoch[86] Batch [5]#011Speed: 186.86 samples/sec#011loss=1.185640\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:40 INFO 140166612858688] Epoch[86] Batch[10] avg_epoch_loss=1.187453\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:40 INFO 140166612858688] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=1.18962860107\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:40 INFO 140166612858688] Epoch[86] Batch [10]#011Speed: 182.52 samples/sec#011loss=1.189629\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:40 INFO 140166612858688] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4236.025810241699, \"sum\": 4236.025810241699, \"min\": 4236.025810241699}}, \"EndTime\": 1597991020.632499, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991016.396395}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:40 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=155.329755567 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:40 INFO 140166612858688] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:40 INFO 140166612858688] #quality_metric: host=algo-1, epoch=86, train loss <loss>=1.18745318326\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:40 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:41 INFO 140166612858688] Epoch[87] Batch[0] avg_epoch_loss=1.301139\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:41 INFO 140166612858688] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=1.30113935471\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:43 INFO 140166612858688] Epoch[87] Batch[5] avg_epoch_loss=1.194736\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:43 INFO 140166612858688] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=1.19473614295\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:43 INFO 140166612858688] Epoch[87] Batch [5]#011Speed: 189.16 samples/sec#011loss=1.194736\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:44 INFO 140166612858688] Epoch[87] Batch[10] avg_epoch_loss=1.209745\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:44 INFO 140166612858688] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=1.227754879\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:44 INFO 140166612858688] Epoch[87] Batch [10]#011Speed: 187.63 samples/sec#011loss=1.227755\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:44 INFO 140166612858688] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4170.362949371338, \"sum\": 4170.362949371338, \"min\": 4170.362949371338}}, \"EndTime\": 1597991024.803393, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991020.63258}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:44 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=155.377460218 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:44 INFO 140166612858688] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:44 INFO 140166612858688] #quality_metric: host=algo-1, epoch=87, train loss <loss>=1.20974465934\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:44 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:45 INFO 140166612858688] Epoch[88] Batch[0] avg_epoch_loss=1.115211\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:45 INFO 140166612858688] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=1.11521136761\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:47 INFO 140166612858688] Epoch[88] Batch[5] avg_epoch_loss=1.183117\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:47 INFO 140166612858688] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=1.18311665456\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:47 INFO 140166612858688] Epoch[88] Batch [5]#011Speed: 190.89 samples/sec#011loss=1.183117\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:48 INFO 140166612858688] Epoch[88] Batch[10] avg_epoch_loss=1.178154\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:48 INFO 140166612858688] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=1.17219796181\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:48 INFO 140166612858688] Epoch[88] Batch [10]#011Speed: 191.83 samples/sec#011loss=1.172198\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:49 INFO 140166612858688] processed a total of 706 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4505.262136459351, \"sum\": 4505.262136459351, \"min\": 4505.262136459351}}, \"EndTime\": 1597991029.309242, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991024.80348}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:49 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=156.701090354 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:49 INFO 140166612858688] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:49 INFO 140166612858688] #quality_metric: host=algo-1, epoch=88, train loss <loss>=1.38680824637\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:49 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:50 INFO 140166612858688] Epoch[89] Batch[0] avg_epoch_loss=1.272877\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:50 INFO 140166612858688] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=1.27287709713\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:51 INFO 140166612858688] Epoch[89] Batch[5] avg_epoch_loss=1.209475\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:51 INFO 140166612858688] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=1.20947464307\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:51 INFO 140166612858688] Epoch[89] Batch [5]#011Speed: 188.36 samples/sec#011loss=1.209475\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:53 INFO 140166612858688] Epoch[89] Batch[10] avg_epoch_loss=1.225123\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:53 INFO 140166612858688] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=1.24390051365\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:53 INFO 140166612858688] Epoch[89] Batch [10]#011Speed: 190.14 samples/sec#011loss=1.243901\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:53 INFO 140166612858688] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4178.442001342773, \"sum\": 4178.442001342773, \"min\": 4178.442001342773}}, \"EndTime\": 1597991033.488264, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991029.309331}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:53 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=154.359246128 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:53 INFO 140166612858688] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:53 INFO 140166612858688] #quality_metric: host=algo-1, epoch=89, train loss <loss>=1.22512276606\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:53 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:54 INFO 140166612858688] Epoch[90] Batch[0] avg_epoch_loss=1.257478\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:54 INFO 140166612858688] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=1.25747823715\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:55 INFO 140166612858688] Epoch[90] Batch[5] avg_epoch_loss=1.274929\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:55 INFO 140166612858688] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=1.27492896716\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:55 INFO 140166612858688] Epoch[90] Batch [5]#011Speed: 186.77 samples/sec#011loss=1.274929\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:23:57 INFO 140166612858688] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3842.8330421447754, \"sum\": 3842.8330421447754, \"min\": 3842.8330421447754}}, \"EndTime\": 1597991037.331608, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991033.488346}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:57 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=162.115248584 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:57 INFO 140166612858688] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:57 INFO 140166612858688] #quality_metric: host=algo-1, epoch=90, train loss <loss>=1.23335648775\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:57 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:58 INFO 140166612858688] Epoch[91] Batch[0] avg_epoch_loss=1.180741\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:58 INFO 140166612858688] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=1.18074142933\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:59 INFO 140166612858688] Epoch[91] Batch[5] avg_epoch_loss=1.220322\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:59 INFO 140166612858688] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=1.2203223904\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:23:59 INFO 140166612858688] Epoch[91] Batch [5]#011Speed: 190.72 samples/sec#011loss=1.220322\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:01 INFO 140166612858688] Epoch[91] Batch[10] avg_epoch_loss=1.184874\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:01 INFO 140166612858688] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=1.14233694077\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:01 INFO 140166612858688] Epoch[91] Batch [10]#011Speed: 187.79 samples/sec#011loss=1.142337\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:01 INFO 140166612858688] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4150.148153305054, \"sum\": 4150.148153305054, \"min\": 4150.148153305054}}, \"EndTime\": 1597991041.482366, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991037.331686}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:01 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=156.375557555 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:01 INFO 140166612858688] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:01 INFO 140166612858688] #quality_metric: host=algo-1, epoch=91, train loss <loss>=1.18487445875\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:01 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:02 INFO 140166612858688] Epoch[92] Batch[0] avg_epoch_loss=1.327465\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:02 INFO 140166612858688] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=1.327465415\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:03 INFO 140166612858688] Epoch[92] Batch[5] avg_epoch_loss=1.257950\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:03 INFO 140166612858688] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=1.2579498291\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:03 INFO 140166612858688] Epoch[92] Batch [5]#011Speed: 191.11 samples/sec#011loss=1.257950\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:05 INFO 140166612858688] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3839.609146118164, \"sum\": 3839.609146118164, \"min\": 3839.609146118164}}, \"EndTime\": 1597991045.32247, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991041.482444}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:05 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=165.375861167 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:05 INFO 140166612858688] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:05 INFO 140166612858688] #quality_metric: host=algo-1, epoch=92, train loss <loss>=1.26221984625\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:05 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:06 INFO 140166612858688] Epoch[93] Batch[0] avg_epoch_loss=1.284793\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:06 INFO 140166612858688] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=1.28479301929\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:07 INFO 140166612858688] Epoch[93] Batch[5] avg_epoch_loss=1.260696\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:07 INFO 140166612858688] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=1.2606959343\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:07 INFO 140166612858688] Epoch[93] Batch [5]#011Speed: 187.64 samples/sec#011loss=1.260696\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:09 INFO 140166612858688] processed a total of 596 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3841.6080474853516, \"sum\": 3841.6080474853516, \"min\": 3841.6080474853516}}, \"EndTime\": 1597991049.164647, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991045.322558}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:09 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=155.138117756 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:09 INFO 140166612858688] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:09 INFO 140166612858688] #quality_metric: host=algo-1, epoch=93, train loss <loss>=1.2478515625\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:09 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:09 INFO 140166612858688] Epoch[94] Batch[0] avg_epoch_loss=1.087745\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:09 INFO 140166612858688] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=1.08774495125\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:11 INFO 140166612858688] Epoch[94] Batch[5] avg_epoch_loss=1.224316\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:11 INFO 140166612858688] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=1.22431576252\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:11 INFO 140166612858688] Epoch[94] Batch [5]#011Speed: 187.09 samples/sec#011loss=1.224316\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:13 INFO 140166612858688] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3862.7610206604004, \"sum\": 3862.7610206604004, \"min\": 3862.7610206604004}}, \"EndTime\": 1597991053.028025, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991049.164735}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:13 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=165.41992491 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:13 INFO 140166612858688] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:13 INFO 140166612858688] #quality_metric: host=algo-1, epoch=94, train loss <loss>=1.22011350393\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:13 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:13 INFO 140166612858688] Epoch[95] Batch[0] avg_epoch_loss=1.070722\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:13 INFO 140166612858688] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=1.07072174549\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:15 INFO 140166612858688] Epoch[95] Batch[5] avg_epoch_loss=1.196424\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:15 INFO 140166612858688] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=1.19642410676\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:15 INFO 140166612858688] Epoch[95] Batch [5]#011Speed: 190.39 samples/sec#011loss=1.196424\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:16 INFO 140166612858688] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3834.1948986053467, \"sum\": 3834.1948986053467, \"min\": 3834.1948986053467}}, \"EndTime\": 1597991056.86284, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991053.028117}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:16 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=162.220293048 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:16 INFO 140166612858688] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:16 INFO 140166612858688] #quality_metric: host=algo-1, epoch=95, train loss <loss>=1.15422022343\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:16 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:16 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_aeea4aed-0b2c-4791-9061-d957e998ce77-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 107.6350212097168, \"sum\": 107.6350212097168, \"min\": 107.6350212097168}}, \"EndTime\": 1597991056.971097, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991056.862904}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:24:17 INFO 140166612858688] Epoch[96] Batch[0] avg_epoch_loss=1.112026\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:17 INFO 140166612858688] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=1.11202633381\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:19 INFO 140166612858688] Epoch[96] Batch[5] avg_epoch_loss=1.093955\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:19 INFO 140166612858688] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=1.09395517906\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:19 INFO 140166612858688] Epoch[96] Batch [5]#011Speed: 190.02 samples/sec#011loss=1.093955\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:21 INFO 140166612858688] Epoch[96] Batch[10] avg_epoch_loss=1.132089\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:21 INFO 140166612858688] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=1.17784910202\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:21 INFO 140166612858688] Epoch[96] Batch [10]#011Speed: 188.10 samples/sec#011loss=1.177849\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:21 INFO 140166612858688] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4161.596059799194, \"sum\": 4161.596059799194, \"min\": 4161.596059799194}}, \"EndTime\": 1597991061.132833, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991056.971172}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:21 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=162.67312407 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:21 INFO 140166612858688] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:21 INFO 140166612858688] #quality_metric: host=algo-1, epoch=96, train loss <loss>=1.1320887804\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:21 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:21 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_1a98858e-bd18-420e-a162-8e09ea135362-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 132.5371265411377, \"sum\": 132.5371265411377, \"min\": 132.5371265411377}}, \"EndTime\": 1597991061.265973, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991061.132917}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:22 INFO 140166612858688] Epoch[97] Batch[0] avg_epoch_loss=1.152470\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:22 INFO 140166612858688] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=1.15246987343\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:23 INFO 140166612858688] Epoch[97] Batch[5] avg_epoch_loss=1.259935\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:23 INFO 140166612858688] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=1.25993492206\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:23 INFO 140166612858688] Epoch[97] Batch [5]#011Speed: 189.75 samples/sec#011loss=1.259935\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:25 INFO 140166612858688] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3816.23911857605, \"sum\": 3816.23911857605, \"min\": 3816.23911857605}}, \"EndTime\": 1597991065.082364, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991061.266057}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:25 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=164.81769409 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:25 INFO 140166612858688] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:25 INFO 140166612858688] #quality_metric: host=algo-1, epoch=97, train loss <loss>=1.20575137138\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:25 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:25 INFO 140166612858688] Epoch[98] Batch[0] avg_epoch_loss=0.943871\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:25 INFO 140166612858688] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=0.943870842457\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:27 INFO 140166612858688] Epoch[98] Batch[5] avg_epoch_loss=1.114618\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:27 INFO 140166612858688] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=1.1146180133\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:27 INFO 140166612858688] Epoch[98] Batch [5]#011Speed: 188.67 samples/sec#011loss=1.114618\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:28 INFO 140166612858688] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3826.7600536346436, \"sum\": 3826.7600536346436, \"min\": 3826.7600536346436}}, \"EndTime\": 1597991068.909705, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991065.082428}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:28 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=167.237762183 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:28 INFO 140166612858688] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:28 INFO 140166612858688] #quality_metric: host=algo-1, epoch=98, train loss <loss>=1.13635775447\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:28 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:29 INFO 140166612858688] Epoch[99] Batch[0] avg_epoch_loss=1.002640\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:29 INFO 140166612858688] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=1.00263988972\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:31 INFO 140166612858688] Epoch[99] Batch[5] avg_epoch_loss=1.119904\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:31 INFO 140166612858688] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=1.11990398169\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:31 INFO 140166612858688] Epoch[99] Batch [5]#011Speed: 189.94 samples/sec#011loss=1.119904\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:33 INFO 140166612858688] Epoch[99] Batch[10] avg_epoch_loss=1.107585\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:33 INFO 140166612858688] #quality_metric: host=algo-1, epoch=99, batch=10 train loss <loss>=1.09280270338\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:33 INFO 140166612858688] Epoch[99] Batch [10]#011Speed: 190.22 samples/sec#011loss=1.092803\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:33 INFO 140166612858688] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4150.139093399048, \"sum\": 4150.139093399048, \"min\": 4150.139093399048}}, \"EndTime\": 1597991073.060411, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991068.909791}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:33 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=158.544248625 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:33 INFO 140166612858688] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:33 INFO 140166612858688] #quality_metric: host=algo-1, epoch=99, train loss <loss>=1.10758521882\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:33 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:33 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_1915a581-d940-41a7-b58b-ed712ba2375e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 118.97397041320801, \"sum\": 118.97397041320801, \"min\": 118.97397041320801}}, \"EndTime\": 1597991073.179951, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991073.060494}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:33 INFO 140166612858688] Epoch[100] Batch[0] avg_epoch_loss=1.159186\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:33 INFO 140166612858688] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=1.15918576717\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:35 INFO 140166612858688] Epoch[100] Batch[5] avg_epoch_loss=1.206621\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:35 INFO 140166612858688] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=1.20662071308\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:35 INFO 140166612858688] Epoch[100] Batch [5]#011Speed: 189.48 samples/sec#011loss=1.206621\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:37 INFO 140166612858688] Epoch[100] Batch[10] avg_epoch_loss=1.175381\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:37 INFO 140166612858688] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=1.13789283037\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:37 INFO 140166612858688] Epoch[100] Batch [10]#011Speed: 185.52 samples/sec#011loss=1.137893\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:37 INFO 140166612858688] processed a total of 696 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4201.769828796387, \"sum\": 4201.769828796387, \"min\": 4201.769828796387}}, \"EndTime\": 1597991077.381878, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991073.180034}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:37 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=165.640105298 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:37 INFO 140166612858688] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:37 INFO 140166612858688] #quality_metric: host=algo-1, epoch=100, train loss <loss>=1.17538076639\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:37 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:38 INFO 140166612858688] Epoch[101] Batch[0] avg_epoch_loss=1.215842\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:38 INFO 140166612858688] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=1.21584200859\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:39 INFO 140166612858688] Epoch[101] Batch[5] avg_epoch_loss=1.249218\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:39 INFO 140166612858688] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=1.24921828508\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:39 INFO 140166612858688] Epoch[101] Batch [5]#011Speed: 189.61 samples/sec#011loss=1.249218\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:41 INFO 140166612858688] Epoch[101] Batch[10] avg_epoch_loss=1.208958\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:41 INFO 140166612858688] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=1.16064636707\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:41 INFO 140166612858688] Epoch[101] Batch [10]#011Speed: 186.16 samples/sec#011loss=1.160646\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:41 INFO 140166612858688] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4197.8600025177, \"sum\": 4197.8600025177, \"min\": 4197.8600025177}}, \"EndTime\": 1597991081.580275, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991077.381949}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:41 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=157.218394112 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:41 INFO 140166612858688] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:41 INFO 140166612858688] #quality_metric: host=algo-1, epoch=101, train loss <loss>=1.20895832235\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:41 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:42 INFO 140166612858688] Epoch[102] Batch[0] avg_epoch_loss=1.179127\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:42 INFO 140166612858688] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=1.1791267395\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:44 INFO 140166612858688] Epoch[102] Batch[5] avg_epoch_loss=1.124348\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:44 INFO 140166612858688] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=1.12434775631\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:44 INFO 140166612858688] Epoch[102] Batch [5]#011Speed: 191.49 samples/sec#011loss=1.124348\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:24:45 INFO 140166612858688] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3798.9280223846436, \"sum\": 3798.9280223846436, \"min\": 3798.9280223846436}}, \"EndTime\": 1597991085.37974, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991081.580358}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:45 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=167.936411286 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:45 INFO 140166612858688] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:45 INFO 140166612858688] #quality_metric: host=algo-1, epoch=102, train loss <loss>=1.16793828607\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:45 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:46 INFO 140166612858688] Epoch[103] Batch[0] avg_epoch_loss=1.137358\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:46 INFO 140166612858688] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=1.13735818863\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:47 INFO 140166612858688] Epoch[103] Batch[5] avg_epoch_loss=1.155050\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:47 INFO 140166612858688] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=1.15504993995\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:47 INFO 140166612858688] Epoch[103] Batch [5]#011Speed: 189.61 samples/sec#011loss=1.155050\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:49 INFO 140166612858688] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3820.6570148468018, \"sum\": 3820.6570148468018, \"min\": 3820.6570148468018}}, \"EndTime\": 1597991089.200991, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991085.379827}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:49 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=161.747035805 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:49 INFO 140166612858688] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:49 INFO 140166612858688] #quality_metric: host=algo-1, epoch=103, train loss <loss>=1.17670424581\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:49 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:50 INFO 140166612858688] Epoch[104] Batch[0] avg_epoch_loss=0.961441\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:50 INFO 140166612858688] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=0.961440742016\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:51 INFO 140166612858688] Epoch[104] Batch[5] avg_epoch_loss=1.088170\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:51 INFO 140166612858688] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=1.08816985289\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:51 INFO 140166612858688] Epoch[104] Batch [5]#011Speed: 188.09 samples/sec#011loss=1.088170\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:53 INFO 140166612858688] Epoch[104] Batch[10] avg_epoch_loss=1.084970\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:53 INFO 140166612858688] #quality_metric: host=algo-1, epoch=104, batch=10 train loss <loss>=1.08112919331\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:53 INFO 140166612858688] Epoch[104] Batch [10]#011Speed: 188.75 samples/sec#011loss=1.081129\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:53 INFO 140166612858688] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4199.778079986572, \"sum\": 4199.778079986572, \"min\": 4199.778079986572}}, \"EndTime\": 1597991093.401364, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991089.201075}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:53 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=161.194354135 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:53 INFO 140166612858688] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:53 INFO 140166612858688] #quality_metric: host=algo-1, epoch=104, train loss <loss>=1.08496955308\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:53 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:53 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_ae472c0b-dd3d-476a-a34e-77f30951813a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 113.79098892211914, \"sum\": 113.79098892211914, \"min\": 113.79098892211914}}, \"EndTime\": 1597991093.515725, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991093.401441}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:54 INFO 140166612858688] Epoch[105] Batch[0] avg_epoch_loss=1.202662\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:54 INFO 140166612858688] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=1.20266199112\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:55 INFO 140166612858688] Epoch[105] Batch[5] avg_epoch_loss=1.078421\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:55 INFO 140166612858688] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=1.07842105627\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:55 INFO 140166612858688] Epoch[105] Batch [5]#011Speed: 189.82 samples/sec#011loss=1.078421\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:57 INFO 140166612858688] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3817.039966583252, \"sum\": 3817.039966583252, \"min\": 3817.039966583252}}, \"EndTime\": 1597991097.332901, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991093.515798}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:57 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=162.162156274 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:57 INFO 140166612858688] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:57 INFO 140166612858688] #quality_metric: host=algo-1, epoch=105, train loss <loss>=1.12432547808\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:57 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:58 INFO 140166612858688] Epoch[106] Batch[0] avg_epoch_loss=0.994191\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:58 INFO 140166612858688] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=0.99419093132\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:59 INFO 140166612858688] Epoch[106] Batch[5] avg_epoch_loss=1.122376\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:59 INFO 140166612858688] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=1.12237580617\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:24:59 INFO 140166612858688] Epoch[106] Batch [5]#011Speed: 188.51 samples/sec#011loss=1.122376\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:01 INFO 140166612858688] Epoch[106] Batch[10] avg_epoch_loss=1.092613\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:01 INFO 140166612858688] #quality_metric: host=algo-1, epoch=106, batch=10 train loss <loss>=1.05689769983\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:01 INFO 140166612858688] Epoch[106] Batch [10]#011Speed: 188.18 samples/sec#011loss=1.056898\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:01 INFO 140166612858688] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4190.433979034424, \"sum\": 4190.433979034424, \"min\": 4190.433979034424}}, \"EndTime\": 1597991101.523898, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991097.33299}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:01 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=164.655953023 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:01 INFO 140166612858688] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:01 INFO 140166612858688] #quality_metric: host=algo-1, epoch=106, train loss <loss>=1.09261303056\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:01 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:02 INFO 140166612858688] Epoch[107] Batch[0] avg_epoch_loss=1.082504\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:02 INFO 140166612858688] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=1.08250427246\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:04 INFO 140166612858688] Epoch[107] Batch[5] avg_epoch_loss=1.162893\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:04 INFO 140166612858688] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=1.16289271911\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:04 INFO 140166612858688] Epoch[107] Batch [5]#011Speed: 188.65 samples/sec#011loss=1.162893\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:05 INFO 140166612858688] Epoch[107] Batch[10] avg_epoch_loss=1.098073\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:05 INFO 140166612858688] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=1.02028998137\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:05 INFO 140166612858688] Epoch[107] Batch [10]#011Speed: 189.56 samples/sec#011loss=1.020290\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:05 INFO 140166612858688] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4185.052156448364, \"sum\": 4185.052156448364, \"min\": 4185.052156448364}}, \"EndTime\": 1597991105.709538, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991101.52398}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:05 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=164.867735285 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:05 INFO 140166612858688] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:05 INFO 140166612858688] #quality_metric: host=algo-1, epoch=107, train loss <loss>=1.09807329286\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:05 INFO 140166612858688] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:25:06 INFO 140166612858688] Epoch[108] Batch[0] avg_epoch_loss=1.234193\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:06 INFO 140166612858688] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=1.234192729\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:08 INFO 140166612858688] Epoch[108] Batch[5] avg_epoch_loss=1.086629\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:08 INFO 140166612858688] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=1.08662942052\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:08 INFO 140166612858688] Epoch[108] Batch [5]#011Speed: 183.07 samples/sec#011loss=1.086629\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:09 INFO 140166612858688] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3871.2289333343506, \"sum\": 3871.2289333343506, \"min\": 3871.2289333343506}}, \"EndTime\": 1597991109.581349, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991105.709619}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:09 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=163.766654931 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:09 INFO 140166612858688] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:09 INFO 140166612858688] #quality_metric: host=algo-1, epoch=108, train loss <loss>=1.11793783307\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:09 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:10 INFO 140166612858688] Epoch[109] Batch[0] avg_epoch_loss=1.247204\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:10 INFO 140166612858688] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=1.24720358849\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:12 INFO 140166612858688] Epoch[109] Batch[5] avg_epoch_loss=1.110043\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:12 INFO 140166612858688] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=1.11004318794\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:12 INFO 140166612858688] Epoch[109] Batch [5]#011Speed: 188.44 samples/sec#011loss=1.110043\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:13 INFO 140166612858688] processed a total of 553 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3486.5288734436035, \"sum\": 3486.5288734436035, \"min\": 3486.5288734436035}}, \"EndTime\": 1597991113.068482, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991109.58144}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:13 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=158.606049657 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:13 INFO 140166612858688] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:13 INFO 140166612858688] #quality_metric: host=algo-1, epoch=109, train loss <loss>=1.17231624656\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:13 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:13 INFO 140166612858688] Epoch[110] Batch[0] avg_epoch_loss=1.192428\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:13 INFO 140166612858688] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=1.19242835045\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:15 INFO 140166612858688] Epoch[110] Batch[5] avg_epoch_loss=1.128849\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:15 INFO 140166612858688] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=1.12884877125\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:15 INFO 140166612858688] Epoch[110] Batch [5]#011Speed: 189.18 samples/sec#011loss=1.128849\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:17 INFO 140166612858688] Epoch[110] Batch[10] avg_epoch_loss=1.141763\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:17 INFO 140166612858688] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=1.15726064444\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:17 INFO 140166612858688] Epoch[110] Batch [10]#011Speed: 188.58 samples/sec#011loss=1.157261\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:17 INFO 140166612858688] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4163.487195968628, \"sum\": 4163.487195968628, \"min\": 4163.487195968628}}, \"EndTime\": 1597991117.232554, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991113.068546}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:17 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=160.197567478 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:17 INFO 140166612858688] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:17 INFO 140166612858688] #quality_metric: host=algo-1, epoch=110, train loss <loss>=1.14176325906\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:17 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:18 INFO 140166612858688] Epoch[111] Batch[0] avg_epoch_loss=1.403067\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:18 INFO 140166612858688] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=1.40306699276\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:19 INFO 140166612858688] Epoch[111] Batch[5] avg_epoch_loss=1.131288\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:19 INFO 140166612858688] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=1.13128804167\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:19 INFO 140166612858688] Epoch[111] Batch [5]#011Speed: 186.59 samples/sec#011loss=1.131288\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:21 INFO 140166612858688] Epoch[111] Batch[10] avg_epoch_loss=1.097042\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:21 INFO 140166612858688] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=1.05594590902\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:21 INFO 140166612858688] Epoch[111] Batch [10]#011Speed: 186.14 samples/sec#011loss=1.055946\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:21 INFO 140166612858688] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4246.865034103394, \"sum\": 4246.865034103394, \"min\": 4246.865034103394}}, \"EndTime\": 1597991121.479923, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991117.232632}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:21 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=161.525856246 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:21 INFO 140166612858688] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:21 INFO 140166612858688] #quality_metric: host=algo-1, epoch=111, train loss <loss>=1.09704161774\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:21 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:22 INFO 140166612858688] Epoch[112] Batch[0] avg_epoch_loss=1.117292\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:22 INFO 140166612858688] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=1.11729180813\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:23 INFO 140166612858688] Epoch[112] Batch[5] avg_epoch_loss=1.235991\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:23 INFO 140166612858688] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=1.23599078258\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:23 INFO 140166612858688] Epoch[112] Batch [5]#011Speed: 184.75 samples/sec#011loss=1.235991\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:25 INFO 140166612858688] Epoch[112] Batch[10] avg_epoch_loss=1.080002\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:25 INFO 140166612858688] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=0.892814710736\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:25 INFO 140166612858688] Epoch[112] Batch [10]#011Speed: 186.25 samples/sec#011loss=0.892815\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:25 INFO 140166612858688] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4218.515157699585, \"sum\": 4218.515157699585, \"min\": 4218.515157699585}}, \"EndTime\": 1597991125.699054, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991121.480012}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:25 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=152.892837639 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:25 INFO 140166612858688] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:25 INFO 140166612858688] #quality_metric: host=algo-1, epoch=112, train loss <loss>=1.08000165901\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:25 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:25 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_5982a934-96fd-4ad1-9c3b-bdfea7ab07a1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 116.95289611816406, \"sum\": 116.95289611816406, \"min\": 116.95289611816406}}, \"EndTime\": 1597991125.816584, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991125.699138}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:25:26 INFO 140166612858688] Epoch[113] Batch[0] avg_epoch_loss=1.138485\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:26 INFO 140166612858688] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=1.13848471642\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:28 INFO 140166612858688] Epoch[113] Batch[5] avg_epoch_loss=1.208962\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:28 INFO 140166612858688] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=1.20896246036\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:28 INFO 140166612858688] Epoch[113] Batch [5]#011Speed: 192.22 samples/sec#011loss=1.208962\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:29 INFO 140166612858688] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3790.513038635254, \"sum\": 3790.513038635254, \"min\": 3790.513038635254}}, \"EndTime\": 1597991129.607254, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991125.816668}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:29 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=164.615913663 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:29 INFO 140166612858688] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:29 INFO 140166612858688] #quality_metric: host=algo-1, epoch=113, train loss <loss>=1.20988783836\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:29 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:30 INFO 140166612858688] Epoch[114] Batch[0] avg_epoch_loss=1.243970\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:30 INFO 140166612858688] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=1.24396967888\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:32 INFO 140166612858688] Epoch[114] Batch[5] avg_epoch_loss=1.175272\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:32 INFO 140166612858688] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=1.17527167002\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:32 INFO 140166612858688] Epoch[114] Batch [5]#011Speed: 190.81 samples/sec#011loss=1.175272\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:33 INFO 140166612858688] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3828.6430835723877, \"sum\": 3828.6430835723877, \"min\": 3828.6430835723877}}, \"EndTime\": 1597991133.436476, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991129.607341}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:33 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=166.371795279 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:33 INFO 140166612858688] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:33 INFO 140166612858688] #quality_metric: host=algo-1, epoch=114, train loss <loss>=1.16433394551\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:33 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:34 INFO 140166612858688] Epoch[115] Batch[0] avg_epoch_loss=1.238727\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:34 INFO 140166612858688] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=1.23872709274\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:35 INFO 140166612858688] Epoch[115] Batch[5] avg_epoch_loss=1.142433\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:35 INFO 140166612858688] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=1.14243298769\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:35 INFO 140166612858688] Epoch[115] Batch [5]#011Speed: 191.80 samples/sec#011loss=1.142433\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:37 INFO 140166612858688] Epoch[115] Batch[10] avg_epoch_loss=1.167982\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:37 INFO 140166612858688] #quality_metric: host=algo-1, epoch=115, batch=10 train loss <loss>=1.19864132404\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:37 INFO 140166612858688] Epoch[115] Batch [10]#011Speed: 189.48 samples/sec#011loss=1.198641\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:37 INFO 140166612858688] processed a total of 687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4152.894020080566, \"sum\": 4152.894020080566, \"min\": 4152.894020080566}}, \"EndTime\": 1597991137.589939, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991133.436565}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:37 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=165.421869198 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:37 INFO 140166612858688] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:37 INFO 140166612858688] #quality_metric: host=algo-1, epoch=115, train loss <loss>=1.16798223149\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:37 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:38 INFO 140166612858688] Epoch[116] Batch[0] avg_epoch_loss=1.213811\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:38 INFO 140166612858688] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=1.21381092072\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:40 INFO 140166612858688] Epoch[116] Batch[5] avg_epoch_loss=1.143490\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:40 INFO 140166612858688] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=1.14348965883\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:40 INFO 140166612858688] Epoch[116] Batch [5]#011Speed: 190.67 samples/sec#011loss=1.143490\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:41 INFO 140166612858688] Epoch[116] Batch[10] avg_epoch_loss=1.116097\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:41 INFO 140166612858688] #quality_metric: host=algo-1, epoch=116, batch=10 train loss <loss>=1.08322643042\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:41 INFO 140166612858688] Epoch[116] Batch [10]#011Speed: 188.60 samples/sec#011loss=1.083226\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:41 INFO 140166612858688] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4199.758052825928, \"sum\": 4199.758052825928, \"min\": 4199.758052825928}}, \"EndTime\": 1597991141.790219, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991137.590022}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:41 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=162.147420741 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:41 INFO 140166612858688] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:41 INFO 140166612858688] #quality_metric: host=algo-1, epoch=116, train loss <loss>=1.11609728228\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:41 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:42 INFO 140166612858688] Epoch[117] Batch[0] avg_epoch_loss=1.185670\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:42 INFO 140166612858688] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=1.18567037582\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:44 INFO 140166612858688] Epoch[117] Batch[5] avg_epoch_loss=1.212062\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:44 INFO 140166612858688] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=1.21206174294\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:44 INFO 140166612858688] Epoch[117] Batch [5]#011Speed: 187.47 samples/sec#011loss=1.212062\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:45 INFO 140166612858688] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3837.7702236175537, \"sum\": 3837.7702236175537, \"min\": 3837.7702236175537}}, \"EndTime\": 1597991145.628582, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991141.790303}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:45 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=164.412741295 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:45 INFO 140166612858688] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:45 INFO 140166612858688] #quality_metric: host=algo-1, epoch=117, train loss <loss>=1.15073355436\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:45 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:46 INFO 140166612858688] Epoch[118] Batch[0] avg_epoch_loss=0.842647\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:46 INFO 140166612858688] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=0.842646539211\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:48 INFO 140166612858688] Epoch[118] Batch[5] avg_epoch_loss=1.057072\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:48 INFO 140166612858688] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=1.05707185467\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:48 INFO 140166612858688] Epoch[118] Batch [5]#011Speed: 190.76 samples/sec#011loss=1.057072\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:49 INFO 140166612858688] Epoch[118] Batch[10] avg_epoch_loss=1.058329\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:49 INFO 140166612858688] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=1.05983818769\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:49 INFO 140166612858688] Epoch[118] Batch [10]#011Speed: 191.08 samples/sec#011loss=1.059838\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:49 INFO 140166612858688] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4171.823978424072, \"sum\": 4171.823978424072, \"min\": 4171.823978424072}}, \"EndTime\": 1597991149.801026, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991145.628672}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:49 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=161.555338012 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:49 INFO 140166612858688] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:49 INFO 140166612858688] #quality_metric: host=algo-1, epoch=118, train loss <loss>=1.05832927877\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:49 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:49 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_0dcc81f7-c81c-45c6-81d1-9e64d7096926-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 118.98088455200195, \"sum\": 118.98088455200195, \"min\": 118.98088455200195}}, \"EndTime\": 1597991149.92057, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991149.801109}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:50 INFO 140166612858688] Epoch[119] Batch[0] avg_epoch_loss=1.085960\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:50 INFO 140166612858688] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=1.08596003056\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:52 INFO 140166612858688] Epoch[119] Batch[5] avg_epoch_loss=1.040654\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:52 INFO 140166612858688] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=1.0406541427\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:52 INFO 140166612858688] Epoch[119] Batch [5]#011Speed: 186.81 samples/sec#011loss=1.040654\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:54 INFO 140166612858688] Epoch[119] Batch[10] avg_epoch_loss=1.049450\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:54 INFO 140166612858688] #quality_metric: host=algo-1, epoch=119, batch=10 train loss <loss>=1.06000517607\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:54 INFO 140166612858688] Epoch[119] Batch [10]#011Speed: 187.32 samples/sec#011loss=1.060005\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:54 INFO 140166612858688] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4203.297853469849, \"sum\": 4203.297853469849, \"min\": 4203.297853469849}}, \"EndTime\": 1597991154.124021, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991149.920654}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:54 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=160.345889984 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:54 INFO 140166612858688] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:54 INFO 140166612858688] #quality_metric: host=algo-1, epoch=119, train loss <loss>=1.04945006696\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:54 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:54 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_ef7ecc92-651c-4cac-934b-acf7a08312c1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 114.14813995361328, \"sum\": 114.14813995361328, \"min\": 114.14813995361328}}, \"EndTime\": 1597991154.238829, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991154.124099}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:55 INFO 140166612858688] Epoch[120] Batch[0] avg_epoch_loss=1.096305\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:55 INFO 140166612858688] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=1.09630465508\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:56 INFO 140166612858688] Epoch[120] Batch[5] avg_epoch_loss=1.138687\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:56 INFO 140166612858688] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=1.13868661722\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:56 INFO 140166612858688] Epoch[120] Batch [5]#011Speed: 187.42 samples/sec#011loss=1.138687\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:58 INFO 140166612858688] Epoch[120] Batch[10] avg_epoch_loss=1.055208\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:58 INFO 140166612858688] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=0.955033218861\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:58 INFO 140166612858688] Epoch[120] Batch [10]#011Speed: 188.44 samples/sec#011loss=0.955033\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:58 INFO 140166612858688] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4176.403999328613, \"sum\": 4176.403999328613, \"min\": 4176.403999328613}}, \"EndTime\": 1597991158.415383, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991154.238913}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:58 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=159.941509873 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:58 INFO 140166612858688] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:58 INFO 140166612858688] #quality_metric: host=algo-1, epoch=120, train loss <loss>=1.05520779978\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:58 INFO 140166612858688] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:25:59 INFO 140166612858688] Epoch[121] Batch[0] avg_epoch_loss=1.004391\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:25:59 INFO 140166612858688] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=1.00439071655\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:00 INFO 140166612858688] Epoch[121] Batch[5] avg_epoch_loss=1.180121\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:00 INFO 140166612858688] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=1.18012122313\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:00 INFO 140166612858688] Epoch[121] Batch [5]#011Speed: 179.86 samples/sec#011loss=1.180121\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:02 INFO 140166612858688] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3918.370008468628, \"sum\": 3918.370008468628, \"min\": 3918.370008468628}}, \"EndTime\": 1597991162.334358, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991158.415463}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:02 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=163.328303113 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:02 INFO 140166612858688] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:02 INFO 140166612858688] #quality_metric: host=algo-1, epoch=121, train loss <loss>=1.20468856096\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:02 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:03 INFO 140166612858688] Epoch[122] Batch[0] avg_epoch_loss=0.964156\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:03 INFO 140166612858688] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=0.964156091213\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:04 INFO 140166612858688] Epoch[122] Batch[5] avg_epoch_loss=1.072435\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:04 INFO 140166612858688] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=1.07243518035\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:04 INFO 140166612858688] Epoch[122] Batch [5]#011Speed: 188.54 samples/sec#011loss=1.072435\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:06 INFO 140166612858688] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3837.1529579162598, \"sum\": 3837.1529579162598, \"min\": 3837.1529579162598}}, \"EndTime\": 1597991166.172136, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991162.334437}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:06 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=163.917375793 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:06 INFO 140166612858688] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:06 INFO 140166612858688] #quality_metric: host=algo-1, epoch=122, train loss <loss>=1.05215078592\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:06 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:06 INFO 140166612858688] Epoch[123] Batch[0] avg_epoch_loss=1.237298\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:06 INFO 140166612858688] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=1.23729765415\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:08 INFO 140166612858688] Epoch[123] Batch[5] avg_epoch_loss=1.163886\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:08 INFO 140166612858688] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=1.16388603052\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:08 INFO 140166612858688] Epoch[123] Batch [5]#011Speed: 183.47 samples/sec#011loss=1.163886\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:10 INFO 140166612858688] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3888.826847076416, \"sum\": 3888.826847076416, \"min\": 3888.826847076416}}, \"EndTime\": 1597991170.061602, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991166.172237}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:10 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=161.484251254 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:10 INFO 140166612858688] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:10 INFO 140166612858688] #quality_metric: host=algo-1, epoch=123, train loss <loss>=1.14736251831\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:10 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:10 INFO 140166612858688] Epoch[124] Batch[0] avg_epoch_loss=1.101693\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:10 INFO 140166612858688] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=1.10169315338\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:12 INFO 140166612858688] Epoch[124] Batch[5] avg_epoch_loss=1.213808\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:12 INFO 140166612858688] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=1.21380805969\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:12 INFO 140166612858688] Epoch[124] Batch [5]#011Speed: 187.64 samples/sec#011loss=1.213808\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:13 INFO 140166612858688] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3819.5950984954834, \"sum\": 3819.5950984954834, \"min\": 3819.5950984954834}}, \"EndTime\": 1597991173.881743, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991170.061666}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:13 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=165.717907209 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:13 INFO 140166612858688] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:13 INFO 140166612858688] #quality_metric: host=algo-1, epoch=124, train loss <loss>=1.26803748608\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:13 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:14 INFO 140166612858688] Epoch[125] Batch[0] avg_epoch_loss=1.068028\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:14 INFO 140166612858688] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=1.06802821159\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:16 INFO 140166612858688] Epoch[125] Batch[5] avg_epoch_loss=1.141295\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:16 INFO 140166612858688] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=1.14129515489\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:16 INFO 140166612858688] Epoch[125] Batch [5]#011Speed: 190.52 samples/sec#011loss=1.141295\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:17 INFO 140166612858688] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3794.297933578491, \"sum\": 3794.297933578491, \"min\": 3794.297933578491}}, \"EndTime\": 1597991177.676633, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991173.88183}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:17 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=168.40482451 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:17 INFO 140166612858688] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:17 INFO 140166612858688] #quality_metric: host=algo-1, epoch=125, train loss <loss>=1.15538698435\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:17 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:18 INFO 140166612858688] Epoch[126] Batch[0] avg_epoch_loss=1.084320\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:18 INFO 140166612858688] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=1.08432042599\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:20 INFO 140166612858688] Epoch[126] Batch[5] avg_epoch_loss=1.147375\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:20 INFO 140166612858688] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=1.14737462997\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:20 INFO 140166612858688] Epoch[126] Batch [5]#011Speed: 192.10 samples/sec#011loss=1.147375\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:21 INFO 140166612858688] Epoch[126] Batch[10] avg_epoch_loss=1.104348\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:21 INFO 140166612858688] #quality_metric: host=algo-1, epoch=126, batch=10 train loss <loss>=1.05271670818\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:21 INFO 140166612858688] Epoch[126] Batch [10]#011Speed: 188.47 samples/sec#011loss=1.052717\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:21 INFO 140166612858688] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4176.40495300293, \"sum\": 4176.40495300293, \"min\": 4176.40495300293}}, \"EndTime\": 1597991181.853619, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991177.676721}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:21 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=155.392195475 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:21 INFO 140166612858688] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:21 INFO 140166612858688] #quality_metric: host=algo-1, epoch=126, train loss <loss>=1.10434830189\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:21 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:22 INFO 140166612858688] Epoch[127] Batch[0] avg_epoch_loss=1.186110\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:22 INFO 140166612858688] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=1.18610990047\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:24 INFO 140166612858688] Epoch[127] Batch[5] avg_epoch_loss=1.150526\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:24 INFO 140166612858688] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=1.15052561959\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:24 INFO 140166612858688] Epoch[127] Batch [5]#011Speed: 192.76 samples/sec#011loss=1.150526\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:26:25 INFO 140166612858688] Epoch[127] Batch[10] avg_epoch_loss=1.071371\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:25 INFO 140166612858688] #quality_metric: host=algo-1, epoch=127, batch=10 train loss <loss>=0.976385551691\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:25 INFO 140166612858688] Epoch[127] Batch [10]#011Speed: 191.07 samples/sec#011loss=0.976386\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:25 INFO 140166612858688] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4122.825145721436, \"sum\": 4122.825145721436, \"min\": 4122.825145721436}}, \"EndTime\": 1597991185.976968, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991181.853702}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:25 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=160.322105742 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:25 INFO 140166612858688] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:25 INFO 140166612858688] #quality_metric: host=algo-1, epoch=127, train loss <loss>=1.07137104327\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:25 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:26 INFO 140166612858688] Epoch[128] Batch[0] avg_epoch_loss=1.012458\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:26 INFO 140166612858688] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=1.01245832443\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:28 INFO 140166612858688] Epoch[128] Batch[5] avg_epoch_loss=1.124103\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:28 INFO 140166612858688] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=1.12410277128\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:28 INFO 140166612858688] Epoch[128] Batch [5]#011Speed: 188.86 samples/sec#011loss=1.124103\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:30 INFO 140166612858688] Epoch[128] Batch[10] avg_epoch_loss=1.132720\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:30 INFO 140166612858688] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=1.14306128025\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:30 INFO 140166612858688] Epoch[128] Batch [10]#011Speed: 191.31 samples/sec#011loss=1.143061\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:30 INFO 140166612858688] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4163.764953613281, \"sum\": 4163.764953613281, \"min\": 4163.764953613281}}, \"EndTime\": 1597991190.141256, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991185.977052}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:30 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=161.627981554 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:30 INFO 140166612858688] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:30 INFO 140166612858688] #quality_metric: host=algo-1, epoch=128, train loss <loss>=1.13272027536\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:30 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:30 INFO 140166612858688] Epoch[129] Batch[0] avg_epoch_loss=1.034573\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:30 INFO 140166612858688] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=1.03457272053\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:32 INFO 140166612858688] Epoch[129] Batch[5] avg_epoch_loss=1.106460\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:32 INFO 140166612858688] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=1.1064598461\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:32 INFO 140166612858688] Epoch[129] Batch [5]#011Speed: 190.44 samples/sec#011loss=1.106460\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:34 INFO 140166612858688] Epoch[129] Batch[10] avg_epoch_loss=1.149025\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:34 INFO 140166612858688] #quality_metric: host=algo-1, epoch=129, batch=10 train loss <loss>=1.20010311604\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:34 INFO 140166612858688] Epoch[129] Batch [10]#011Speed: 190.81 samples/sec#011loss=1.200103\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:34 INFO 140166612858688] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4156.013965606689, \"sum\": 4156.013965606689, \"min\": 4156.013965606689}}, \"EndTime\": 1597991194.297814, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991190.141334}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:34 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=155.673405766 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:34 INFO 140166612858688] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:34 INFO 140166612858688] #quality_metric: host=algo-1, epoch=129, train loss <loss>=1.1490249688\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:34 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:35 INFO 140166612858688] Epoch[130] Batch[0] avg_epoch_loss=1.038996\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:35 INFO 140166612858688] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=1.03899586201\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:36 INFO 140166612858688] Epoch[130] Batch[5] avg_epoch_loss=1.106552\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:36 INFO 140166612858688] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=1.10655157765\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:36 INFO 140166612858688] Epoch[130] Batch [5]#011Speed: 191.99 samples/sec#011loss=1.106552\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:38 INFO 140166612858688] Epoch[130] Batch[10] avg_epoch_loss=1.027586\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:38 INFO 140166612858688] #quality_metric: host=algo-1, epoch=130, batch=10 train loss <loss>=0.932827198505\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:38 INFO 140166612858688] Epoch[130] Batch [10]#011Speed: 185.80 samples/sec#011loss=0.932827\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:38 INFO 140166612858688] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4194.03600692749, \"sum\": 4194.03600692749, \"min\": 4194.03600692749}}, \"EndTime\": 1597991198.492406, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991194.297895}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:38 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=158.077053498 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:38 INFO 140166612858688] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:38 INFO 140166612858688] #quality_metric: host=algo-1, epoch=130, train loss <loss>=1.02758595076\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:38 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:38 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_0e88a126-6507-4e90-b2dc-cba9c593aa80-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 125.57315826416016, \"sum\": 125.57315826416016, \"min\": 125.57315826416016}}, \"EndTime\": 1597991198.618587, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991198.492488}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:39 INFO 140166612858688] Epoch[131] Batch[0] avg_epoch_loss=0.917991\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:39 INFO 140166612858688] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=0.91799134016\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:41 INFO 140166612858688] Epoch[131] Batch[5] avg_epoch_loss=1.165023\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:41 INFO 140166612858688] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=1.16502256195\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:41 INFO 140166612858688] Epoch[131] Batch [5]#011Speed: 191.93 samples/sec#011loss=1.165023\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:42 INFO 140166612858688] Epoch[131] Batch[10] avg_epoch_loss=1.060037\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:42 INFO 140166612858688] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=0.934054285288\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:42 INFO 140166612858688] Epoch[131] Batch [10]#011Speed: 188.73 samples/sec#011loss=0.934054\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:42 INFO 140166612858688] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4150.758981704712, \"sum\": 4150.758981704712, \"min\": 4150.758981704712}}, \"EndTime\": 1597991202.769504, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991198.618671}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:42 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=159.243227639 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:42 INFO 140166612858688] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:42 INFO 140166612858688] #quality_metric: host=algo-1, epoch=131, train loss <loss>=1.06003698165\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:42 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:43 INFO 140166612858688] Epoch[132] Batch[0] avg_epoch_loss=1.223306\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:43 INFO 140166612858688] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=1.22330582142\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:45 INFO 140166612858688] Epoch[132] Batch[5] avg_epoch_loss=1.142398\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:45 INFO 140166612858688] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=1.14239769181\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:45 INFO 140166612858688] Epoch[132] Batch [5]#011Speed: 190.03 samples/sec#011loss=1.142398\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:46 INFO 140166612858688] Epoch[132] Batch[10] avg_epoch_loss=1.014723\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:46 INFO 140166612858688] #quality_metric: host=algo-1, epoch=132, batch=10 train loss <loss>=0.861513032764\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:46 INFO 140166612858688] Epoch[132] Batch [10]#011Speed: 188.64 samples/sec#011loss=0.861513\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:46 INFO 140166612858688] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4156.873941421509, \"sum\": 4156.873941421509, \"min\": 4156.873941421509}}, \"EndTime\": 1597991206.926916, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991202.769586}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:46 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=154.92015698 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:46 INFO 140166612858688] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:46 INFO 140166612858688] #quality_metric: host=algo-1, epoch=132, train loss <loss>=1.01472284679\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:46 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:47 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_94a6121a-b0a4-471d-841a-9d9bfffd69f5-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 108.63089561462402, \"sum\": 108.63089561462402, \"min\": 108.63089561462402}}, \"EndTime\": 1597991207.036118, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991206.926987}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:26:47 INFO 140166612858688] Epoch[133] Batch[0] avg_epoch_loss=1.000399\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:47 INFO 140166612858688] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=1.00039935112\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:49 INFO 140166612858688] Epoch[133] Batch[5] avg_epoch_loss=1.075798\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:49 INFO 140166612858688] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=1.07579753796\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:49 INFO 140166612858688] Epoch[133] Batch [5]#011Speed: 188.57 samples/sec#011loss=1.075798\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:50 INFO 140166612858688] processed a total of 587 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3811.619997024536, \"sum\": 3811.619997024536, \"min\": 3811.619997024536}}, \"EndTime\": 1597991210.8479, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991207.036208}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:50 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=153.997597017 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:50 INFO 140166612858688] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:50 INFO 140166612858688] #quality_metric: host=algo-1, epoch=133, train loss <loss>=1.01099816263\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:50 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:50 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_a23dd563-f48b-417d-9c6d-3a7346ef1fde-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 116.60313606262207, \"sum\": 116.60313606262207, \"min\": 116.60313606262207}}, \"EndTime\": 1597991210.965172, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991210.847987}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:51 INFO 140166612858688] Epoch[134] Batch[0] avg_epoch_loss=0.931469\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:51 INFO 140166612858688] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=0.931469321251\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:53 INFO 140166612858688] Epoch[134] Batch[5] avg_epoch_loss=1.061469\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:53 INFO 140166612858688] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=1.06146915754\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:53 INFO 140166612858688] Epoch[134] Batch [5]#011Speed: 190.38 samples/sec#011loss=1.061469\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:55 INFO 140166612858688] Epoch[134] Batch[10] avg_epoch_loss=0.996884\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:55 INFO 140166612858688] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=0.919381913543\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:55 INFO 140166612858688] Epoch[134] Batch [10]#011Speed: 188.80 samples/sec#011loss=0.919382\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:55 INFO 140166612858688] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4163.961887359619, \"sum\": 4163.961887359619, \"min\": 4163.961887359619}}, \"EndTime\": 1597991215.129274, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991210.965246}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:55 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=159.93932145 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:55 INFO 140166612858688] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:55 INFO 140166612858688] #quality_metric: host=algo-1, epoch=134, train loss <loss>=0.99688404663\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:55 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:55 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_9459f6e3-0453-4cbc-a951-89cb374a65e5-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 113.88802528381348, \"sum\": 113.88802528381348, \"min\": 113.88802528381348}}, \"EndTime\": 1597991215.243765, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991215.129352}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:55 INFO 140166612858688] Epoch[135] Batch[0] avg_epoch_loss=0.902855\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:55 INFO 140166612858688] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=0.902855396271\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:57 INFO 140166612858688] Epoch[135] Batch[5] avg_epoch_loss=1.038174\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:57 INFO 140166612858688] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=1.03817381461\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:57 INFO 140166612858688] Epoch[135] Batch [5]#011Speed: 190.15 samples/sec#011loss=1.038174\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:59 INFO 140166612858688] processed a total of 591 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3822.176933288574, \"sum\": 3822.176933288574, \"min\": 3822.176933288574}}, \"EndTime\": 1597991219.066093, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991215.243848}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:59 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=154.618620525 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:59 INFO 140166612858688] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:59 INFO 140166612858688] #quality_metric: host=algo-1, epoch=135, train loss <loss>=1.02829400897\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:59 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:59 INFO 140166612858688] Epoch[136] Batch[0] avg_epoch_loss=1.120307\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:26:59 INFO 140166612858688] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=1.12030673027\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:01 INFO 140166612858688] Epoch[136] Batch[5] avg_epoch_loss=1.091327\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:01 INFO 140166612858688] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=1.09132661422\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:01 INFO 140166612858688] Epoch[136] Batch [5]#011Speed: 189.70 samples/sec#011loss=1.091327\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:03 INFO 140166612858688] Epoch[136] Batch[10] avg_epoch_loss=1.082347\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:03 INFO 140166612858688] #quality_metric: host=algo-1, epoch=136, batch=10 train loss <loss>=1.07157126665\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:03 INFO 140166612858688] Epoch[136] Batch [10]#011Speed: 187.16 samples/sec#011loss=1.071571\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:03 INFO 140166612858688] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4170.798063278198, \"sum\": 4170.798063278198, \"min\": 4170.798063278198}}, \"EndTime\": 1597991223.237517, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991219.066181}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:03 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=161.835071379 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:03 INFO 140166612858688] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:03 INFO 140166612858688] #quality_metric: host=algo-1, epoch=136, train loss <loss>=1.08234691078\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:03 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:03 INFO 140166612858688] Epoch[137] Batch[0] avg_epoch_loss=1.420172\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:03 INFO 140166612858688] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=1.4201720953\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:05 INFO 140166612858688] Epoch[137] Batch[5] avg_epoch_loss=1.194812\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:05 INFO 140166612858688] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=1.19481225808\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:05 INFO 140166612858688] Epoch[137] Batch [5]#011Speed: 189.35 samples/sec#011loss=1.194812\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:06 INFO 140166612858688] processed a total of 575 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3459.552049636841, \"sum\": 3459.552049636841, \"min\": 3459.552049636841}}, \"EndTime\": 1597991226.697631, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991223.237588}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:06 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=166.201689882 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:06 INFO 140166612858688] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:06 INFO 140166612858688] #quality_metric: host=algo-1, epoch=137, train loss <loss>=1.14850502544\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:06 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:07 INFO 140166612858688] Epoch[138] Batch[0] avg_epoch_loss=1.167982\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:07 INFO 140166612858688] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=1.16798245907\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:27:09 INFO 140166612858688] Epoch[138] Batch[5] avg_epoch_loss=1.029374\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:09 INFO 140166612858688] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=1.02937425176\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:09 INFO 140166612858688] Epoch[138] Batch [5]#011Speed: 186.49 samples/sec#011loss=1.029374\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:10 INFO 140166612858688] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3808.725118637085, \"sum\": 3808.725118637085, \"min\": 3808.725118637085}}, \"EndTime\": 1597991230.506935, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991226.697694}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:10 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=164.878727368 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:10 INFO 140166612858688] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:10 INFO 140166612858688] #quality_metric: host=algo-1, epoch=138, train loss <loss>=1.05335237384\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:10 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:11 INFO 140166612858688] Epoch[139] Batch[0] avg_epoch_loss=1.254505\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:11 INFO 140166612858688] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=1.25450491905\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:12 INFO 140166612858688] Epoch[139] Batch[5] avg_epoch_loss=1.093907\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:12 INFO 140166612858688] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=1.09390737613\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:12 INFO 140166612858688] Epoch[139] Batch [5]#011Speed: 191.80 samples/sec#011loss=1.093907\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:14 INFO 140166612858688] Epoch[139] Batch[10] avg_epoch_loss=1.107876\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:14 INFO 140166612858688] #quality_metric: host=algo-1, epoch=139, batch=10 train loss <loss>=1.12463912964\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:14 INFO 140166612858688] Epoch[139] Batch [10]#011Speed: 190.66 samples/sec#011loss=1.124639\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:14 INFO 140166612858688] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4163.509130477905, \"sum\": 4163.509130477905, \"min\": 4163.509130477905}}, \"EndTime\": 1597991234.671035, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991230.507026}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:14 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=158.275350745 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:14 INFO 140166612858688] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:14 INFO 140166612858688] #quality_metric: host=algo-1, epoch=139, train loss <loss>=1.107876355\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:14 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:15 INFO 140166612858688] Epoch[140] Batch[0] avg_epoch_loss=1.264873\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:15 INFO 140166612858688] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=1.26487267017\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:17 INFO 140166612858688] Epoch[140] Batch[5] avg_epoch_loss=1.065991\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:17 INFO 140166612858688] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=1.06599077582\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:17 INFO 140166612858688] Epoch[140] Batch [5]#011Speed: 192.13 samples/sec#011loss=1.065991\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:18 INFO 140166612858688] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3780.972957611084, \"sum\": 3780.972957611084, \"min\": 3780.972957611084}}, \"EndTime\": 1597991238.452535, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991234.671117}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:18 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=168.998448712 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:18 INFO 140166612858688] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:18 INFO 140166612858688] #quality_metric: host=algo-1, epoch=140, train loss <loss>=1.07895178199\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:18 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:19 INFO 140166612858688] Epoch[141] Batch[0] avg_epoch_loss=0.843614\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:19 INFO 140166612858688] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=0.843614339828\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:20 INFO 140166612858688] Epoch[141] Batch[5] avg_epoch_loss=1.037689\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:20 INFO 140166612858688] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=1.0376889805\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:20 INFO 140166612858688] Epoch[141] Batch [5]#011Speed: 191.44 samples/sec#011loss=1.037689\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:22 INFO 140166612858688] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3846.928119659424, \"sum\": 3846.928119659424, \"min\": 3846.928119659424}}, \"EndTime\": 1597991242.300034, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991238.452621}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:22 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=161.162201481 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:22 INFO 140166612858688] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:22 INFO 140166612858688] #quality_metric: host=algo-1, epoch=141, train loss <loss>=1.05762612224\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:22 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:23 INFO 140166612858688] Epoch[142] Batch[0] avg_epoch_loss=0.986820\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:23 INFO 140166612858688] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=0.986819565296\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:24 INFO 140166612858688] Epoch[142] Batch[5] avg_epoch_loss=1.091783\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:24 INFO 140166612858688] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=1.09178339442\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:24 INFO 140166612858688] Epoch[142] Batch [5]#011Speed: 190.32 samples/sec#011loss=1.091783\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:26 INFO 140166612858688] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3833.8701725006104, \"sum\": 3833.8701725006104, \"min\": 3833.8701725006104}}, \"EndTime\": 1597991246.134523, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991242.300122}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:26 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=159.885908831 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:26 INFO 140166612858688] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:26 INFO 140166612858688] #quality_metric: host=algo-1, epoch=142, train loss <loss>=1.06983523965\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:26 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:26 INFO 140166612858688] Epoch[143] Batch[0] avg_epoch_loss=1.049965\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:26 INFO 140166612858688] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=1.0499651432\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:28 INFO 140166612858688] Epoch[143] Batch[5] avg_epoch_loss=1.083584\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:28 INFO 140166612858688] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=1.08358390133\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:28 INFO 140166612858688] Epoch[143] Batch [5]#011Speed: 188.57 samples/sec#011loss=1.083584\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:29 INFO 140166612858688] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3819.610118865967, \"sum\": 3819.610118865967, \"min\": 3819.610118865967}}, \"EndTime\": 1597991249.954756, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991246.134594}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:29 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=167.288922777 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:29 INFO 140166612858688] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:29 INFO 140166612858688] #quality_metric: host=algo-1, epoch=143, train loss <loss>=1.13255802989\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:29 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:30 INFO 140166612858688] Epoch[144] Batch[0] avg_epoch_loss=1.109082\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:30 INFO 140166612858688] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=1.10908198357\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:32 INFO 140166612858688] Epoch[144] Batch[5] avg_epoch_loss=1.094202\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:32 INFO 140166612858688] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=1.09420150518\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:32 INFO 140166612858688] Epoch[144] Batch [5]#011Speed: 191.79 samples/sec#011loss=1.094202\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:34 INFO 140166612858688] Epoch[144] Batch[10] avg_epoch_loss=1.086220\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:34 INFO 140166612858688] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=1.07664253712\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:34 INFO 140166612858688] Epoch[144] Batch [10]#011Speed: 191.12 samples/sec#011loss=1.076643\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:34 INFO 140166612858688] processed a total of 682 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4124.490022659302, \"sum\": 4124.490022659302, \"min\": 4124.490022659302}}, \"EndTime\": 1597991254.079874, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991249.954845}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:34 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=165.348844191 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:34 INFO 140166612858688] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:34 INFO 140166612858688] #quality_metric: host=algo-1, epoch=144, train loss <loss>=1.08622015606\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:34 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:34 INFO 140166612858688] Epoch[145] Batch[0] avg_epoch_loss=1.128978\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:34 INFO 140166612858688] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=1.1289781332\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:27:36 INFO 140166612858688] Epoch[145] Batch[5] avg_epoch_loss=1.040783\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:36 INFO 140166612858688] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=1.04078267018\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:36 INFO 140166612858688] Epoch[145] Batch [5]#011Speed: 189.52 samples/sec#011loss=1.040783\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:38 INFO 140166612858688] Epoch[145] Batch[10] avg_epoch_loss=0.942660\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:38 INFO 140166612858688] #quality_metric: host=algo-1, epoch=145, batch=10 train loss <loss>=0.824912573583\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:38 INFO 140166612858688] Epoch[145] Batch [10]#011Speed: 187.49 samples/sec#011loss=0.824913\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:38 INFO 140166612858688] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4175.925016403198, \"sum\": 4175.925016403198, \"min\": 4175.925016403198}}, \"EndTime\": 1597991258.256391, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991254.079956}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:38 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=154.212706096 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:38 INFO 140166612858688] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:38 INFO 140166612858688] #quality_metric: host=algo-1, epoch=145, train loss <loss>=0.942659899\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:38 INFO 140166612858688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:38 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/state_91c192e3-a188-4805-a2d5-1dd7a6a66b5f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 110.56184768676758, \"sum\": 110.56184768676758, \"min\": 110.56184768676758}}, \"EndTime\": 1597991258.367592, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991258.256472}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:39 INFO 140166612858688] Epoch[146] Batch[0] avg_epoch_loss=0.855019\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:39 INFO 140166612858688] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=0.855018734932\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:40 INFO 140166612858688] Epoch[146] Batch[5] avg_epoch_loss=1.022383\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:40 INFO 140166612858688] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=1.0223834614\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:40 INFO 140166612858688] Epoch[146] Batch [5]#011Speed: 191.72 samples/sec#011loss=1.022383\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:42 INFO 140166612858688] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3824.3000507354736, \"sum\": 3824.3000507354736, \"min\": 3824.3000507354736}}, \"EndTime\": 1597991262.192023, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991258.367667}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:42 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=161.593977718 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:42 INFO 140166612858688] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:42 INFO 140166612858688] #quality_metric: host=algo-1, epoch=146, train loss <loss>=1.07771416306\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:42 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:42 INFO 140166612858688] Epoch[147] Batch[0] avg_epoch_loss=1.089004\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:42 INFO 140166612858688] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=1.08900403976\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:44 INFO 140166612858688] Epoch[147] Batch[5] avg_epoch_loss=1.052182\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:44 INFO 140166612858688] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=1.05218246579\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:44 INFO 140166612858688] Epoch[147] Batch [5]#011Speed: 189.92 samples/sec#011loss=1.052182\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:46 INFO 140166612858688] Epoch[147] Batch[10] avg_epoch_loss=1.071382\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:46 INFO 140166612858688] #quality_metric: host=algo-1, epoch=147, batch=10 train loss <loss>=1.09442151785\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:46 INFO 140166612858688] Epoch[147] Batch [10]#011Speed: 188.22 samples/sec#011loss=1.094422\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:46 INFO 140166612858688] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4157.280921936035, \"sum\": 4157.280921936035, \"min\": 4157.280921936035}}, \"EndTime\": 1597991266.349939, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991262.19209}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:46 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=154.904396134 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:46 INFO 140166612858688] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:46 INFO 140166612858688] #quality_metric: host=algo-1, epoch=147, train loss <loss>=1.07138203491\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:46 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:47 INFO 140166612858688] Epoch[148] Batch[0] avg_epoch_loss=0.963202\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:47 INFO 140166612858688] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=0.963201642036\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:48 INFO 140166612858688] Epoch[148] Batch[5] avg_epoch_loss=1.029834\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:48 INFO 140166612858688] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=1.02983447909\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:48 INFO 140166612858688] Epoch[148] Batch [5]#011Speed: 186.96 samples/sec#011loss=1.029834\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:50 INFO 140166612858688] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3831.7770957946777, \"sum\": 3831.7770957946777, \"min\": 3831.7770957946777}}, \"EndTime\": 1597991270.182286, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991266.350015}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:50 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=164.932092008 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:50 INFO 140166612858688] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:50 INFO 140166612858688] #quality_metric: host=algo-1, epoch=148, train loss <loss>=0.981825941801\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:50 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:50 INFO 140166612858688] Epoch[149] Batch[0] avg_epoch_loss=1.081780\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:50 INFO 140166612858688] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=1.08178019524\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:52 INFO 140166612858688] Epoch[149] Batch[5] avg_epoch_loss=1.024397\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:52 INFO 140166612858688] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=1.02439716458\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:52 INFO 140166612858688] Epoch[149] Batch [5]#011Speed: 182.02 samples/sec#011loss=1.024397\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:54 INFO 140166612858688] Epoch[149] Batch[10] avg_epoch_loss=1.007984\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:54 INFO 140166612858688] #quality_metric: host=algo-1, epoch=149, batch=10 train loss <loss>=0.988287520409\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:54 INFO 140166612858688] Epoch[149] Batch [10]#011Speed: 189.25 samples/sec#011loss=0.988288\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:54 INFO 140166612858688] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4223.045110702515, \"sum\": 4223.045110702515, \"min\": 4223.045110702515}}, \"EndTime\": 1597991274.40594, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991270.182353}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:54 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=158.885466191 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:54 INFO 140166612858688] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:54 INFO 140166612858688] #quality_metric: host=algo-1, epoch=149, train loss <loss>=1.00798368996\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:54 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:55 INFO 140166612858688] Epoch[150] Batch[0] avg_epoch_loss=0.988804\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:55 INFO 140166612858688] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=0.988803505898\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:56 INFO 140166612858688] Epoch[150] Batch[5] avg_epoch_loss=1.136972\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:56 INFO 140166612858688] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=1.13697157303\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:56 INFO 140166612858688] Epoch[150] Batch [5]#011Speed: 191.03 samples/sec#011loss=1.136972\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:27:58 INFO 140166612858688] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3804.989814758301, \"sum\": 3804.989814758301, \"min\": 3804.989814758301}}, \"EndTime\": 1597991278.211482, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991274.406022}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:58 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=167.668867568 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:58 INFO 140166612858688] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:58 INFO 140166612858688] #quality_metric: host=algo-1, epoch=150, train loss <loss>=1.07456769347\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:58 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:59 INFO 140166612858688] Epoch[151] Batch[0] avg_epoch_loss=1.109840\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:27:59 INFO 140166612858688] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=1.10984003544\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:00 INFO 140166612858688] Epoch[151] Batch[5] avg_epoch_loss=1.132305\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:00 INFO 140166612858688] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=1.13230532408\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:00 INFO 140166612858688] Epoch[151] Batch [5]#011Speed: 190.59 samples/sec#011loss=1.132305\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:02 INFO 140166612858688] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3838.474988937378, \"sum\": 3838.474988937378, \"min\": 3838.474988937378}}, \"EndTime\": 1597991282.050562, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991278.211569}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:02 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=162.298798447 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:02 INFO 140166612858688] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:02 INFO 140166612858688] #quality_metric: host=algo-1, epoch=151, train loss <loss>=1.14360010624\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:02 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:02 INFO 140166612858688] Epoch[152] Batch[0] avg_epoch_loss=0.863516\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:02 INFO 140166612858688] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=0.86351621151\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:04 INFO 140166612858688] Epoch[152] Batch[5] avg_epoch_loss=1.042904\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:04 INFO 140166612858688] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=1.04290381074\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:04 INFO 140166612858688] Epoch[152] Batch [5]#011Speed: 190.70 samples/sec#011loss=1.042904\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:05 INFO 140166612858688] processed a total of 581 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3812.3018741607666, \"sum\": 3812.3018741607666, \"min\": 3812.3018741607666}}, \"EndTime\": 1597991285.86344, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991282.050646}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:05 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=152.396082501 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:05 INFO 140166612858688] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:05 INFO 140166612858688] #quality_metric: host=algo-1, epoch=152, train loss <loss>=1.05721882582\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:05 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:06 INFO 140166612858688] Epoch[153] Batch[0] avg_epoch_loss=1.081043\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:06 INFO 140166612858688] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=1.08104276657\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:08 INFO 140166612858688] Epoch[153] Batch[5] avg_epoch_loss=1.098244\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:08 INFO 140166612858688] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=1.09824419022\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:08 INFO 140166612858688] Epoch[153] Batch [5]#011Speed: 185.79 samples/sec#011loss=1.098244\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:09 INFO 140166612858688] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3927.051067352295, \"sum\": 3927.051067352295, \"min\": 3927.051067352295}}, \"EndTime\": 1597991289.791109, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991285.86353}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:09 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=158.383405609 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:09 INFO 140166612858688] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:09 INFO 140166612858688] #quality_metric: host=algo-1, epoch=153, train loss <loss>=1.07801043391\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:09 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:10 INFO 140166612858688] Epoch[154] Batch[0] avg_epoch_loss=1.031349\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:10 INFO 140166612858688] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=1.03134858608\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:12 INFO 140166612858688] Epoch[154] Batch[5] avg_epoch_loss=1.060532\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:12 INFO 140166612858688] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=1.06053169568\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:12 INFO 140166612858688] Epoch[154] Batch [5]#011Speed: 190.24 samples/sec#011loss=1.060532\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:13 INFO 140166612858688] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3819.5409774780273, \"sum\": 3819.5409774780273, \"min\": 3819.5409774780273}}, \"EndTime\": 1597991293.611243, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991289.791195}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:13 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=164.673913262 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:13 INFO 140166612858688] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:13 INFO 140166612858688] #quality_metric: host=algo-1, epoch=154, train loss <loss>=1.08516005874\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:13 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:14 INFO 140166612858688] Epoch[155] Batch[0] avg_epoch_loss=0.967040\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:14 INFO 140166612858688] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=0.96704018116\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:16 INFO 140166612858688] Epoch[155] Batch[5] avg_epoch_loss=1.046899\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:16 INFO 140166612858688] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=1.04689905047\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:16 INFO 140166612858688] Epoch[155] Batch [5]#011Speed: 188.83 samples/sec#011loss=1.046899\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:17 INFO 140166612858688] Epoch[155] Batch[10] avg_epoch_loss=1.058277\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:17 INFO 140166612858688] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=1.07193155289\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:17 INFO 140166612858688] Epoch[155] Batch [10]#011Speed: 187.28 samples/sec#011loss=1.071932\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:17 INFO 140166612858688] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4238.216161727905, \"sum\": 4238.216161727905, \"min\": 4238.216161727905}}, \"EndTime\": 1597991297.850034, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991293.611331}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:17 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=151.474401535 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:17 INFO 140166612858688] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:17 INFO 140166612858688] #quality_metric: host=algo-1, epoch=155, train loss <loss>=1.05827746066\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:17 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:18 INFO 140166612858688] Epoch[156] Batch[0] avg_epoch_loss=1.102432\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:18 INFO 140166612858688] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=1.10243165493\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:20 INFO 140166612858688] Epoch[156] Batch[5] avg_epoch_loss=1.073019\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:20 INFO 140166612858688] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=1.07301861048\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:20 INFO 140166612858688] Epoch[156] Batch [5]#011Speed: 190.05 samples/sec#011loss=1.073019\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:22 INFO 140166612858688] Epoch[156] Batch[10] avg_epoch_loss=1.122403\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:22 INFO 140166612858688] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=1.18166432381\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:22 INFO 140166612858688] Epoch[156] Batch [10]#011Speed: 189.40 samples/sec#011loss=1.181664\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:22 INFO 140166612858688] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4205.068826675415, \"sum\": 4205.068826675415, \"min\": 4205.068826675415}}, \"EndTime\": 1597991302.055627, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991297.850118}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:22 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=156.948870752 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:22 INFO 140166612858688] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:22 INFO 140166612858688] #quality_metric: host=algo-1, epoch=156, train loss <loss>=1.12240302563\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:22 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:22 INFO 140166612858688] Epoch[157] Batch[0] avg_epoch_loss=0.750973\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:22 INFO 140166612858688] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=0.750973403454\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:24 INFO 140166612858688] Epoch[157] Batch[5] avg_epoch_loss=1.000956\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:24 INFO 140166612858688] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=1.00095645587\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:24 INFO 140166612858688] Epoch[157] Batch [5]#011Speed: 189.70 samples/sec#011loss=1.000956\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:25 INFO 140166612858688] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3840.880870819092, \"sum\": 3840.880870819092, \"min\": 3840.880870819092}}, \"EndTime\": 1597991305.897031, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991302.055708}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:25 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=165.582564894 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:25 INFO 140166612858688] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:25 INFO 140166612858688] #quality_metric: host=algo-1, epoch=157, train loss <loss>=1.03059831858\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:25 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:26 INFO 140166612858688] Epoch[158] Batch[0] avg_epoch_loss=0.848092\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:26 INFO 140166612858688] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=0.848091542721\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:28 INFO 140166612858688] Epoch[158] Batch[5] avg_epoch_loss=0.973068\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:28 INFO 140166612858688] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=0.97306800882\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:28 INFO 140166612858688] Epoch[158] Batch [5]#011Speed: 187.89 samples/sec#011loss=0.973068\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:28:30 INFO 140166612858688] Epoch[158] Batch[10] avg_epoch_loss=1.013057\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:30 INFO 140166612858688] #quality_metric: host=algo-1, epoch=158, batch=10 train loss <loss>=1.06104383469\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:30 INFO 140166612858688] Epoch[158] Batch [10]#011Speed: 188.19 samples/sec#011loss=1.061044\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:30 INFO 140166612858688] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4185.3039264678955, \"sum\": 4185.3039264678955, \"min\": 4185.3039264678955}}, \"EndTime\": 1597991310.082925, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991305.897099}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:30 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=164.857808441 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:30 INFO 140166612858688] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:30 INFO 140166612858688] #quality_metric: host=algo-1, epoch=158, train loss <loss>=1.01305702058\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:30 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:30 INFO 140166612858688] Epoch[159] Batch[0] avg_epoch_loss=1.146390\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:30 INFO 140166612858688] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=1.14639019966\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:32 INFO 140166612858688] Epoch[159] Batch[5] avg_epoch_loss=1.088327\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:32 INFO 140166612858688] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=1.08832686146\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:32 INFO 140166612858688] Epoch[159] Batch [5]#011Speed: 189.82 samples/sec#011loss=1.088327\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:34 INFO 140166612858688] Epoch[159] Batch[10] avg_epoch_loss=1.017489\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:34 INFO 140166612858688] #quality_metric: host=algo-1, epoch=159, batch=10 train loss <loss>=0.932482743263\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:34 INFO 140166612858688] Epoch[159] Batch [10]#011Speed: 186.56 samples/sec#011loss=0.932483\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:34 INFO 140166612858688] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4182.971954345703, \"sum\": 4182.971954345703, \"min\": 4182.971954345703}}, \"EndTime\": 1597991314.266466, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991310.083002}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:34 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=160.885349081 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:34 INFO 140166612858688] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:34 INFO 140166612858688] #quality_metric: host=algo-1, epoch=159, train loss <loss>=1.01748862592\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:34 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:35 INFO 140166612858688] Epoch[160] Batch[0] avg_epoch_loss=1.194705\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:35 INFO 140166612858688] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=1.19470453262\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:36 INFO 140166612858688] Epoch[160] Batch[5] avg_epoch_loss=1.121437\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:36 INFO 140166612858688] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=1.1214367648\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:36 INFO 140166612858688] Epoch[160] Batch [5]#011Speed: 188.59 samples/sec#011loss=1.121437\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:38 INFO 140166612858688] Epoch[160] Batch[10] avg_epoch_loss=1.088461\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:38 INFO 140166612858688] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=1.04888951778\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:38 INFO 140166612858688] Epoch[160] Batch [10]#011Speed: 186.07 samples/sec#011loss=1.048890\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:38 INFO 140166612858688] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4182.873010635376, \"sum\": 4182.873010635376, \"min\": 4182.873010635376}}, \"EndTime\": 1597991318.449895, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991314.266553}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:38 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=153.956636504 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:38 INFO 140166612858688] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:38 INFO 140166612858688] #quality_metric: host=algo-1, epoch=160, train loss <loss>=1.08846074343\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:38 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:39 INFO 140166612858688] Epoch[161] Batch[0] avg_epoch_loss=1.223301\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:39 INFO 140166612858688] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=1.22330129147\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:40 INFO 140166612858688] Epoch[161] Batch[5] avg_epoch_loss=1.200018\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:40 INFO 140166612858688] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=1.20001834631\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:40 INFO 140166612858688] Epoch[161] Batch [5]#011Speed: 188.59 samples/sec#011loss=1.200018\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:42 INFO 140166612858688] Epoch[161] Batch[10] avg_epoch_loss=1.268727\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:42 INFO 140166612858688] #quality_metric: host=algo-1, epoch=161, batch=10 train loss <loss>=1.35117840767\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:42 INFO 140166612858688] Epoch[161] Batch [10]#011Speed: 187.19 samples/sec#011loss=1.351178\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:42 INFO 140166612858688] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4204.164028167725, \"sum\": 4204.164028167725, \"min\": 4204.164028167725}}, \"EndTime\": 1597991322.654628, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991318.449974}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:42 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=153.652799684 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:42 INFO 140166612858688] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:42 INFO 140166612858688] #quality_metric: host=algo-1, epoch=161, train loss <loss>=1.26872746511\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:42 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:43 INFO 140166612858688] Epoch[162] Batch[0] avg_epoch_loss=1.230127\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:43 INFO 140166612858688] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=1.23012721539\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:45 INFO 140166612858688] Epoch[162] Batch[5] avg_epoch_loss=1.138408\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:45 INFO 140166612858688] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=1.13840815425\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:45 INFO 140166612858688] Epoch[162] Batch [5]#011Speed: 192.22 samples/sec#011loss=1.138408\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:46 INFO 140166612858688] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3850.6929874420166, \"sum\": 3850.6929874420166, \"min\": 3850.6929874420166}}, \"EndTime\": 1597991326.505875, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991322.65471}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:46 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=158.667344745 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:46 INFO 140166612858688] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:46 INFO 140166612858688] #quality_metric: host=algo-1, epoch=162, train loss <loss>=1.06251408458\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:46 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:47 INFO 140166612858688] Epoch[163] Batch[0] avg_epoch_loss=1.150268\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:47 INFO 140166612858688] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=1.15026819706\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:49 INFO 140166612858688] Epoch[163] Batch[5] avg_epoch_loss=1.069825\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:49 INFO 140166612858688] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=1.06982516249\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:49 INFO 140166612858688] Epoch[163] Batch [5]#011Speed: 188.98 samples/sec#011loss=1.069825\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:50 INFO 140166612858688] Epoch[163] Batch[10] avg_epoch_loss=1.057804\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:50 INFO 140166612858688] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=1.04337879419\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:50 INFO 140166612858688] Epoch[163] Batch [10]#011Speed: 190.47 samples/sec#011loss=1.043379\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:50 INFO 140166612858688] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4207.069873809814, \"sum\": 4207.069873809814, \"min\": 4207.069873809814}}, \"EndTime\": 1597991330.713512, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991326.505964}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:50 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=159.96416869 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:50 INFO 140166612858688] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:50 INFO 140166612858688] #quality_metric: host=algo-1, epoch=163, train loss <loss>=1.05780408599\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:50 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:51 INFO 140166612858688] Epoch[164] Batch[0] avg_epoch_loss=1.068458\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:51 INFO 140166612858688] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=1.06845831871\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:53 INFO 140166612858688] Epoch[164] Batch[5] avg_epoch_loss=1.086743\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:53 INFO 140166612858688] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=1.08674281836\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:53 INFO 140166612858688] Epoch[164] Batch [5]#011Speed: 189.28 samples/sec#011loss=1.086743\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:54 INFO 140166612858688] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3811.5320205688477, \"sum\": 3811.5320205688477, \"min\": 3811.5320205688477}}, \"EndTime\": 1597991334.525607, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991330.713594}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:54 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=164.495174754 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:54 INFO 140166612858688] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:54 INFO 140166612858688] #quality_metric: host=algo-1, epoch=164, train loss <loss>=1.11432294846\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:54 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:55 INFO 140166612858688] Epoch[165] Batch[0] avg_epoch_loss=1.153615\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:55 INFO 140166612858688] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=1.15361464024\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:28:57 INFO 140166612858688] Epoch[165] Batch[5] avg_epoch_loss=1.088238\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:57 INFO 140166612858688] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=1.08823820949\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:57 INFO 140166612858688] Epoch[165] Batch [5]#011Speed: 190.42 samples/sec#011loss=1.088238\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:58 INFO 140166612858688] Epoch[165] Batch[10] avg_epoch_loss=1.045891\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:58 INFO 140166612858688] #quality_metric: host=algo-1, epoch=165, batch=10 train loss <loss>=0.995073974133\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:58 INFO 140166612858688] Epoch[165] Batch [10]#011Speed: 188.61 samples/sec#011loss=0.995074\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:58 INFO 140166612858688] processed a total of 689 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4180.012941360474, \"sum\": 4180.012941360474, \"min\": 4180.012941360474}}, \"EndTime\": 1597991338.706204, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991334.525696}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:58 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=164.827212058 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:58 INFO 140166612858688] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:58 INFO 140166612858688] #quality_metric: host=algo-1, epoch=165, train loss <loss>=1.04589082978\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:58 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:59 INFO 140166612858688] Epoch[166] Batch[0] avg_epoch_loss=1.176995\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:28:59 INFO 140166612858688] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=1.17699480057\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:01 INFO 140166612858688] Epoch[166] Batch[5] avg_epoch_loss=1.037907\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:01 INFO 140166612858688] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=1.03790699442\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:01 INFO 140166612858688] Epoch[166] Batch [5]#011Speed: 188.49 samples/sec#011loss=1.037907\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:02 INFO 140166612858688] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3936.7239475250244, \"sum\": 3936.7239475250244, \"min\": 3936.7239475250244}}, \"EndTime\": 1597991342.643453, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991338.706285}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:02 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=157.487323343 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:02 INFO 140166612858688] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:02 INFO 140166612858688] #quality_metric: host=algo-1, epoch=166, train loss <loss>=1.05852965117\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:02 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:03 INFO 140166612858688] Epoch[167] Batch[0] avg_epoch_loss=0.917990\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:03 INFO 140166612858688] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=0.917990028858\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:05 INFO 140166612858688] Epoch[167] Batch[5] avg_epoch_loss=0.976242\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:05 INFO 140166612858688] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=0.976242154837\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:05 INFO 140166612858688] Epoch[167] Batch [5]#011Speed: 187.33 samples/sec#011loss=0.976242\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:06 INFO 140166612858688] Epoch[167] Batch[10] avg_epoch_loss=1.139707\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:06 INFO 140166612858688] #quality_metric: host=algo-1, epoch=167, batch=10 train loss <loss>=1.33586506844\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:06 INFO 140166612858688] Epoch[167] Batch [10]#011Speed: 187.30 samples/sec#011loss=1.335865\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:06 INFO 140166612858688] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4215.18611907959, \"sum\": 4215.18611907959, \"min\": 4215.18611907959}}, \"EndTime\": 1597991346.859209, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991342.643519}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:06 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=156.572261461 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:06 INFO 140166612858688] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:06 INFO 140166612858688] #quality_metric: host=algo-1, epoch=167, train loss <loss>=1.13970711556\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:06 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:07 INFO 140166612858688] Epoch[168] Batch[0] avg_epoch_loss=0.969221\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:07 INFO 140166612858688] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=0.969220638275\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:09 INFO 140166612858688] Epoch[168] Batch[5] avg_epoch_loss=0.991981\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:09 INFO 140166612858688] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=0.991980771224\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:09 INFO 140166612858688] Epoch[168] Batch [5]#011Speed: 186.71 samples/sec#011loss=0.991981\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:10 INFO 140166612858688] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3877.9261112213135, \"sum\": 3877.9261112213135, \"min\": 3877.9261112213135}}, \"EndTime\": 1597991350.737673, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991346.85929}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:10 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=159.873216328 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:10 INFO 140166612858688] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:10 INFO 140166612858688] #quality_metric: host=algo-1, epoch=168, train loss <loss>=0.981033420563\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:10 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:11 INFO 140166612858688] Epoch[169] Batch[0] avg_epoch_loss=1.093538\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:11 INFO 140166612858688] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=1.09353840351\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:13 INFO 140166612858688] Epoch[169] Batch[5] avg_epoch_loss=1.094966\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:13 INFO 140166612858688] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=1.09496631225\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:13 INFO 140166612858688] Epoch[169] Batch [5]#011Speed: 190.99 samples/sec#011loss=1.094966\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:14 INFO 140166612858688] Epoch[169] Batch[10] avg_epoch_loss=1.123488\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:14 INFO 140166612858688] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=1.15771443844\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:14 INFO 140166612858688] Epoch[169] Batch [10]#011Speed: 190.28 samples/sec#011loss=1.157714\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:14 INFO 140166612858688] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4132.684946060181, \"sum\": 4132.684946060181, \"min\": 4132.684946060181}}, \"EndTime\": 1597991354.870936, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991350.737764}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:14 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=155.826257757 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:14 INFO 140166612858688] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:14 INFO 140166612858688] #quality_metric: host=algo-1, epoch=169, train loss <loss>=1.12348818779\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:14 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:15 INFO 140166612858688] Epoch[170] Batch[0] avg_epoch_loss=1.049069\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:15 INFO 140166612858688] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=1.04906916618\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:17 INFO 140166612858688] Epoch[170] Batch[5] avg_epoch_loss=1.035137\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:17 INFO 140166612858688] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=1.03513700763\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:17 INFO 140166612858688] Epoch[170] Batch [5]#011Speed: 188.52 samples/sec#011loss=1.035137\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:29:19 INFO 140166612858688] Epoch[170] Batch[10] avg_epoch_loss=0.974952\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:19 INFO 140166612858688] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=0.902729952335\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:19 INFO 140166612858688] Epoch[170] Batch [10]#011Speed: 187.57 samples/sec#011loss=0.902730\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:19 INFO 140166612858688] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4213.983058929443, \"sum\": 4213.983058929443, \"min\": 4213.983058929443}}, \"EndTime\": 1597991359.085469, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991354.871018}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:19 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=152.34562321 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:19 INFO 140166612858688] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:19 INFO 140166612858688] #quality_metric: host=algo-1, epoch=170, train loss <loss>=0.974951982498\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:19 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:19 INFO 140166612858688] Epoch[171] Batch[0] avg_epoch_loss=1.218612\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:19 INFO 140166612858688] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=1.21861219406\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:21 INFO 140166612858688] Epoch[171] Batch[5] avg_epoch_loss=1.068613\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:21 INFO 140166612858688] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=1.06861293316\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:21 INFO 140166612858688] Epoch[171] Batch [5]#011Speed: 190.14 samples/sec#011loss=1.068613\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:23 INFO 140166612858688] Epoch[171] Batch[10] avg_epoch_loss=1.131911\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:23 INFO 140166612858688] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=1.2078690052\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:23 INFO 140166612858688] Epoch[171] Batch [10]#011Speed: 187.64 samples/sec#011loss=1.207869\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:23 INFO 140166612858688] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4162.468910217285, \"sum\": 4162.468910217285, \"min\": 4162.468910217285}}, \"EndTime\": 1597991363.248523, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991359.085547}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:23 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=160.236389161 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:23 INFO 140166612858688] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:23 INFO 140166612858688] #quality_metric: host=algo-1, epoch=171, train loss <loss>=1.13191114772\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:23 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:24 INFO 140166612858688] Epoch[172] Batch[0] avg_epoch_loss=1.075513\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:24 INFO 140166612858688] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=1.07551276684\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:25 INFO 140166612858688] Epoch[172] Batch[5] avg_epoch_loss=1.045864\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:25 INFO 140166612858688] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=1.04586430391\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:25 INFO 140166612858688] Epoch[172] Batch [5]#011Speed: 189.47 samples/sec#011loss=1.045864\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:27 INFO 140166612858688] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3793.4741973876953, \"sum\": 3793.4741973876953, \"min\": 3793.4741973876953}}, \"EndTime\": 1597991367.042561, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991363.248608}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:27 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=166.859761335 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:27 INFO 140166612858688] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:27 INFO 140166612858688] #quality_metric: host=algo-1, epoch=172, train loss <loss>=1.0714127183\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:27 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:27 INFO 140166612858688] Epoch[173] Batch[0] avg_epoch_loss=0.923950\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:27 INFO 140166612858688] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=0.923949599266\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:29 INFO 140166612858688] Epoch[173] Batch[5] avg_epoch_loss=1.003964\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:29 INFO 140166612858688] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=1.0039635698\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:29 INFO 140166612858688] Epoch[173] Batch [5]#011Speed: 187.46 samples/sec#011loss=1.003964\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:30 INFO 140166612858688] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3868.802070617676, \"sum\": 3868.802070617676, \"min\": 3868.802070617676}}, \"EndTime\": 1597991370.911947, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991367.04265}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:30 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=162.059058663 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:30 INFO 140166612858688] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:30 INFO 140166612858688] #quality_metric: host=algo-1, epoch=173, train loss <loss>=0.992218381166\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:30 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:31 INFO 140166612858688] Epoch[174] Batch[0] avg_epoch_loss=0.897720\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:31 INFO 140166612858688] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=0.897720396519\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:33 INFO 140166612858688] Epoch[174] Batch[5] avg_epoch_loss=1.065995\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:33 INFO 140166612858688] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=1.06599510709\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:33 INFO 140166612858688] Epoch[174] Batch [5]#011Speed: 188.95 samples/sec#011loss=1.065995\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:35 INFO 140166612858688] Epoch[174] Batch[10] avg_epoch_loss=1.062149\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:35 INFO 140166612858688] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=1.05753269196\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:35 INFO 140166612858688] Epoch[174] Batch [10]#011Speed: 190.62 samples/sec#011loss=1.057533\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:35 INFO 140166612858688] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4137.333154678345, \"sum\": 4137.333154678345, \"min\": 4137.333154678345}}, \"EndTime\": 1597991375.049983, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991370.91206}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:35 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=155.892898756 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:35 INFO 140166612858688] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:35 INFO 140166612858688] #quality_metric: host=algo-1, epoch=174, train loss <loss>=1.06214855476\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:35 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:35 INFO 140166612858688] Epoch[175] Batch[0] avg_epoch_loss=0.968935\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:35 INFO 140166612858688] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=0.968935132027\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:37 INFO 140166612858688] Epoch[175] Batch[5] avg_epoch_loss=1.112416\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:37 INFO 140166612858688] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=1.11241590977\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:37 INFO 140166612858688] Epoch[175] Batch [5]#011Speed: 191.46 samples/sec#011loss=1.112416\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:39 INFO 140166612858688] Epoch[175] Batch[10] avg_epoch_loss=1.171183\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:39 INFO 140166612858688] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=1.24170325994\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:39 INFO 140166612858688] Epoch[175] Batch [10]#011Speed: 184.34 samples/sec#011loss=1.241703\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:39 INFO 140166612858688] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4198.542833328247, \"sum\": 4198.542833328247, \"min\": 4198.542833328247}}, \"EndTime\": 1597991379.24906, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991375.050066}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:39 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=158.383716326 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:39 INFO 140166612858688] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:39 INFO 140166612858688] #quality_metric: host=algo-1, epoch=175, train loss <loss>=1.17118288712\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:39 INFO 140166612858688] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:29:40 INFO 140166612858688] Epoch[176] Batch[0] avg_epoch_loss=1.055267\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:40 INFO 140166612858688] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=1.05526697636\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:41 INFO 140166612858688] Epoch[176] Batch[5] avg_epoch_loss=1.072375\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:41 INFO 140166612858688] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=1.07237535715\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:41 INFO 140166612858688] Epoch[176] Batch [5]#011Speed: 188.36 samples/sec#011loss=1.072375\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:43 INFO 140166612858688] Epoch[176] Batch[10] avg_epoch_loss=1.099957\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:43 INFO 140166612858688] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=1.1330553174\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:43 INFO 140166612858688] Epoch[176] Batch [10]#011Speed: 188.03 samples/sec#011loss=1.133055\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:43 INFO 140166612858688] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4228.806018829346, \"sum\": 4228.806018829346, \"min\": 4228.806018829346}}, \"EndTime\": 1597991383.478403, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991379.249142}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:43 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=152.284418461 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:43 INFO 140166612858688] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:43 INFO 140166612858688] #quality_metric: host=algo-1, epoch=176, train loss <loss>=1.09995715727\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:43 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:44 INFO 140166612858688] Epoch[177] Batch[0] avg_epoch_loss=1.072908\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:44 INFO 140166612858688] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=1.07290780544\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:45 INFO 140166612858688] Epoch[177] Batch[5] avg_epoch_loss=1.049413\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:45 INFO 140166612858688] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=1.04941289624\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:45 INFO 140166612858688] Epoch[177] Batch [5]#011Speed: 191.90 samples/sec#011loss=1.049413\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:47 INFO 140166612858688] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3800.706148147583, \"sum\": 3800.706148147583, \"min\": 3800.706148147583}}, \"EndTime\": 1597991387.279643, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991383.478486}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:47 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=168.384099389 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:47 INFO 140166612858688] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:47 INFO 140166612858688] #quality_metric: host=algo-1, epoch=177, train loss <loss>=1.04467567801\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:47 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:48 INFO 140166612858688] Epoch[178] Batch[0] avg_epoch_loss=1.066288\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:48 INFO 140166612858688] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=1.06628787518\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:49 INFO 140166612858688] Epoch[178] Batch[5] avg_epoch_loss=1.009596\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:49 INFO 140166612858688] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=1.00959587097\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:49 INFO 140166612858688] Epoch[178] Batch [5]#011Speed: 184.69 samples/sec#011loss=1.009596\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:51 INFO 140166612858688] Epoch[178] Batch[10] avg_epoch_loss=1.026182\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:51 INFO 140166612858688] #quality_metric: host=algo-1, epoch=178, batch=10 train loss <loss>=1.04608598948\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:51 INFO 140166612858688] Epoch[178] Batch [10]#011Speed: 189.84 samples/sec#011loss=1.046086\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:51 INFO 140166612858688] processed a total of 687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4212.483882904053, \"sum\": 4212.483882904053, \"min\": 4212.483882904053}}, \"EndTime\": 1597991391.492739, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991387.27973}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:51 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=163.081988479 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:51 INFO 140166612858688] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:51 INFO 140166612858688] #quality_metric: host=algo-1, epoch=178, train loss <loss>=1.02618228847\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:51 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:52 INFO 140166612858688] Epoch[179] Batch[0] avg_epoch_loss=1.168568\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:52 INFO 140166612858688] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=1.16856777668\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:53 INFO 140166612858688] Epoch[179] Batch[5] avg_epoch_loss=1.060515\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:53 INFO 140166612858688] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=1.06051472823\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:53 INFO 140166612858688] Epoch[179] Batch [5]#011Speed: 190.71 samples/sec#011loss=1.060515\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:55 INFO 140166612858688] processed a total of 600 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3793.4181690216064, \"sum\": 3793.4181690216064, \"min\": 3793.4181690216064}}, \"EndTime\": 1597991395.28669, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991391.492821}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:55 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=158.163366441 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:55 INFO 140166612858688] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:55 INFO 140166612858688] #quality_metric: host=algo-1, epoch=179, train loss <loss>=0.955934481323\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:55 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:56 INFO 140166612858688] Epoch[180] Batch[0] avg_epoch_loss=0.854343\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:56 INFO 140166612858688] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=0.854342639446\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:57 INFO 140166612858688] Epoch[180] Batch[5] avg_epoch_loss=1.054073\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:57 INFO 140166612858688] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=1.05407297611\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:57 INFO 140166612858688] Epoch[180] Batch [5]#011Speed: 191.52 samples/sec#011loss=1.054073\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:59 INFO 140166612858688] Epoch[180] Batch[10] avg_epoch_loss=0.986102\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:59 INFO 140166612858688] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=0.904536259174\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:59 INFO 140166612858688] Epoch[180] Batch [10]#011Speed: 189.31 samples/sec#011loss=0.904536\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:59 INFO 140166612858688] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4187.92986869812, \"sum\": 4187.92986869812, \"min\": 4187.92986869812}}, \"EndTime\": 1597991399.475201, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991395.286778}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:59 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=154.248281905 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:59 INFO 140166612858688] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:59 INFO 140166612858688] #quality_metric: host=algo-1, epoch=180, train loss <loss>=0.986101741141\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:29:59 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:00 INFO 140166612858688] Epoch[181] Batch[0] avg_epoch_loss=1.171377\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:00 INFO 140166612858688] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=1.17137670517\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:01 INFO 140166612858688] Epoch[181] Batch[5] avg_epoch_loss=0.995629\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:01 INFO 140166612858688] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=0.99562934041\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:01 INFO 140166612858688] Epoch[181] Batch [5]#011Speed: 190.38 samples/sec#011loss=0.995629\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:03 INFO 140166612858688] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3862.1318340301514, \"sum\": 3862.1318340301514, \"min\": 3862.1318340301514}}, \"EndTime\": 1597991403.337886, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991399.475283}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:03 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=157.679579469 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:03 INFO 140166612858688] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:03 INFO 140166612858688] #quality_metric: host=algo-1, epoch=181, train loss <loss>=1.04700097442\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:03 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:04 INFO 140166612858688] Epoch[182] Batch[0] avg_epoch_loss=1.172139\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:04 INFO 140166612858688] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=1.17213869095\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:05 INFO 140166612858688] Epoch[182] Batch[5] avg_epoch_loss=1.194616\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:05 INFO 140166612858688] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=1.1946156621\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:05 INFO 140166612858688] Epoch[182] Batch [5]#011Speed: 192.35 samples/sec#011loss=1.194616\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/21/2020 06:30:07 INFO 140166612858688] Epoch[182] Batch[10] avg_epoch_loss=1.190167\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:07 INFO 140166612858688] #quality_metric: host=algo-1, epoch=182, batch=10 train loss <loss>=1.18482872248\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:07 INFO 140166612858688] Epoch[182] Batch [10]#011Speed: 189.73 samples/sec#011loss=1.184829\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:07 INFO 140166612858688] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4162.524938583374, \"sum\": 4162.524938583374, \"min\": 4162.524938583374}}, \"EndTime\": 1597991407.5011, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991403.337976}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:07 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=157.591995744 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:07 INFO 140166612858688] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:07 INFO 140166612858688] #quality_metric: host=algo-1, epoch=182, train loss <loss>=1.19016705318\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:07 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:08 INFO 140166612858688] Epoch[183] Batch[0] avg_epoch_loss=1.191986\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:08 INFO 140166612858688] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=1.19198644161\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:10 INFO 140166612858688] Epoch[183] Batch[5] avg_epoch_loss=1.110027\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:10 INFO 140166612858688] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=1.11002725363\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:10 INFO 140166612858688] Epoch[183] Batch [5]#011Speed: 185.91 samples/sec#011loss=1.110027\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:11 INFO 140166612858688] Epoch[183] Batch[10] avg_epoch_loss=1.084963\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:11 INFO 140166612858688] #quality_metric: host=algo-1, epoch=183, batch=10 train loss <loss>=1.05488687754\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:11 INFO 140166612858688] Epoch[183] Batch [10]#011Speed: 188.10 samples/sec#011loss=1.054887\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:11 INFO 140166612858688] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4221.74596786499, \"sum\": 4221.74596786499, \"min\": 4221.74596786499}}, \"EndTime\": 1597991411.723384, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991407.501182}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:11 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=156.328788465 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:11 INFO 140166612858688] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:11 INFO 140166612858688] #quality_metric: host=algo-1, epoch=183, train loss <loss>=1.08496344631\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:11 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:12 INFO 140166612858688] Epoch[184] Batch[0] avg_epoch_loss=1.158506\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:12 INFO 140166612858688] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=1.15850627422\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:14 INFO 140166612858688] Epoch[184] Batch[5] avg_epoch_loss=1.159310\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:14 INFO 140166612858688] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=1.15930960576\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:14 INFO 140166612858688] Epoch[184] Batch [5]#011Speed: 188.91 samples/sec#011loss=1.159310\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:15 INFO 140166612858688] Epoch[184] Batch[10] avg_epoch_loss=1.153370\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:15 INFO 140166612858688] #quality_metric: host=algo-1, epoch=184, batch=10 train loss <loss>=1.1462418437\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:15 INFO 140166612858688] Epoch[184] Batch [10]#011Speed: 191.40 samples/sec#011loss=1.146242\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:15 INFO 140166612858688] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4161.254167556763, \"sum\": 4161.254167556763, \"min\": 4161.254167556763}}, \"EndTime\": 1597991415.885194, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991411.723468}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:15 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=164.849281314 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:15 INFO 140166612858688] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:15 INFO 140166612858688] #quality_metric: host=algo-1, epoch=184, train loss <loss>=1.15336971391\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:15 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:16 INFO 140166612858688] Epoch[185] Batch[0] avg_epoch_loss=0.997323\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:16 INFO 140166612858688] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=0.997323215008\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:18 INFO 140166612858688] Epoch[185] Batch[5] avg_epoch_loss=1.077791\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:18 INFO 140166612858688] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=1.07779093583\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:18 INFO 140166612858688] Epoch[185] Batch [5]#011Speed: 191.70 samples/sec#011loss=1.077791\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:19 INFO 140166612858688] processed a total of 581 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3805.2260875701904, \"sum\": 3805.2260875701904, \"min\": 3805.2260875701904}}, \"EndTime\": 1597991419.690943, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991415.885278}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:19 INFO 140166612858688] #throughput_metric: host=algo-1, train throughput=152.679461492 records/second\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:19 INFO 140166612858688] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:19 INFO 140166612858688] #quality_metric: host=algo-1, epoch=185, train loss <loss>=1.13121818304\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:19 INFO 140166612858688] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:19 INFO 140166612858688] Loading parameters from best epoch (145)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 61.79690361022949, \"sum\": 61.79690361022949, \"min\": 61.79690361022949}}, \"EndTime\": 1597991419.753388, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991419.691034}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:19 INFO 140166612858688] stopping training now\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:19 INFO 140166612858688] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:19 INFO 140166612858688] Final loss: 0.942659899 (occurred at epoch 145)\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:19 INFO 140166612858688] #quality_metric: host=algo-1, train final_loss <loss>=0.942659899\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:19 WARNING 140166612858688] You are using large values for `context_length` and/or `prediction_length`. The following step may take some time. If the step crashes, use an instance with more memory or reduce these two parameters.\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:19 INFO 140166612858688] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:19 WARNING 140166612858688] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:19 INFO 140166612858688] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 3044.335126876831, \"sum\": 3044.335126876831, \"min\": 3044.335126876831}}, \"EndTime\": 1597991422.79874, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991419.753457}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:23 INFO 140166612858688] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 3560.4920387268066, \"sum\": 3560.4920387268066, \"min\": 3560.4920387268066}}, \"EndTime\": 1597991423.314847, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991422.798854}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:23 INFO 140166612858688] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:23 INFO 140166612858688] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 75.38509368896484, \"sum\": 75.38509368896484, \"min\": 75.38509368896484}}, \"EndTime\": 1597991423.390338, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991423.314907}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:23 INFO 140166612858688] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[08/21/2020 06:30:23 INFO 140166612858688] No test data passed, skipping evaluation.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 759061.0659122467, \"sum\": 759061.0659122467, \"min\": 759061.0659122467}, \"setuptime\": {\"count\": 1, \"max\": 8.533954620361328, \"sum\": 8.533954620361328, \"min\": 8.533954620361328}}, \"EndTime\": 1597991423.526451, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597991423.390397}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-08-21 06:30:40 Uploading - Uploading generated training model\n",
      "2020-08-21 06:30:40 Completed - Training job completed\n",
      "Training seconds: 818\n",
      "Billable seconds: 818\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session.logs_for_job(estimator.latest_training_job.name, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Predicting the Model\n",
    "\n",
    "After that we have trained a model, we can use it to perform predictions by deploying the model. To detect anomaly, we can define the following utility class: this allows to return a dcitionary encoding for requests using pandas.Series objects rather than raw JSON strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepARPredictor(sagemaker.predictor.RealTimePredictor):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, content_type=sagemaker.content_types.CONTENT_TYPE_JSON, **kwargs)\n",
    "        \n",
    "    def predict(self, ts, cat=None, dynamic_feat=None, \n",
    "                num_samples=100, return_samples=False, quantiles=[\"0.1\", \"0.5\", \"0.9\"]):\n",
    "        \"\"\"Requests the prediction of for the time series listed in `ts`, each with the (optional)\n",
    "        corresponding category listed in `cat`.\n",
    "        \n",
    "        ts -- `pandas.Series` object, the time series to predict\n",
    "        cat -- integer, the group associated to the time series (default: None)\n",
    "        num_samples -- integer, number of samples to compute at prediction time (default: 100)\n",
    "        return_samples -- boolean indicating whether to include samples in the response (default: False)\n",
    "        quantiles -- list of strings specifying the quantiles to compute (default: [\"0.1\", \"0.5\", \"0.9\"])\n",
    "        \n",
    "        Return value: list of `pandas.DataFrame` objects, each containing the predictions\n",
    "        \"\"\"\n",
    "        prediction_time = ts.index[-1] + datetime.timedelta(minutes=10)\n",
    "#         prediction_time = 144\n",
    "        quantiles = [str(q) for q in quantiles]\n",
    "        req = self.__encode_request(ts, cat, dynamic_feat, num_samples, return_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req)\n",
    "        return self.__decode_response(res, ts.index.freq, prediction_time, return_samples)\n",
    "    \n",
    "    def __encode_request(self, ts, cat, dynamic_feat, num_samples, return_samples, quantiles):\n",
    "        instance = series_to_dict(ts, cat if cat is not None else None, dynamic_feat if dynamic_feat else None)\n",
    "\n",
    "        configuration = {\n",
    "            \"num_samples\": num_samples,\n",
    "            \"output_types\": [\"quantiles\", \"samples\"] if return_samples else [\"quantiles\"],\n",
    "            \"quantiles\": quantiles\n",
    "        }\n",
    "        \n",
    "        http_request_data = {\n",
    "            \"instances\": [instance],\n",
    "            \"configuration\": configuration\n",
    "        }\n",
    "        \n",
    "        return json.dumps(http_request_data).encode('utf-8')\n",
    "    \n",
    "    def __decode_response(self, response, freq, prediction_time, return_samples):\n",
    "        # we only sent one time series so we only receive one in return\n",
    "        # however, if possible one will pass multiple time series as predictions will then be faster\n",
    "        predictions = json.loads(response.decode('utf-8'))['predictions'][0]\n",
    "        prediction_length = len(next(iter(predictions['quantiles'].values())))\n",
    "        \n",
    "        prediction_index = pd.date_range(prediction_time, prediction_time + freq * (prediction_length-1), freq=freq)\n",
    "        \n",
    "        if return_samples:\n",
    "            dict_of_samples = {'sample_' + str(i): s for i, s in enumerate(predictions['samples'])}\n",
    "        else:\n",
    "            dict_of_samples = {}\n",
    "        return pd.DataFrame(data={**predictions['quantiles'], **dict_of_samples}, index=prediction_index)\n",
    "\n",
    "    def set_frequency(self, freq):\n",
    "        self.freq = freq\n",
    "        \n",
    "def encode_target(ts):\n",
    "    return [x if np.isfinite(x) else \"NaN\" for x in ts]        \n",
    "\n",
    "def series_to_dict(ts, cat=None, dynamic_feat=None):\n",
    "    \"\"\"Given a pandas.Series object, returns a dictionary encoding the time series.\n",
    "\n",
    "    ts -- a pands.Series object with the target time series\n",
    "    cat -- an integer indicating the time series category\n",
    "\n",
    "    Return value: a dictionary\n",
    "    \"\"\"\n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": encode_target(ts)}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    if dynamic_feat is not None:\n",
    "        obj[\"dynamic_feat\"] = dynamic_feat        \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you train your model, you can deploy it to get predictions. Now is the time to pull down the deployed model, and detect include when website activity uncharactersitically spike to the actual historical values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "# predictor.delete_endpoint()\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    predictor_cls=DeepARPredictor, \n",
    "    wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pass the training dataset formatted CSV format, to the inference endpoint so we can automatically detect the anomalies we saw with our eyes in the plots, above. Note that the serializer and deserializer will automatically take care of the datatype conversion from Numpy NDArrays.\n",
    "\n",
    "For starters, let's only pass in the first six datapoints so we can see what the output looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-01 00:00:00    24.0\n",
       "2012-03-01 00:10:00    22.0\n",
       "2012-03-01 00:20:00    20.0\n",
       "2012-03-01 00:30:00    17.0\n",
       "2012-03-01 00:40:00    15.0\n",
       "                       ... \n",
       "2012-03-14 23:10:00    60.0\n",
       "2012-03-14 23:20:00    60.0\n",
       "2012-03-14 23:30:00    38.0\n",
       "2012-03-14 23:40:00    36.0\n",
       "2012-03-14 23:50:00    29.0\n",
       "Freq: 10T, Length: 2016, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.Series(training_data[0]['target'][:-144])\n",
    "test_data.index=pd.date_range(training_data[0]['start'], \n",
    "                              datetime.datetime.strptime(training_data[0]['start'],'%Y-%m-%d %H:%M:%S')+datetime.timedelta(minutes=10*2015), \n",
    "                              freq='10T')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predictor.predict(ts=test_data, \n",
    "                               dynamic_feat=training_data[0]['dynamic_feat'],\n",
    "                               quantiles=[0.10, 0.5, 0.90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-01 00:00:00    24.0\n",
       "2012-03-01 00:10:00    22.0\n",
       "2012-03-01 00:20:00    20.0\n",
       "2012-03-01 00:30:00    17.0\n",
       "2012-03-01 00:40:00    15.0\n",
       "                       ... \n",
       "2012-03-15 23:10:00    68.0\n",
       "2012-03-15 23:20:00    70.0\n",
       "2012-03-15 23:30:00    50.0\n",
       "2012-03-15 23:40:00    45.0\n",
       "2012-03-15 23:50:00    37.0\n",
       "Freq: 10T, Length: 2160, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.Series(training_data[0]['target'])\n",
    "full_data.index=pd.date_range(training_data[0]['start'], \n",
    "                              datetime.datetime.strptime(training_data[0]['start'],'%Y-%m-%d %H:%M:%S')+datetime.timedelta(minutes=10*2159), \n",
    "                              freq='10T')\n",
    "full_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Plotting the Prediction\n",
    "\n",
    "Now we can use the previously created predictor object. For simplicity, we will predict data after March 15, 2012 00:00 used for training, and compare the results with the original training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIQAAAEvCAYAAAA0MRq8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd3xcd53v/9eZXiSNqq1mFfdux3biFEhCAoQNSUgIWQKhJLAE9sLehb3L7kIou1zCsndh+W1gF3CWkACGNNIJJKQ61Y4dt9iSm3qzNOrSaPr5/TEqljUqtiXL9ryfj4cftr/nzJnvOIo08zmfYpimiYiIiIiIiIiIpA7LbG9AREREREREREROLwWERERERERERERSjAJCIiIiIiIiIiIpRgEhEREREREREZEUo4CQiIiIiIiIiEiKUUBIRERERERERCTF2GZ7AwC5ublmWVnZbG9DREREREREROScsWPHDr9pmnnJjp0RAaGysjK2b98+29sQERERERERETlnGIZRO94xlYyJiIiIiIiIiKQYBYRERERERERERFKMAkIiIiIiIiIiIilGASERERERERERkRSjgJCIiIiIiIiISIpRQEhEREREREREJMUoICQiIiIiIiIikmIUEBIRERERERERSTEKCImIiIiIiIiIpBgFhEROk4FwjNeP+Gd7GyIiIiIiIiIKCImcLr9+s4aP372V2vb+2d6KiIiIiIiIpDgFhEROkx21nQC8WdU+yzsRERERERGRVKeAkMhpsqu+C4Ct1R2zvBMRERERERFJdQoIiZwGLd1BjvaEsFoMtlYpICQiIiIiIiKzSwEhSXmmafK1R/bw17/ZMWPPsas+US527eoCGrsGaOgMzNhziYiIiIiIiExGASFJeT967hC/21bP8xWtRGLxGXmOnfVdOKwWbr2kHIBtKhsTERERERGRWaSAkKS0R95u4K7nD1Ga4yEci1Ptn5kJYLvqulhWmMGqIh8ZLpsCQiIiIiIiIjKrFBCSlLW1qp1//P0eLpqfw08+tg6AiuaeaX+eWNxkb2M3a4t9WC0GF5Rnq7G0iIiIiIiIzCoFhCQlVfv7+fxvdlCS7eFnn1jPkvx07FaDypbeaX+uQ629BMIx1pZkAnBBeTbV/n5ae4LT/lwiIiIiIiIiU6GAkKSczv4wt/1yGxbD4Je3XoDPY8dhs7AgL43KGcgQ2lWXGDe/dl4WABvLcwCNnxcREREREZHZo4CQpJzvPV1BU3eQuz+1npIcz/D6soKMGckQ2t3Qhc9tp2zwuVYUZuB1WNVHSERERERERGaNAkKScg619rGxPJv1pdmj1pfmp9PcHaQrEJ7W59tZ18WaeZkYhgGAzWphfVk2W6vbp/V5RERERERERKZKASFJOf6+ELlpzjHrSwsyAKY1S6g/FOXg0V7Wzssctb6xPJuDR/vo6J/e4JOIiIiIiIjIVCggJCnFNM3BgJBjzLFl+ekA09pHaG9jN3ETzksSEAJUNiYiIiIiIiKzQgEhSSn94RjBSDxphlBeupNsr2NaM4R21ycaSq8u9o1aX1Xsw2mzqGxMREREREREZoUCQpJS/L0hgKQBIcMwWJqfTsU0BoR21XdRku0h57jnc9qsrCvJUoaQiIiIiIiIzAoFhCSl+PsGA0LpYwNCAEvzMzjY0kssbk7L8+2q7xrTP2jIBeXZ7G/uoXsgMi3PJSIiIiIiIjJVCghJShkOCCXpIQSwtCCdgUiMuo7AKT/X0Z4gzd1B1owTENo4PxvThB21yhISERERERGR00sBIUkpbX2JqV55SUrGAJblD04am4bG0rsG+weNlyG0riQLu9Vga5UCQiIiIiIiInJ6KSAkKcXfG8IwINubPENo0dw0LAZUTFNAyG41WFGYkfS4y25lTXEmW9VHSERERERk9mzeDGVlYLEkft+8ebZ3JHJaTBoQMgzjHsMwWg3DeOeYtX82DKPRMIxdg7+uPubY1wzDOGwYxgHDMK6aqY2LnIy2vhBZHgc2a/IvfZfdyvy8tGlpLL2rrotlBRm47NZxz9k4P5u9jd3D08hEREREROQ02rwZbr8damvBNBO/3367gkKSEqaSIXQv8IEk6z8yTXPt4K+nAQzDWA7cDKwYfMx/G4Yx/qdhkdPM3xsat3/QkKX56VS2nFqGUCxusrexmzXFycvFhtxwXjFZHgcf+q/X+IeHd9M2OAVNREREREROgzvugECAOAZ1vrmJtUAgsS5yjps0IGSa5hZgqjUtHwLuN00zZJpmNXAYuOAU9icyrfx9oaQj54+1rCCD+o4BeoMnP/3rSFsffaHouP2Dhiyck8aLf38Zt186n0febuSKH7zE/7xSRSQWP+nnFhERERGRKaqrA+DJZZdyxed+Trs7Y9S6yLnsVHoIfckwjD2DJWVZg2tFQP0x5zQMromcEfx94UkDQkvz0wE4eHRs2dhz+4/y9Uf3EorGJrzG64f9AKwtmTggBJDusvP1q5fxpy9fyrrSLL77hwquuetV+kPRSR8rIiIiIiKnoKQEgP1z5xO12mhNyx61LnIuO9mA0E+BBcBaoBn44eC6keRcM9kFDMO43TCM7YZhbG9razvJbYicmKlkCC0tSNwVqGgeHRDqHojwD7/fw2+31vG1R/Zimkm/tNnb0M2//ekA55VkUp7jnfLeFs5J497bzue716/kwNHe4SllIiIiIiIyQ+68EzweqrMKAehypYPHk1gXOcedVEDINM2jpmnGTNOMA3czUhbWAMw75tRioGmca2wyTXODaZob8vLyTmYbIickEI4SCMfITZ+4h1Chz0W6yzamj9BPXjhEZyDMh88r4pG3G/nJC4fHPLapa4DP3vcW2V4Hmz65AYslWYx0fIZhcMXSOQDUtPef0GNFREREROQE3XILbNpE7ZxERlB3STls2pRYFznHnVRAyDCMgmP+egMwNIHsCeBmwzCchmGUA4uAbae2RZHp4e8NA0yaIWQYBsvyM6g8JkOoxt/Pva/XcNP6Yn74l2v48HlF/PDPB3l8V+PwOX2hKJ+59y0GwjF+edv55KVP/Dzjyc9w4bRZqPErICQiIiIiMtPiH/s4NbmJvIau//ixgkGSMmyTnWAYxu+Ay4FcwzAagG8DlxuGsZZEOVgN8HkA0zT3GYbxILAfiAJfNE1z4mYrIqdJW19iglfeJAEhgKUF6TzydiOmaWIYBt97ugKH1cLfv38JhmHwrzeuoqFrgK8+vIfiLDdrijP5m9++zaHWPu697XwWz00/6X1aLAalOR5q2gMnfQ0REREREZmao71BQtHEUJeugZMfLCNytpk0IGSa5seSLP9igvPvBFRwKWcc/2BAaLIMIYCl+Rn0hWpp6BygviPAs/uP8tWrljAnwwWA02bl559Yzw3//Rqf+9UOLl2Uy4sH2vjeDat496JTL4EszfEqQ0hERERE5DSoPuZ9d1dAASFJHacyZUzkrDIcEJqkhxAkMoQA9jX18J2n9lOU6eaz7yofdU6W18E9t55P3DR5bFcTn3t3OR/fOD3TCMpzvdR2BIjHkzeuFhERERGR6VE7mJlvtRh0D4RneTcip8+kGUIi54qhHkI53skzhJYMlnz9+zOVHGnr578+vg6X3TrmvPl5afzqMxfw6mE/n790wbTttTTHQzgap7knSFGme9quKyIiIiIio9W09+OwWSjOcitDSFKKAkKSMvx9IXxuOw7b5IlxXqeN0hwPR9r6Ob8si6tX5Y977uriTFYXZ07nVofH1df6+xUQEhERERGZQTX+fkqyPWS67XSrh5CkEJWMScrw94XITZu8XGzI0vxEltA3r1mOYZzY+PhTVZqbCAhVa/S8iIiIiMiMqm0PUJbjJdNjV4aQpBRlCEnKSASEpj4K/kvvWcRVK/KnPftnKgoyXDhsluF6ZhERERERmX7xuElNez/vWphLZyBCRXPvbG9J5LRRhpCkDH9fmNz0qQeEVhX7+PC64hnc0fgsFoPSbM+oiQciIiIiIjK9WntDBCNxPGlHORy/l67AwGxvSeS0UYaQpAx/b4i8E8gQmm1luV5qVTImIiIiIjJjqv39GNY+Hm3+IV3hNoLWhYSj8Sn1HRU52+mrXFJCMBKjNxQ9oR5Cs60sx0Ntu0bPi4iIiIjMlGp/D66i39Eb7gLA4q5TY2lJGQoISUrw94UATqiH0Gwry/USisZp6QnO9lZERERERM5Jj9ZuwuY9wkW+z+MiD6u7ju6B8GxvS+S0UEBIUoK/L/FN/awKCA2Onq9R2ZiIiIiIyKTiZpxYPDbl85+ueprKgaew9LyLxd734LMsHAwIKUNIUoN6CElK8PcOZgidQFPp2VY2OHq+xh/g4gWzvBkRERERkTNIKBbilYZXqOqu4kjXEY50VVHbU4Pb5uE/Lv8hG/I3TPj4Ax0H+Nbr38IIlZMV+ggAObZFHI2/QXVnI+tLs0/HyxCZVcoQkpQwUjJ29vQQGhk9rwwhEREREZFjfePVb/CVl77Cj3f+mFfq36Iv4GKB672YMTefe/ZzPHb4sXEf6x/w87cvfhkbXgL1t5DldgEw17EYgP0d75yW1yAy25QhJCnhbOwhpNHzIiIiIiJjVXdX80zNMyz3fpD16R/DbnEPHwvFb+LFzh/yzde+SXV3NX+77m+xGIk8iK5gF/fuu5fNFb8lEo9wWdq3eTxiJ9NjB2COaz5mj43DPftm5XWJnG4KCElK8PeFSXfacNmts72VE1Ka46W2PTDb2xAREREROWPcs/cerIaDNWk3jgoGATgtabw/+w7e6P4F97xzDzXdtXxt4z/x4IEH+U3FZoLRAcrcF3Ne2l/S15cNNOJzJwJCHruDWLCYhkDFLLwqkdNPASFJCW19IfLOov5BQ8pzPbxyqI143MRiMWZ7OyIiIiIis6q5r5knq55kiecq3FZf0nMsho2LfbeTaSvixfp7eaH+eQDKXRezNusmsuwlADQEugHI8iTaShiGgREqwR95nXAsjMN69rSbEDkZCghJSvD3hs6qcrEhpTmJ0fNHe4MU+NyTP0BERERE5Bx27757MU1YmfahCc8zDIMVadeQYSukNriV5d6rybaXjjqnayCC1TBIc418LLZFyjHZQmVHJavzVs/IaxA5U6iptKQEf1+I3PSzL8I/NHo+WR+h/lCU7/+xkp6gxmKKiIiIyLmvfaCdhw/+ngWey0iz5k7pMfNc63hX5l+PCQYBdAXCZLhtWIyRTHxnrByAPW17pmfTImcwBYQkJfj7wmdlhlBZrgcgaR+hh7bX87OXj/Cnd1pO97ZERERERE6731T8hkg8zOq0G6blet0DETI9o28ae6zZGNEsdrftnpbnEDmTKSAk57xwNE73QOSsDAgV+Nw4rBZqkmQIPbi9AYC3aztP97ZERERERE6rnnAPv6v4HWWui/DZCk/5eqZp0hWIkDnYUHqI02bBDJWwq1UBITn3KSAk57z2/rNv5PwQq8WgJMdDTfvogNC+pm72N/fgsFrYroCQiIiIiJzjHqh8gP5oP6vTPzwt1+sPx4jGTXye0QEhl91KLDCPlkAzbYG2aXkukTOVAkJySlp7gsTj5mxvY0L+3jAAuWlnXw8hgLIcDzX+0SVjD21vwGG18OmLSznc2kdXIDxLuxMRERERmVkD0QHu2/crip3ryLGXT8s1uwOJPpzHZwi5bFaCfYkpZOojJOc6BYTkpFW29HDR91/g2f1ndg8bf99ghtBZOHYeEo2lazv6hwNvoWiMx3Y18r4Vc7li6VwA3q5TlpCIiIiInJseOfQI3eEu1qTdOG3X7BxI3FA9voeQy24hHirEik19hOScp4CQnLR7X6shFjc53No321uZUFtvIiCUdxaWjAGU5noJRhKj5wGer2ilKxDhpvXFrJ2XidVisENlYyIiIiJyjnri8JPk2Rcy17l02q7ZHYhgMSDdaRu17rJbwbSRaS1XQEjOeQoIyUnp7A/z6M5GAJq7g7O8m4m19Z29PYQAygdHzw+VjT20vZ78DBfvXpSH22FlRWHGWR8Q6uwP09mvsjcRERERGa2lv4X9HfsodV04rdftCkTwue1YLMaodac98RE53bKAfe37iMQj0/q8ImcSBYTkpDywvZ5QNE6mx37GB4T8fSG8Dituh3W2t3JSSnMSo+dr2vtp6Q7y8sE2blxfhHXwh9e6kix21XcRicVnc5un5Eu/e5uvPLhrtrchIiIiImeYF+peAKDUvXFar9s1EMZ3XP8gSPQQAkgzFxCKhTjYeXBan1fkTKKAkJywaCzOr9+o5cL52WwozToLAkLhs7Z/EEBh5uDo+fZ+HtnZQNyEj6yfN3x8Q1kWwUiciuaeWdzlyYvFTXbWdXHo6JldeigiIiIip98LdS+QZS+ellHzQ0zTpHsgMqZ/EAyWjAGu2HwAdmv8vJzDFBCSE/ZcRSuNXQPcenEZ+T4XLd0Ds72lCfl7Q2dtuRgkRs/Py3ZT3dbPw9sbOL8si/Jc7/Dx9aVZAGdt2Vhtez+BcIyWniCxM3xinYiIiIicPt2hbt46up15zgum9bqBcIxIzBwzYQzAaUt8RI7HfHit2ezxa9KYnLsUEJITdt/rNRRlunnvsrkU+Nx0BiIEI7HZ3ta4/H2hs3bk/JDyXC+vHPJT5e/npg3zRh0r8LkpynSz/SwNCO1rSmQ2xeImrb1ndraZiIiIiJw+Wxq2EDdjlLqmuVxsaOS8J0nJ2GCGUDhikmtfxK6jZ0iG0ObNUFYGFkvi982bZ3tHcg6YNCBkGMY9hmG0GobxzjFr/24YRqVhGHsMw3jUMIzMwfUywzAGDMPYNfjrZzO5eTn9Klt6eKOqnU9cWIrNaiE/wwWcGY2l/+PPB/nZy0fGrCcCQmdvhhBAaY6XgUgMj8PKB1cVjDm+rjSLt8/ygBBAU9eZnW0mIiIiIqfP83XPk2bNIdc+f1qvO97IeUhk59utBsFIjDmOJTT2N9AaaJ3W5z9hmzfD7bdDbS2YZuL3229XUEhO2VQyhO4FPnDc2p+BlaZprgYOAl875tgR0zTXDv76wvRsU84U971ei9Nm4ebzE1kqBZlDAaHZ/SAfjcX5xStV/PszBzh0tHd4PRKL0xmInPUBobLBErGrVxXgPW40JsD6kkyau4NnZUBlf3MPnsGG341dsx9YFBEREZHZF4wGea3xNYqd52MY01vY0tYbwm41SHeNfV8NiSyhYDRGiet8DCzct+++aX3+UaaS+XPHHRAIsCd/Ib0Od2ItEEisi5yCSf/PMk1zC9Bx3NqzpmlGB//6JlA8A3uTM0xXIMyjOxu4fm0RWd5ENL3Al/iG1DLLGUL7mnroD8eIxU2++4eK4fWOwVHmZ3NTaYDVRT6sFoOPbyxJenxDWTbAWVc2Zpom+5u6uWxxHqAMIRERERFJeKPpDYKxIKXu6e0fBInPLnPTXVgMI+lxl81KMBLHZytkofsy7q98gKP9R0/sSaYS6Jlq5k9dHU3pudzwyR/yk4s+Ompd5FRMR6j1M8Afj/l7uWEYOw3DeNkwjHdPw/XlDPHg9nqCkTifvrhseO1MKRnbVp2IWX7+0vm8fLCNFw8k0jrbekMA5J3lPYTWzMtk97ffz7qSrKTHl+an47Zbz7qysbbeEP6+MBeUZ5PhstHYOXFA6Ndv1vIvT+47TbsTERERkdnyfN3zOC1eChwrkp8Qj+FuayatuY6M+iNkVleSfWgv7rbmCa8bjcXx94WY63ONe47Tbhnukbo2/SaiZoy799499c1PNdBzxx0Ew1Fuvvl7vFW0PLGWLPOnpIRHVl5BzGLllfLzRq2LnIrkOXJTZBjGHUAUGPrKbgZKTNNsNwxjPfCYYRgrTNMcMw/bMIzbgdsBSvSFfMaLxU1+9UYtF5Rns7wwY3jd7bCS6bHPesnY1up2ynO9/J/3L+HZ/Uf57lP7edfCXPx9iYDQ2V4yBpCWpFRsiM1qYe28TLbXdox7zploqH/QikIfhZnuSTOEntzVxL6mbr51zXKMce7oiIiIiMjZLRqP8lL9SxQ712Mxkr8HXvbILyh9+Q9j1uMWKzs/93XaVm5I+ri2vhBxc+TGdjIuu3W40iDdNpfF7it5+ODD3LriVorTp1Acc8cdmIEAL5ev4901u7Ca8ZFAzy23jJxXV8eBuQt5s3Q1/2l+jN888M3h9WOZ372Th15N3IDfP3cBHe4Mso0o3Hnn5HsRmcBJZwgZhvFp4BrgFtM0TQDTNEOmabYP/nkHcARYnOzxpmluMk1zg2maG/Ly8k52G3KaPL23mYbOAW47JjtoSIHPPaslY/G4ybbqDjaWZ+OwWbjj6mUcaetn85u1+PsGS8bOgYDQZDaUZVHR3Et/KDr5yWeIfU3dACwrSKco003jJAGhmvZ++sMxjvaETsf2RERERGQW7GzdSXe4m1JX8nIx60CAojeep235enbd9lXe/tzX2f6Fb7HtS9+ht6iMtb/4PtkHko+LH/rckj9BhpDLZhk1RXlN+o0YWPnZ7inOTKqrY0/+Im79y+/w50UbR62PUlJCdXYRAK+WncehnHnD68fadvEHqM3M5xOHtgDw+vorYdOm0cElkZNwUgEhwzA+APwjcJ1pmoFj1vMMw7AO/nk+sAiomo6Nyqk7dLSXD971ygkHb+Jxk5+8cJgFeV7evyJ/zPECn2tWS8YqW3rpCUa5oDzRR+fKZXN418JcfvTcIQ639gFnfw+hqVhXmkUsbrK7oeukHh+Lm9y86Y3hcrvTYX9zD6U5HtJddoqyJs4QCoSjtA6WAB5p6ztdWxQRERGR0+yFuhewGnaKnGuTHi986yVs4SD/s+BKms67hNbVG/GvWE/HkjVs/+I/E8grZN2mO8msqhjz2JaeIGlO24TZ9067lVAkzmDeA15rDks8V/HkkSep6p7Cx9uSEmqyEpOBD+aWjlof5c47qZpbiiUewxENc9+6a8DjGZP589COBtKcNv5x83dJd9p47Sv/omCQTIupjJ3/HfAGsMQwjAbDMD4L/ARIB/583Hj5S4E9hmHsBh4GvmCa5tlVw3IO21nXxb6mHh7cXn9Cj3t2/1EOHO3lS1csxGoZW6aT73PNaobQtup2ADbOzwHAMAy+cc0yeoMRfvlaNS67Be/gFKtz2bp5if5CO2pOro+Qvy/Em1UdPPNOy3Rua0L7mnpYMViCWJjppicYpTcYSXpujX849kyVAkIiIiIi5yTTNHmu9nkKHauxW9zJTqDk1T9yJGseW6xzhm8AD4l4M3jrS/9CyJfN+p9+h4z6I6Me6645zF/ve4ILf/hVNvzXt1nzyx+w7MGfsfCpzeTv2AKmictuIWaaROPm8ENXp92A1XDw3zv/e/IXceedNOYmMn+OZA+WmCUJ9HDLLVS/70MUBzq4rmILj6x6L90/vXtUsKc/FOXpvc1cs7qAdJedjfNzeP2If/I9iEzBVKaMfcw0zQLTNO2maRabpvkL0zQXmqY57/jx8qZp/t40zRWmaa4xTXOdaZpPzvxLkKny9yeyKx7aUU/8mG9uEzFNkx+/cIjSHA/Xri5Mek5Bhov2/vCotMrTaWt1B0WZbooyR35gLM3P4GMXlBCKxslNc6ZEvxmfx87iuWnsqDu5gNBQA+6hvj4zrScYobY9wPKCkYAQQNM4o+dr2/uH/3ykrT/pOSIiIiJydjvQeYCWQDOl7o1Jj2cd2U96cx1PlF2E1WKwrbpjOJNnSDgji7f+5jtEPWls+K9vk1O5i/nPPszFd36J7z/zAy6t2ELc5sAWDJBRf4SCt19lwbMPs/beHzJnz5u4bImbycd+vnFbfSz3fpBnap/hQMeBiV/ELbfQeM1HADiSUwylpeOWeFWn5VK+bjm3bvpnAnYnD5VfOOr4H/Y2EwjHuGlDIrB0ycIcatsD1HcExlxL5ERNx5QxOUt0DPbTqe8YYGv11BK3XjzQyr6mHr54+UJs1uRfLgWDH+SP9pz+LCHTHOwfND97zLG/e99i0p028lKgXGzI+tIs3q7tnHLA71hDAaEDLb1EYvHp3toYlc29QKKhNEBRZqKOe7yyserBgND8PK9KxkRERETOQaZp8tjhxzCwMM+ZvCl0ySt/JODw8EbpOi5fkkd7fzjpzcJgVh7bvvQd4lYb5//Xt1n85K/pd3q5a82N/O6rP2Xb397Jm//n33nlWz/lhe//hmd/9DB9c4tZ/NRvcA8WFwQjo98Tr0z7EE6Llx/v/PGkr6UxLxHAqSpZglldnTQYZJom1W39lOd6WVnkY0NpFr96o5bYMe/lH9pez/w87/C04UsW5gIoS0imhQJCKaS9P8ycdCfpThsP7Zi8bMw0Te56/jBFmW5uWFc07nkFvtkbPX+krY/2/jAby8cGhHLSnNz96Q18/eplp31fs2V9aTY9wSiHTyJg0jY4kS0ci5+WgMtQQ+ljS8aAcRtL1/oD5KY5WVOcyZFWBYREREREziV1PXV87tnb2VyxmXL3RbitvjHnOHq6mLv7DZ4t2UB5cQ7L8zPwue1sqxmbJQQwkFfAtr/9HpU3fIaXv/1zfnbjP/Kn8ovwzc0dc65ptXLomk+Q1tLAyn2vAYypgHBavKzwXsfLDS9T2VE54etp6Ey8pw2EY7SMc+O8rTdEfzjG/DwvAJ++uIy6jgAvDfb0rPb381ZNJx9ZXzxc8bBoThp56U5eO9w+4fOLTIUCQinE3xeiMNPNNWsKeXpv87i9Woa8etjPrvou/td7FmAfJzsIRjr0z0YfoaFMp43lOUmPXzg/h/PLxgaLzlVDgbGXD7Sd8GOHMoQA9jXOfNnY/qYectMcwxlcc9Jd2CzGhBlC5bke5ud6aeoOEgifPdPURERERCS5SCzC3Xvu5obHP8zO1j1c5Pscl2V+Oem5xW/8GUssylOlF7K8IAOLxeD8sizaekPUtCcvoQrMKaTmig8xkJvP0Z4g2WkOHLbkn22OrrmQrpJFbHjxYeyxCKHo2Kz5Zd4PYDVsPHb4sXFfk2maNHYODLdGONKavN1BlT+xXp6bCAh9YGU+czOc3Pt6DQAP76jHYsCN60ZG3RuGwSULEn2EkgXBRE6EAkIppL0vTI7XwU0biglG4vxhT/OE5//4+cMU+Fx8ZH3xhOcNZclmBnsAACAASURBVAg1dU88MnwmbK3qYE66k9Icz2l/7jPRvGwPq4p8PLWn6YQf29Ybwuuw4rJbTksfoX1NPSwv9A3f7bBaDPJ9rnEDQrXt/ZTmeFkwJw2AKvUREhERETmrHeg4wE1P/iV37byLQsc6Ppz3nyzzfgDDSPIxNR5j3mvPsC9/MaGCYuYM3lRcmp9BusuWtJfQsUzT5Gh3kPyM8cfNYxgcvO5TeLvbuab69aQ9Up2WNEqcF/DUkaeIxJLfYO8MRBiIxLh0cR4w/oTc6uMCQnarhU9sLOWVQ34OHu3l9zsauWxxHnOP2/PFC3Px94U5cLR3/NciMgUKCKWQ9v4QOWkOzpuXyYI8Lw/taBj33Der2tlW08HnL52P0zbxhC6Pw4bPbT/tGUIj/YNyUqJp9FRdu6aA3Q3d1I1zl2Q8/r4QczJcLM3PYH9z9wztLiEcjXOotXf4rsmQwkx30qbSgXCUoz0hynO9LMhLBITUR0hERETk7Hbn1u/R1NvGe7P/iSuy/x6PdfzM/rx9O3B3tvHovER20LE3FTeUZtHSE6RugkbLXQMRgtH4xAEhoGPJalqXrOWjB5/H7E8ecFnouZzucDdbGrYkPd7QmdjHeSWZpDtt407Irfb347BZKPSNDMf52MYSHIbJ//7Wb2npCXLTL/4VNm8e9bihPkIqG5NTpYBQijBNM5EhNDhx6y83zGNHbee4H6p//MIhctOc3HxByZSuX+BznfYeQnUdAVp6glyQpH9QKvvg4DS4J08wS6itN0RempPlhRnsb+qZ0RTUQ629RGLmcP+gIUWZ7qQ9hGoHg1ulOR5KczxYDE0aExERETmbxeIxKtorKHNfTInr/EnPL3nlj/R4M9lWuIIl+emjji0vzCDNaWNbzfiDc4YG4ByfbZPMoWs/gS8cYMPWPyY9XuRci8eaNW7ZWONg/6DiLPfgQJRxSsba+inP8WKxjNzczn38Ya7Zv4XKrGIyB3q48s2n4PbbRwWFijLdlOd6ee2wGkvLqVFAKEX0DESJxk1yvA4AblhXhNVi8ND2sVlC971ew2uH2/n8pfNx2SfODhqS73Od9gyhof5BFyogNEpRppv1pVk8ufsEA0J9IfLSnawozKAnGB1uhDcThkrSjg8IFWa6aOkJEj1uylnNYDptWY4Xl93KvGyPMoREREREzmJ1vXUEYwPk2MsnPdfd1kxu5U7+WLqRkjkZeBy2UcdtFgvrS7No6goOZ+ccr6U7iN1qkJPmmPT5eksX8dq8tVzy9rM4errGHLcYVha4LuWVxldoHxibpTN0g7M408OCvLRx37dW+fuGy8WG3XEHt257FIDr972EMxaFQADuuGPUaRcvyGFrVftpmQ4s5y4FhFKEvz/RMDg3baSB7+WL83jk7YbhD9/xuMn3nq7g20/s473L5vDJi0qnfP1EhtDMBBAe2l7Pq4fGRr+3VnWQ7XWwcLCnjIy4ZnUBlS29HG6del2xvzdEbppjuIxrJvsI7W/qweOwUpYz+gdgYaabWNyk9ZgG18Bwk8ChXlHzc73qISQiIiJyFhua0jWVgFDJa3/CxODJeRew/LgbikNWFmbgcVjZOk4voZaeIHPSXVim2GrikbXXYI1FWfDMg0mPL/RcTsyM8XT102OONXQOkOa0keG2sWBOGs3dQfpCoweiRGNx6toDlOcdFxCqq2N1y2Hueeif+cqrm0etH+tdC3PpD8fY0zA2YCUyVQoIpYj2vjDAqIj4TRuKae0N8cohP8FIjL+5fyebtlTxqYtK+fknN0w5OwggP8ONvy9MKDq28dqp+s6T+/nUPVvZvLV21PrW6nYuKMtW/6AkPriqAMOAJ3dP3Dh8SDASoycYJS/dydL8DCwG7G+auT5C+5t6WDY4GeJYRYOj549vLF3j7yc3zUG6yw7Agrw0qtr6iMc1WUFERETkbFTRUYEFG5m2eROeZw0NUPz6n9lVtpYBXzZl2d6k59msFs4vy6ahc4DKltE3RaPxOP7e8KT9g47VlZ3Pq4suYt5rz+A9OraqIsteQp5jYdKysYbOAYoy3RiGwYLBgE/1cTczGzoHiMbNsRlCJYmWHVdUbccX6h+zPuSiBTkYBrx6SH2E5OQpIJQiOgYzhHK8zuG1K5bOJdvr4Jev1/DJX2zlD3ua+frVS/mX61ZgtZxYkKUgM/HNtbUnNMmZJ6YnGKE3FCXdZeeOR9/h3/5USTxu0tg1QEPngPoHjWNOhouN5dk8tadpSr2A/H2J/2556U7cDisL8tLY3zwzGULxuMn+5p4x5WIwEhA6vo9QTXv/qGyiBXPSCEXjSfsNiYiIiMiZr6K9kiz7PKyGfcLzit58AftAP78puYRl+WNvKB5rdbGPQp+Llw620RscmQDm7w0TM03m+pzjPvZ4LruVh1ddTczhZMVv/wviY0uzFrrfw8HOg8PZTkMauwbIyKrhmkeuAUcimFTlH102NjRhbP7xAaE77wTPcROUPZ7E+jEyPQ5WFGbw2hH1EZKTp4BQivAPZgjlHpMh5LBZuH5tEVsOtrG7vpsff+w8br90wUll3AyNnp/uxtJDmSLf+dAKPnZBCT996QhfeXAXrw2WkG2cr4DQeK5dU8iRtn4qmicvGxv5+kj8kFxemDFjJWP1nQH6QtExE8YACoYzhEZ/HdUMjpwfokljIiIiMpH2gXZaA62zvY2U9fPdP+f3B38/7nHTNKloryDbNkm5WDxG6UtP0FCwgIqs0nHLxYZYDIP3LZ+LaZo8V9E6fGO0ZbCh9IlkCDntFo7avVR++DNkV+1n3qt/GnPOfPclWA0bjx9+fNR6Q38lh4wfU9tby0stj2C1GBxpHf2+teq4kfPDbrkFNm2C0lIwjMTvmzYl1o9zSaiVnYdbCTjdUFY2ZhqZyGQUEEoRQyVjWd7RTdRuvbiMixfk8Ju/2si1awpP+vojAaHpzdgYCgjNy/bwvRtW8tWrlvD4ria+8dg7pLtsLM2f+IdCKvuLlQVYLQZPTWHaWFvvSIYQJJo9N3cH6egPT/u+RhpK+8YcS3Pa8LntNHaNNAMcGTk/cqdkKPVWk8ZERETkeKZp8oXn/ppPPf1pIvHI5A+QaRWLx7jnnV/yi3fuGfec1kAr3eGuSfsHzXlnO15/C39Ycjm5aQ6yvZM3hM70OHjXwlzqOgLsaUy0QGjpCeJ1WofbD0yFy24lGInRuPFK/EvWsOSJ+3B1tAGJdgsATks685zn8+SRp4jEEl9ru1oqMOf+DzYznVLXRp6r+zNF2WPft1b7+8hw2cj2OqjrqSMWP6b1xi23QE1NIiuppiZpMIjNm7nkf35AxGpjW9FyqK0dM41MZDIKCKWI9v4QPrcdu3X0f/KSHA+//dyFp1x6le9LZHZMd4ZQ42CmyFAN7hffs5D/76NrMTG5aH7OCZe2pZJsr4NLFuby5BTKxo4PCC0vSARr9s9AltC+pm5sFoNFc5M3Ay/MdI/KEBoZOT9y9yTb68DntlOlDCERERE5zraWbVR2VNDY38DTVWMb/srMququIhDtp763jpb+lqTnDJVYZU8SECp78XEC2Xn8MWvJcGuBqVhV5KM028Orh/x0BcK0dAdPKDsIwGWzEomZxEzYd/MXwTRZ/sBPqWvvZ9OWKtoHWy4s8ryH7nAXWxq3UN9Tz5de/AKmaWOV9R9YlXY9oVgIX27FmMz2an8/5XlpVHZUcu1j1/L7Q+NnVCV1xx2cf2QnzkiIe9dfR8ywJJ1GJjIRBYRSRHtfeEojFk9WmtNGuss27aPnm7oGsFsN8tJG6n2vP6+I5/7uMv71w6um9bnORdesLqC+Y4A9DRM3iB7qITTUY2qov8++GWgsvb+ph4Vz0sZtWl6U6R7VVLq2fWw67VCDPpWMiYiIyPHu23cfHquPbHspm/bcPTrzQmbcnrY9w39+q+WtpOdUdFRgYJBjLxv3Ohl1h8k+vI99F36AkGmhwDf1gJBhGLx32VysFoOn32mheyDC3BMNCNkTH5WDkRgDuXM5dM0nmLN/B55XnsdkpMVBkXMtHmsWv97/az777F8RCIcZqPssc9yF5NkXkWUvptf+OlX+fmLHDESpbutnfq6Xu/feTdyM82Ldiye0P+rqcEdD3PHiPby0YAN3vuczw+siU6WAUIrw94XI9U69idrJmInR842dA+T7XGOax5XmeMlJm9nXcy64akU+dqvBk7snLhtr6w2R6bHjsCW+JWR5HRT6XDPSWLqhc2DMuPljFWW6RjWLPn7k/JAFeWkqGRMREZFRjnQd4ZXGV1jq+QvWpN1EXW8tz9Q8M9vbSil7/XtxWdJwWdLY1rIt6TmVHZVk2AqwW8YP8pS9+ARRp4tXF10MjLSomKo0l43Ll+QNZ8JPmCFkmpzX9Fs+uvevcEUSY9ydtsTNy1A00Uy69rIP0lm6mOteuR9fqI+jvYmAkMWwMt/1bnYc3UH7QCcLYl8hHp5LusuGYRgsdL+H9uhBopaW4ZueA+EYTd1BsnydPFf7HHbDw7aWtwhGT+Dm+uDUsU/t/AO3bn+Ce86/nl+fd/WYaWQiE1FAKEW0989shhAkysZmoqn0iaSHymg+t53LFufxh73NE45ob+sNjcrCgplrLN01ECHLO379dmGmm95glJ7ByRDHj5wfsmBOGm29oeHzRERERO7bdx82w8lSz1WUuTaSZZ/Hz/dsIm6OnRAlM2NX625y7YuY41jO1ubkAaH97RVk28rGvYazq538t1+l4aL3URM0hqsRTtSSueksnJOG1WIwJyP5zWRHtI9rDvwTl1f/iMKe3axpeRgYnSEEgMXKC9d+DnckyBf2Pk5r78h05aXeq5jjWMKVWV8jFizCajHwOBIBpQXuyzCwYPPt4PBgdnvNYAb8kfATWA0HF/k+SzgeGjejKhn/d7/O3TcUcv2dC1kTeogrD2/jn9/7eV669tOJBtMWixpNy6QUEEoR7X2hGQ8IFWS4ZiQgVKiA0Cm5dk0hzd1BdtR1jnuOvy80PGFsyPJCH1VtfQyEpy/N2jRNugciZLgnDgjBSEPx4yeMDRmaNFalLCEREREB/AN+nqp6ioXuy3BZMzAMC6u9N1LVfYQX6l6Y7e2lhP5IP1XdR8hzLKbQsYrm/iYaehtGndMd6qa5v2nC/kGlW/6AYZrUXnYtzd1BCnyuMZOQswNVrGl+EG+obdzrGIbBVcvn8vELSoYzfo6V23+IW/Z8moUdL8P7/i/mwvdzXvOD2GLB4fYGwwEh4G1LFg8uuZLLG3aS2XCEaCwRaMyw5XNN7vcocK6gJxgdzg4C8FizKHSchz3zbQ4dTbRjqPb3Y9g72NX5Aos976XMfRE2w8Grja9O9M+LaZq81fIWX335q7wv/lPu+lA29XOcPHlJJnftup8lZh9fsq+ksh8wTTWalkkpIJQCorE4XQOR4f4wM6Ug04W/L0Q4Oj13YKKxOC09QWUInaJLF+UBsLu+a9xz2vpCww2lhywvyCBuQmXL2Cyh+o4AgXD0hPcSjMQJR+NkuscPTo4JCPkDSUvM5g9NGmtVHyERERGB+yvvJxqPsiLt2uG1cvfF+GyF/Gz3zycdsiGn7h3/O5iY5NkXUeBcCYztI3Sg4wDAuBPGrKEgxa89w9E1G2lLy6E3GE1aLnZl1b9xRdW/87nt13DDvr9hSdsz2GJjb07brJak08mWH32Sj+25jQxrCOPWp+CS/43xri/jjnSyvPXJ4YDQUMmYaZocaetn17orATjv6AH8fWMn8vYGI2Qcl9m+xHslFlsvb7a8ASQCQo7sLYCFVWkfwmY4yXesZEvDK0n/TQAi8Qif/OOn+Mwzn+GluldZ4vkAN865iyWZ17NrRSZGxU5+8dT/wxsa4DM3fZtWb1bigWo0LRNQQCgFdAYimCbkznSGkM+FaUJr7/RkCR3tDRE3UYbQKcoanMhV7R8/k6atd2xAaKSx9OiA0I7aTq78j5f5wTMHT3gv3QOJ8i7fBBlCxVmJ/96NXUEGwjFaeoKUHdc/CKAk24PNYqixtIiIiDAQHeD+yvuZ59qAz1Y4vG4xrKxOu4EDnZVsadgyiztMDUMNpfMci8i0zcNt8Y3pI1TRUQFAjn1+0msUv/4sjkAfNe/50HB/0oLjPg9kBWoo7n4bNn4B491/R0m8gasPfoPPv/UBLqv6Dwxz4gz38xvu5arD38FScgGWz78CpYk+RZReTLzofM5v2ozbmggEDWUIdfSH6R6IMGdeAV35JaxpO5z0c0/PQJSM48rb5rnWYcTSqOx7LvFv0NqII2s7Cz2X47XmJF636zwa+uqp60neFPql+pfY3baL9em38JdzNrHRdxs+WxGFztVE4hF2tu6k4MAefvHwv+D3ZPLfF9408mA1mpZxKCCUAtr7E/Wt2TOcITTdo+cbOxM/ABQQOnVlOZ7h8e3H6w9FCYRjY0rGirPcZLhsoxpL17UHuP1X2wlH42ytbj/hfXQNJO6iZHrGDwjlpTmxWw2augao7UgEscpyx2YI2a0WSnM8CgiJiIgITxx+gu5wNyu91405tsB9Kem2OdOeJdQZ7OS1xtem7Xrngj1te8i0FeO0pGEYBvmOFWxt3jbq372yoxKvNRu31Tf6waZJ+Z9/z9JHf0n7opV0lS+lqTuIzWKM6XW56uijmBYbvPv/wJXfxPLlvfDpp7Av/yDrmn/HZdU/GneP5R2vcEntf2OuvBHLJx+D9LkjBw0Dy7u+TEawkZXdL2GQyHAHhoeZzM/z0rVkNSvaq2nvGP0+NBKLMxCJjel9aTXspEUvoNeyh85gJ7t7HgdirE67fvicYuc6AF5pTJ4l9EDlA6Tb8hIZRZaRf4+5jmVYDRtvNr8JJSWsbK1isb+OmqyRwKgaTct4FBBKAe2DqYwz3kNoMJVzugJCQyVDRZknNlFAxirL9Y6bITQ0cv74DCHDMEY1lu4eiHDbvduIxk2uW1NIRXMPfaETKxvrDkyeIWSxGOT7XDR1DVDjTwSxxptKpkljIiIiEjfj3Lf/V+Q5FjLXsWzMcYthY5X3Bt5p38sbzW9M2/Peu+9evvDcF2gfOPGbZOci0zTZ3baHXPvC4bUC50raBlqp7akdXks0lB5dLmYNBlh7z/9jyRO/ouW8i3n7898Ew6C5e4C5GS6sx0wctsZDrGj7Ayy9BtLmJBYtFih/N8aNd8OFX+S85gdY23T/mD1mBWq4+uA3MfNXY1z3E7AmaVS95GriOYs4v+nXOO0GwWgiQ+hIWx/5GS68ThvtS9bgjEfxVVeMemhvMPHe+PgMIYACy6VgxPjl3l/TZduCJ7qeDFvB8PEMWz4+WyGvNoztI1TTXcPWlq0sdr8PizG6F5LN4mSOfSlvNL0Jd94JHg9F3a00ZSTaRuDxJNZFklBAKAUMfeA/HSVjAC3TNHp+aPS4MoROXWmOl6buAULRsemzQ6M4jw8IAawo9FHZ3EMwEuN/bd5BXUeAn39yPTeuLyZuTtyXKJmuKZSMART63ImA0OAEhtLcsSVjkJg0VtveP9zQT0RERFLPS/UvUd9bxwrvdWMaDw9Z5HkPadYcfr5707Q97+7W3QDsats1bdc8mzX2NdIZ6mCOY/HwWoFzFcBw2VgwGqSmp2ZUQ2lPaxMX/vAfmLv7TSqvv5Xdt/49MaeLSCxOW29oTP+gRf7ncUW6MTbclnwj7/+/mEuu5vLqHzG/Y6RM0Bnt5frKv8fmdGO5eTM4kr+/xGLBcsn/Zk7fAS637iMYidEbjNDaGxruYdmxcCUxw0J5feWo96G9g9Nv05O81y30lBMbKObe/f8DlhDzjGvGnFPkXJt0/PyDBx/EYthY7Lky6ZYLnKs40FlJ541Xw6ZNFBKk0ZeHWVoKmzbBLbckf62S8hQQSgHDGUIzXDKW7rKT5rRNKUPINE2+fP9OXj44/lSApq4Bsjx2PI4THzEpo5XnejDNRDPo400UMFxekEEoGuev7tvOa4fb+dcPr+bC+TmcV5KJYcD2mvEnlyUzlR5CAEWZbho7B6ht7yfH6xjTmG/I/FwvkZhJfef0BCFFRETk7PPggQdJt+ZR5rpw3HOshp0V3ut4u3XHcJ+bUxGNR9nXvg+AXa0KCAHs9e8FEv2DhmRYC/Bas4cbSx/qPETcjA03lM4+sIeLfvD3OHu7eOuL/0zNlTfAYFDvaE+QuJkYXHOs1UcfJZ41H8ouTb4RixXjxv/BLFjDBw/ewZy+Cgwzxl8c/Aa+UCOWj/4aMudN/GJWf5R42lw+YzxBKBKnajDTfmjKbcztoa2wnDVth0Y1lu6ZIEMoy+sg0r0eE5NI7zIKPGObahc7140ZPx+MBnns0OOUOjfitmYm3W6hczUAW1u2wi23UPR3X6Tf4aGn4pCCQTIhBYRSQHt/CKvFmPRD+HTI97lo7po8IFTR3Mtju5p4fFfjuOdo5Pz0GRrbPlSCdawJM4SKEo2lXz3s50vvWchH1hcDkOGys2Ru+oSj7JMZKhmbqIcQQFGWm5aeIIdb+yhN0lB6yII5iR/KmjQmIiKSuio6Ksl3rhpTSnO8xZ4rcVq83Lvv3lN+ziNdRwjGgoDB20d3nvL1zgV72vZgM5xk2UqH1xJ9hFYO9xEaaSidCIYsePw+gp40Xv+H/6BjyZpR1xu6yVzgG/k8kBM4QlHPLiwbbk2UiY3H4cXy8QeweHO5vuLvuPLI9ynvfB3jL/7fSAPpidicWC78X1xg7qEsfJCqtn4yPXayjnkP27FkDUs66+lsG3k/3DMQwWKA1zk2IORz2Yn1nIfZv4Jw21VkecbejM13Lh8zfv5PNX+iN9LDUu9V4243174Ah8XD1uatwNipvSLjUUAoBbT3hcn2OrBYkqfQTqcCn4vmnskDQi8dbAWgsrl33HMaFRCaNuVDAaH2sf122npDWIzkGWQL8tLI8ti5bk0hf/e+xaOOrSvNYmdtJ/H41Jszdg9EsFoM0pL8kDxWYaZ7sCStO2lD6eH95Q4GhNRYWkREJCX1hHvoCLaTaSua9Fy7xc0Sz1U8X/s89T31p/S8Q9kwpa4L2N++b0yJTyra1babXPuCMYG5AudKOkMdHOk6QmVHJU6LlzTrHIxIBF9jNc/lrqAnI3fM9Zq7g2R57LjtI9db1fIoptUBa6eQ9ZI+F8stD+EmxKqjj2Guvw3O/+zUX9CG2xiwePlo5FEaOgMsyE0bVZLYu3wtVjNO+qF3RtaCUdKcNixJShctFoNMVwZ9dZ/EDOcnzYBPjJ9fMWr8/P2VD5Bln0e+Y/m4W7UYVvIdK3ij8U1gJCDUqCx6mYQCQimgvT9Mjndm+wcNKfC5ptRD6KUDiVKxw619RJL0fzFNk8bOAYoUEJoWmR47GS5b8oDQYMDQmiRgaLda2PIP7+E/b147JqC4oTSL3lCUg63jB/WO1zUQxue2j1vfP2Toh1g4Fh+3oTSAz2MnN81JlRpLi4iIpKTq7moAfFMICAEs916NYVi4b/99p/S87/jfwWVJZ6H7MqLmSPlYqgrHwhzoqCTPvmjMsQLHSiDRR6hisKG0YRikN9Vgi8fYn1HEWzUdox5jmibNXQOjsoNssSAr2p6GZdeBd2wAKam5y7Hc8iBc9KVEdtCJcPnYkXs9V/EmH7a8PNw/aEj3/GVErDaKqkYCQj3ByLitDoDhDCOfy570vTckysaGxs/vb9/PvvZ3WOJ+/+Tvn52raexvoKG3gcLBMrumaertKucuBYRSQHtfaMxI8ZmS73PT2htKGuQZ0hOMsKO2k3nZbsKxeNIP8z3BKP3h2PA3Mzk1hmFQnutNOnq+rXfir490V/IAzvrSLAB21E69bKx7IDql0sVjJ8tNlCEEsCDPqwwhERGRFHWiASGPNYv57kt57PBjdAZPrPT9WLvb9pBjX8gcx1IAdramdtlYZUclkXiEPMfiMcfSbXPJsM3hjaY3ONh5iGx7GQCZtQcBOJhVws76ruFekwCdgQjBaHzUZ4HF/j/jiPaO30x6PKUXw1V3gu3Eb5DvLv8sW+PL+IH959za+n3ssZH30nG7g/rCRSxpOjD82ac3GCXdPX4m/FCZ2ETtE4pd5wGJ8fMPVD6A3XCy0HPZpHstdAz2EWreSq7XicNmGR7Sc0o2b4ayskSJXllZ4u9yzlBAKAW094dnfOT8kAKfC9OE1sG+NMm8dshPLG5y+7vnA1DZ0jPmnJGR8+P3j5ETU5qTfPR8W18oaf+gyZRke8hNc7LjBBpLdwXCUwoIHXs3qGyCHkIAC+ekcfBoL6Y59dI1EREROTdUd1djNWykW+dO+TGrvB8iFAtx/4GxY8mnIhAJUNV1hDz7ItxWH5m2wpQPCA2V0M1JEhACmGtfyZbGVwjHQ8P9g9JrDtHpTCN/USkG8Nph//D5zYOZLce+J1x99FHiOYug9JIZehVjudOz+UTk6zw35zaWt/2RW/Z8mpz+w8PHWxeuYn5PM30trcTiJn2hKOnHZggd9/40e7BqI1n/oCEZtgJ8tgL+VP0MT1c/Tbn73TgsE98ghURQ1GvN5s3mN7FYDAp9Lpqm0Nt1Qps3w+23Q21t4rXU1ib+rqDQOWNKASHDMO4xDKPVMIx3jlnLNgzjz4ZhHBr8PWtw3TAM4y7DMA4bhrHHMIx1M7V5mZqhHkKnQ/4URs+/dKCNdJeNj6yfh91qUJGkj1DT8Mh5ZQhNl7JcL01dY0fP+3tD5J1EBplhGKwvzTyhxtI9A5EpBYS8TtvwnZPSCUrGAFYW+egJRqlLMkFNREREzm1VXVVk2AombSh9rEx7MfNc6/ltxe9OqvfPvvZ9xIkPT9PKsy9lV+tu4ub4GfLnut1tu0mz5uCxZic9XuBcQdxMvAfNsSduCmfUHuRg5jzm+txsKM3iUGvfcEZLU1cQl80yXGKV23+Igt69WDbcNjyF7HTI8tqJY8FyxdcwPvU4PiPAx/fcyoqjjwPQv3ItAJ79u+kLjZ4w1h+a5gAAIABJREFUlllVweXf+iyZVRUj15tChhBAkfM8drXtJBgLstQzfjPpYxmGQYFjNW80vUncjFOY6T71ptJ33AGBAP958c187/LBzKxAILEu54SpZgjdC3zguLV/Ap43TXMR8Pzg3wH+Alg0+Ot24Kenvk05WcFIjL5Q9LSVjBUMBoTGGz1vmiYvH2zj3YtycTusLMhLmyRDSD2EpktZjoe4CfUdIz8YTNM86QwhSJSN1bYHhieVTaZrIDLpD8AhRZlusr2OSQNIq4p8AOxt7J7SdUVEROTcUdVdjc86tXKxY630foiuUCdPHHnihB87PF7dvhCAuY4l9IS7qemuOeFrnalM0+Tmp27mrrfvmtL5u1v3kGtPnh0EUOBcBYDNcOCzFWEdCJDR1sTBrHl4HVbWlWaR5rSx5WBbon9Q9wAFme7htgUrjz6GaXXCmo+d+os7AVcsncs3PriMSxflwfzLsPz1a1hLL+T9h79LXt8B/n/2zjswjvJO/5+Zne1V0q56s2RZstwLrphiSggJgZCEEkKAJJBCkrvwu+OOJJd24Woal0IgPYQkQCAQShKqsY3Bxl3FliWr97pd2+f3x0grrbWSZZBcYD7/2Jp5Z+Yd7a525pnn+3yjZZUEJAPZTTV4x0rebAYtmlCQ5Q/9AIN7iJJtTyf3l2PTs6XCSWWOdcbjFuiVsjGXtgKnrmzW883TL8MTcXNs5Bj5DuNJQ6V/fvjnPNn05PQD2tsBeKFiA39btGnKcpVzn1kJQrIsbweGT1h8NTCexvYb4JpJy38rK7wBOARByJuLyaqcOkOBCMBpC5UuyjChk0R2Ng6mXX+010evN8RFi7IBWJxnS9tprNM9ilYjnDYh693AeBZP26RgaW8oRiSWeBuCkPIUaLY5Qp5ZOoQAzivNZGNZ1knHLcqxotOI1HSqgpCKioqKisq7iWg8Sqe/c9b5QZPJ1VXj0i3k13W/IZ6In3yDSRweOIxdysWgsQG8I3OEuvxd1A3V8bOan/Fow6Mzjh0aHaI70JV0TKXDrMnCIeWTIZUgChrsHU0IskxDRjEWvYRWI7J5YRb9vjAHOtyMBKPJB82CHKNq6EWovAJM6R1I84XdqOVTW8qQNGO3zZZshA8oIlmOvx4kieP5FZS1H8EXUhxCVoNE1RO/wDjUz1DFUnIO70brVx6AC4LA6uIM9NqZHW15+iW4tBWssH7olOabPya87e7ZTb7DSJ8vNG22a3+wnx8e/BE/2Hff9J+B4mIA+iyZ9NicJBBSlquc+7ydDKEcWZZ7AMb+zR5bXgBM7uPYObZM5Qww5FecG1mnSVgx6yWuX1vE4/s704aYjXcXu7DSBUBVrpVeb4iRMeFqnG53iDy7cUpnK5W3zni3rsk5QoNj74+3KrwtLbCh04jsn0XZWCIh4xmN4pilIPSNDyzhxzedvOJUJ4lU5Vk5rApCKioqKioq7yo6fB0k5DgOqXDKuqrHf87G/7kLV+2bU3JcQLkxX2L+AB2+drZ1bDul49YM1JI1qZuWXSrAIFrfUYJQ7aCSFJIhFXPv7v9gV/euacdOOKamdwgBbHH8A5scdwBgb2sEoNFRhFmvlFhV5ljJtRnYOZYlNC4IFXn2YYwMIyz98Ns4oznEXkxCa8YZPA5A14Kl5PgHSfR0A7CwcT9Fr79I86XXcuTDtyPGY+TvffWUDiEJeq5y/RfFhvNOaTuzJosMbSGvd79OocOILEPvNJUbf278Mwk5zlBokN29u9Pv8N57iVqsDJodRDVaBs0OMJng3ntPaV4qZy/zESqd7g5+yl9hQRDuEARhryAIewcGBuZhGiqg5AcBpy1UGuAzF5UD8NNtx6es29bQz+I8Gzk25Q98VZ7yZOVob6pLqNuttpyfazLGWs9P7jQ2Xur1Vh1CeknDskI7e1tPNBBOxReOIctgm6UgdCosK7BT2+0hkVCDpVVUVFRUVN4tNHuagakdxoRYlMI3XsTa1cKaB77Nuv/7CvbWhinblxo2YJNyuP/Q/YzGZpe10h/sp3+0L1kuBoq45NJWsv8dJghpBC1XOr+FQyrkrlfu4rh76rU9KI4pEQ1O7cylTS7dwmR+kL29kWGbi4DRgl5SbkkFQeCCRU5kGUSB5P3CooEXSOgsUHHZHJ7h20AUEXKqcQUUUcuzeAUAliMHyZeDLPvjT/AUltF05Q3480txF1dQ+PoLaYVJACnoZ81PvoG99dicTC9Xt4x9ffvItilCW7ocoXgizp+O/YkMsRKtYOLZ5mfT7+ymmxj84U+RBeU16lq0HB58EG66aU7mqnLmeTuCUN94KdjYv/1jyzuBoknjCoHuEzeWZflBWZbXyrK81uVyvY1pqMxE0gFiPn2lVwUOIx9aXcgjezvo804o0r6xdvMXVU683otzlfrZE3OEut2j5KuC0JwiCAKlTjOtk0rG3q4gBLC2JIPaLi+h6Mx2a09Qqat2zNBV4a2yrMCOLxSjTQ2WVlFRUVFRedcw0XI+P2V5xvF6pNAoh277Z+o+8mnMfZ1s/O7drPzFf2Mc7E2OEwUNa623cGzkGF965S6i8Sgno2ZgzA1zQjetHF0VHb52hkaH3u5pnRXUDNaQpV2AXrRyacY9yLKOz774uZTzk2WZuqE6tnduJ1NbgiTO/nrS3tZIq6sEs06TzAkCpavYsgI7C5xmtBoRMRFl0fArCFVXgvbsuTcQcpbgGj0OsoxUtpARvYVFXQ18Yd+jSKEghz/+JWRJeQjatfFSrN1t2Nqb0u5r4d8ewXXkAIVvvDgnc8vXLScUD+FDOV53mmY/r3W/Rm+wl5GedQjB5bzQ9uK0omjv1vcm/9/96z+oYtA7jLcjCP0FuGXs/7cAT01a/vGxbmMbAM94aZnK6Wc4cPodQgCfu2gh8YTMA682J5e91jRILCFz0aIJQchl1ZNp1qXkCEXjCfq8IQrUDmNzTmlWqiD0dkvGAFaXZBCJJ6jrnrlkyzMWtDfbDKFTYVmhGiytoqKioqLybqPF04JF40QrpgoF2bVvEpe0DC5eTccFV7L9az+l6b034Kzfz5r7v5Xi1Cg1rmeT/TO81r2Tf9nxL8QSsRmPWTNYg4hEpraU/N0vc+HXPokQiyZzhA4OHHxb5xSMnvmHW7FEjPqhepxjLiiL5OKSjH9lIDjEF17+Iq92vMq3Xv8Wlzx2KTc8cwMNI8dYaLo4ZR/PHu5Jln6diM47gnFkkKbM4mS52GS2VmXz/uWKyFfi3o0+5j17ysXGyVmKPurBHBnAbJCoy67gwq6DrOys5djVtxDIm8jY6VmzhbhWp7iETsDU30Xxq88iCyLOur3TuohOhTz9EgRE6j1vAKRtPf9Yw2MYRQe+4Sri3lWMxoK82pG+rK3PO9E8pst95t+fKnPLbNvO/wF4HagUBKFTEIRPAv8FXCYIQiNw2djPAM8BzUAT8DPgc3M+a5VZMxSIYNCKmHSzb8U5FxRnmbh6ZT6/39OWFB22NQxg1UusLslIjhMEgcV51hSHUK8nREJGdQjNA6VZJrpGRonElHC5AV8YSRRmneuTjjVjr+fe1plzhNyjijg52y5jp8KiHCs6SaSm0z3n+1ZRUVFRUVE5O2n2NGNLEyjtqtvHcMUy4nrl4WLcYKLpyhs5eu0nsPR3YelpSxlfab6UdbZbeaHtBb6x6xszto8/PHCYLG0JkqDDefQgxpFBLD0dOHXlaASJg/1vTRAKx8N86/VvsekPm9jXt2/GsQPBAT774mfp9HW+pWOdjGZPM6F4KCkIgVLudYHji9QMHubzL3+epxqfwSyXscXxeW7M+QXV5iuTY6PxBM2DfjpH0osH4/lBR+yFaQWhyVQOPk/C4ICyi2ccd9rJrgbAFWxEEARaS6rRyAmaiqppu+B9KUNjRjO9qzaTt28HYiS1M2/lk78modPR+P6bMLqHsHSnvjffCjrRTKlhI39s+AMZjmE6T+g01hvoZXvndnLFLYCGoKcEsyaLp48/nXZ/4xUfopBeXFI5t5ltl7EbZVnOk2VZK8tyoSzLv5BleUiW5UtkWa4Y+3d4bKwsy/KdsiyXy7K8TJblvfN7CiozMegPk2XWp1gxTxd3XryQcCzBz3Y0I8sy2xoGOL/CiVaT+raryrXR0OcjPpb/Ml7nqgpCc0+p06y0nh/7gh7whXFa9G8rvNtp0VOaZTppp7H5dAhpNSKL82yqQ0hFRUVFReVdgizLtHhacZwgCJn6uzAPdDOwZO2UbQaWKgG92Yf3TFm31HIVKy3X8dTxp/jvPf+NnMapEU/EqR2qwzkWKD1+827rPI4k6MjSlrO/79RzhLr8Xdz83Md57NhjiGj5wb4fpD3+OD868CN2du085TDs2VI3WAcoItBkSo0buDzzq1ye+VVuzP0VWzP/mQrTxRg19pRx/d4wCRm8o+ndVvb2RmRBpM6ch0U3vSCkiYdYOPwq4uKrQDq91Q4nJUcRhJyBsWDpZev5W8k6nr/qdhCn3mJ3brwMbShI7oHXksuyjh4kp2YPxy//CF3rtwLgqpvh1jkRZ+XP/4uVP/tPSl98AkfzEcRoJO3QDfZPImFAdD1Kl9ufsu6JxieQkTFHNgMQiUOxfjOvdb/GSGjq9XyfN4RWI1DusqRtGqRybjMfodIqZxFD/shpLxcbp9xl4f3L83no9TbeaB5W2s1XTs2Lqsq1Eoomku3Qx+tcVUFo7ikZ6zTWOtZpbNAfxml9+++P1SUZ7GsbmfHixT2eITQPghDAsgIbtV1eNVhaRUVFRUXlXUB/sJ9gLDAlUNpVq9xQpxOEwvZM3KWLyKlJ31FplfU6lpjfz++P/p4fHfzRlPUtnhZGY0GcugqEWBRLn+LQsXUookC2tpIjw/WE4+Ep207H9s7tfOQv19HsbuOSjH/hPNvHOThwkJ1dO9OOb3Y382TTkwDUD9XP+jinQu1gLXrRjE2TN2VdoWEVhYZVaITpr+e6PaN89tATXFPzt6QrfTL2tkZ8uUX4BC1m/fRVDAvcu9DGg7D01FqvnxaMGSSsBTiDitvJlu3kvlXXocnOSTt8pLyagCs/mRMkxONUPfFLglk5tF10FWF7Jp6iclx107vDnA2HyD30Oo7WBqqe+g0bvv+vXPrPN7Lhu/88JTTdqLGzwf4pIlIrTaHnkstjiRh/OvY4+foV+Hy25PJsYSNxOc7fW/8+5bi93hDZVgOFGca0AdUq5zaqIPQOZygQJst85hT1z1+8kGAkzl2PKvbZCxdlTxmz+IROY+NWRLXL2NyzwDkmCI11Ghvwh3G9jfygcdaWZDIUiKR0MDuRcYfQfHQZA1he4MAfjqVkJKmoqKioqLyrePhhKC1VHAqlpcrPKLk02zu3z1gKda7R4h0PlE4VhLLr9uLLLWLUmf7GvG/ZeuztTehHpubbCILAOtutLDJdwoOHH+SRo4+krB9vr56tq8Dc34UYjyELArZOJTMzR1dFNBFNOmxmIiEn+OGBH3LnS3eiI5OrnP9DiXEdFaat2KQc7tv/f2lfrx/svw9J1JOtraR2Fsd5KxwerCFLW4YgvLVbxXBnFx9o2cVHG15A7upIXSnL2NuaGChUuhLPVDJWOfACCZMLSre8pXnMN0LuElxjredLs0y8b1kexZmmaQYLdG64hMymOkz93RS+/gLWnjYarrmVhFa5VxuoXkNGy1GkoD/tLgreeImIycqr3/gZL9/7G/bf/mVaL/4AxsE+Kp7+3ZTxCwybMcdW4DU+Q7NbeY/u6NzBwGg/labLGfRH0GqUKgExkk+mtphn0nQb6/eGybbpyXeogtA7EVUQmmdi8QSx+Jn78lUcQqevw9iJVOZauWJJLj2eEFW5VnLtU4OiF2ZbEAU42qPkCHW5R8k06zCe5tyjdwMZJi1Wg5R0Y42XjL1dxnOEZiob84xGMWhFDNr5eV2XFqjB0ioqKioq72IefhjuuAPa2ghptNDWBnfcwfHf3ccNz97InS/dyeONj5/pWc4Z4x3GHFJhcplmNEhGU12yNCwd/cvXA5BdM7VsDBRRaJP90xQZ1vAfu/+Dl9tfTq47PHg46ZyxdrUCMFSxDFtnCyTiyWDpA7NoP/9i24s8ePhBKoxbeZ/zP7BJuco5CFpWWq6jYeQoL7aldp062H+QVzpeZqn5GgoMK2n1tsx5CHU4HqZx5FiyLO5E4gmZxAyOcFmWWXZ4OwkE4oLI4r//MWW9cbAXXdBHT67Sfn46QUgbD1I2shNxydWgmTln6Ewh5CwhI9iCmIgiCAILsy0zxnR0r99KQhQpfeUvVDz7MMMLl9C3YmNy/eCSNQhyAueR/VO2lYJ+sg/vpue8C5C1WiI2B/3L13Ps6lvoOP89ZDXWovOmXocLgkApHwdZy5d3/hvxRJzHjj2GWZNBkX41Q4FwUsDyh+MsMGzh0MBBOnypIl6vN0SuzUC+w8hIMEowMnPwusq5hSoIzTPffLqej/4svS11vpFl+YyWjI3zhUuU+uOLq6a6gwAMWg1lLgtHkg6hUfLVDmPzgiAILHCaaRkMkEgo74+303J+nIpsC1a9xMGO6UOdPcHovOQHJeeQY0EvidR0qoKQioqKisq7kK98BYJBXitZwfJ/eIRDuRX8ZaWOG0Z/Rq9viAypiB8f+MlZ0cVqLmh2N6MTTRhFR3KZs+EgYiKetlxsnEBOIQFX/rRlY6C0o7/IcRdZujLu3n43hwYOAXB4oIYs7UIEQcTa3UZCI9Gz9gI00Qjmvi6MGjsOKX9WgtCB/gNIgp7Njs8gCanXYmXGLWRoi/jhgR8RT8QB5br+e/u+j0njYIn5/Ti15cjIHBk+ctJjnQpHh48Sl+MpgdLjyLLMw7vb2HV8KM2WCh5/iItb99BSUs2fF17AoppdWDtbkuvt7UqJVXt2KQDmaR4Alw3vQEqEzs5ysXGyl6CRY2SMzi4IOmzPZLB6DcU7/4o24OPoBz8BkwQkd0kFEbM1bdlY3r4daGJRutZfMmVdz+otCHIiJZ9onExDFqHeq6gbOsx3932XnV07WWi8BF9IJhqXKck0IwC+cJRy4/kAPNf8XMo++jwhcmyGZPWG6hJ6Z6EKQvOILMu8UN9HTZdnxmyV+cIXjhGJJ3Caz5xDCGBJvp3HPrORz15UPu2YqtyJTmNdI6Pk29VysfmiJMtM21AQ92iUWEKeE0FIFAWKs0wzBs25RyM4jPMnTo4HSx9WHUIqKioqKu9G2tsBOJRbQUQr87kvLOErdxSytDnI1a7vsMnxGYZCg/y2/rdneKJzQ4unBbumIMWR4ap9k6jRjHtB1fQbCgJ9y9eT2ViLNDp9mblWNHBpxpfRCw7ufPHzNAw30ORuwjXmnLF2t+HPLcJTsgggWTbm0lZxsP/gSa/96wbryNKWIgpTBRFR0LDKcgOt3haeaX4GULKGDvTvZ6XlOrSigSyt4rCZ6xyh2sFa5Tx0UwUhbyjGSDBKQ69v2vOTDu0le9RNz+bL+fOirQT1JiqemShncrQ1EtfqaLcrjijLNA6hysHnSVjzoGjD2z2l+SNnCQDOYNOsN+nceBkAXeu34i0+4XcsahhcvBrXkf2QSK0wKXjjJbz5pXgLy6bsM5BXjDe/lLx9O6assxq0xLyryBRW8FD9QwBUmi5h0K+EUbtsesx6CX8ohkXKJldXzTPNzyZfX38oSlBzlP2h77PbrZSgdqmdxt5RqILQPNIxPEqvN8RoNJ4M1D2dDI990M+0QwjgvNJMbIbp3SGL82x0DI/iC0XHHEKqIDRfLMgy0TkSTKr7c1EyBpBrM9Drmf4LwjM6vw4hgOWFduq6PGqwtIqKiorKu4/iYgAa8pyYSn+MJ/84F79m4Lu/DmPSZJKjq6LEsJ5f1v6KodHpHR7nCs2eltT8oEQCV/0+BhevRtbMXJ7ev3w9YjyGs37m9u5GjZ3LMr9KJJbglr/dSkKOJ4USa3crvvwSAjmFxLU6bB3jOUKVeCKeZMZROmKJGEeGj5Clnf5haYlhPU5tOT8++BNCsRDf2/d97FI+i0yKQ8SkycCiyaJuaG5zhGoHazFrMjFrsqas6xlr/OIPx+jzpQ/OXrh3G16dmcCaTWhsVp5ffjnZdXvJaFLmaW9rxFu4AF8MNKKATpp6O6qPeSkd2YW45Nq0HbvOGpwVyKIWV6Bx1pv0L11L3XWfoeGa29KuH1iyFp3fm3RSAVh62nG0N9K14ZIUR9FketdsIaPlKIbh/pTlNoMECBTEbkYvminUr8YiZTPoV16/LLMOq0HCF1bKwMqMW2j1tnBo4BB/bvwzNzx7HaaSn9MyupsXOh8DIaY6hN5hnMWfsHOf3S0TX7ZnokXfUGDsg34GM4RmS1WuFYA3W4cJROIUZqiC0HxRkqW0nj8wVt41Fw4hgBy7gV7v9IKQOxjFbppfQWhpgZ1AJE7zoBosraKioqLyLuPee8Fkoqbaj8bQh6vmPeyV7mT7Lf8vOWSt7SbCsRAPHH7gDE707eOP+BkY7U8RhOztTeh9HvqXTl8uNo67dBFhi52cNO3nT8Qu5XNJ5j2EY8rDXZd2EdqAD4N7CF9+CbJGgy+/BFvnWKexsRyhg/0Hp91ni6eFUDyUtixrHEEQWG29kZ5AN3e+dCfNnuOstn4UUZhw1GRqy6gdmF4QkmWZR44+wqMNj/J69+t0+buSJWjTUTNQO61Q1e0OIYkCggDNA1ODj7UBL0taDrC3Yh2yTofNqOXZhVsI2TJY9PRDCPE4to7jeIorCITjWPRSauaOnMAUGWRZ75/RyLGzu1wMQKNFdi4iayxYelaIGjq2vJeo2Zp29eDilciCmFI2VvDGSyREDd1rL5x2tz2rlXKv3P2p3emMWg0aUSAcsvIB53e4IOMLynH8YRwmLVqNiFUv4QspgtAC4yY0gsQtf72Fr+36GsPBMKPdH2K59guEEyEkU4sqCL3DODsTut4h7G4ZTv6/2z2aDL09XYxbAc9kl7HZUjXWaeylI4qqrTqE5o/SsU5jb469P+dKEMqzGRgORAjH4uilqU/mvKfJIQRQ2+VhYbZlXo+loqKioqJyVnHTTQAMjfwO64iVr764l0++9yIeKati3dgQu1TAItOlPNrwKB9b/DGKbcVnbr5vg1ZvKwCOSYKQq24vsiAyWL365DsQNfQvO4/cA7sQYlFkaebrk2zdIi7J+Bd6I3UYNXYs3UpZlb+gFABvUTl5e7dDIoFdKsAgWjnQf4BrK65Nu7/xsiznDA4hgAL9SnJ11ezp3UO2roJSQ2r5lFNbzgHfXvwRPxbd1OueQ/2H+fbub6cskwSJImsx/7bxq5yXmxq+7Y14afO1stq6kXT0eBQXf0KWaR4IsKncmbLe9cYraBNxjq25mFLAZtByzBPi+HtvYMkj97PgxSfQRCN4SioIhGOYdRoW9z/Lsr4nsUX6MYX7FSEISGSUIRbM4rU8w4g5S8g+9uqc7S9qtuEuXYSrfh9N7/soQjxG/pvbGFi6lqh1+nvJUWcu7pIK8vbvpPXSifedIAhjgk8Uq5SXXD44KUfUYpA4PhhAlmX0ooUl5g/gjnVQbb4Sz3AJz3v6KTbmUBeTsGU2nRGjg8r8oTqE5pE9LcOsHeu+dCaU1KGzqGTsZOTbDdgMEi8fVQWh+aY0S+kmsLdVEYTmqmQsZ6yDXL83vYXYPRrFMc+C0EKXBYNW5LAaLK2ioqKi8i6k7+oriVu6Mdi2cPg7D1DuMrO3bRh/eKIr0ErrdYhouW//fSnbRuNRfn/k93zoLx9mW8e20zzzU2O8w5j9BEHIvaCSqFl5yLiu9QEubPrvaffRv2w92lCQzMbaWR2zwLCCNbaPAkq5GIAnt4RAOIa3sBxtKIhxqA9BEHBpK9nfN32wdN1QHTrRiF3Kn/GYgiCw1vYxJMHAWuvHp3SwyjpJsPSTx15AlkUWhL7Oe7O+yWb7Z1lsfj8DAR9f3/UNovHUSIvxPCJXmg5j4VicIX+EPLuBMqeZoUAEdzAyMUCWKdj1Ag2OIqSFyvY2o0Q4luD4eRcTcOWx8LnfK7+3kkX4I4ogtKnjQfIZwFpxPprNX4ArvwM3/AHxtuemLY86q8hZgiXchz7mTbvaGu495V0OLFmLvb0JnXcEZ/1+9D43nRumhkmfSM/qLdg7jmPq70qdg0HCG5r4GxCJJfCMRnGO3SNaDVriCZnRqOIeW2u7iUsz/5V8/XKCESXLyGGwkKNbAqYG1SH0DkMVhOaJHs8o7cNBrliai14Sz0zJ2FhtaOY54BASBIGqPBs9Yxk0apex+SNzrFa42xNCJ4ljtcVvn1yb8pr1pMkRisQSBCPxeXcISRqR6jwbtWqwtIqKiorKu5BnG19FEBLkaVcBcP5CJ4kE7Do+mBxj0mSwxHwVz7c9T81AjdIEpe0Frn7yav5zz3/S5uniH175R55tfvZMncZJafG0IKJJtmrXe4axdxxPdheTZZmy7qdY2fc4krc97T6GKlcQ0+nJnqHb2HRYu1qJmK285obfvN7KcMECYCJYOkdXRbuvjeHQcNrtawdryZLKEIST34pl6yq5Ofd35Oqrp6wbdxhNFyz9Wvd24sEShkcyydMvpdJ8KefZbmaj/XY6fO080vDIlHkBOHXKfs097eg9SgRGryeEDOTZDZS7FDdS88BEib6tvYms/g5eKD2PnLFrQvtYfqgnAo3v+yhiIkHUaCboyiMQjlGuHcAW6kY4/0vwoZ/Bpd+AdbdD1ZVgm3CznNXkLAXAGZgaLF3g2cen9l5FVf9fT2mXA0vWAOCq30/BGy8RttoZrF5z0u16V5+PLAhTwqWtBi2+8IT4NxxQhLzxh8Ljwd6+0NR28v5wDK1GyXoq1K8iKvbS7u08pfNRObtRBaF5Ys9YOc6GsiwKHEa6z0Aa+1AggtUgpS3fORtZPJYjpNOIZ7wz2jsZQRAozVLKxlwW/ZSnTW+VvDGHULocIc+o8iXkmOcMIYBlBXbWhPr4AAAgAElEQVRquz3E1WBpFRUVFZV3GTs6dyDHjRSaKgFwmHSsLHZwpMdH36Tv52WWqzFp7Pz7G9/mY8/dzF3b7sIfhssyv8x12T8lR7eYe3bcwyNHH5nuUGeUZk8zNik3maczHg7dPyYIDfV3kycPICJjr3uIaDwxZR8JnZ7BqlXk1OyBU+wGbO1pw5dfSmO/n2hcpsWaQ0LUJIOlZ8oRisajHBs5NiU/SJZlmgf8PF/bQziamvMz3bWaUWPHonGmDZbu9nfTG2oh5l9MrzeUcl1UqF9NgX4FPzl4P57wxEO02sFa7FI+etGCGAmz8Tv/xIVfv4OlD/+QaIviysq1G7AZtTgtOo5PyhEqfP0FwhottZUb0GqUW0zr2INAbyhK76rzcZdUMFSxjEhcaXm+PjH2+ynfmvb8zglyFKEuXaextV1Kd7UNXb8Eeep7cDp8BQsI2TPJ3/My2bVv0r32ImTNyR/ghh1ZjJRXK4LQpPe01SARCMeT74HxQOlxQcg69nB4spNwnEA4lhSMigxKCd9w4rB6nf0OQhWE5ok3moex6iUW59koyDCeEYfQoD88Z+VAp4PxHKE8hwFRPAcsoucw4zlCzjnKD4KJkrG+NA6hcUHINs8OIYBlhQ6CkTgtg1PDDlVUVFRUVN6pJOQEde49xPyLyDRNlN6fV5qBUath+7GBZCtprWhkheU6jgzXc3yknc32z3K187sUGdagFY1clvllCg2r+fbub/Pzmp+fqVOalmZ3C7aUcrF9jGY48eeXIMsywda9AIwa83h//EVeqmknkUb06V++HoN7CFvH7NuGk0hg6W5jKKc4mdfZN5rAn1ecDJZ26srRCFJaQeiY+xjRRJQs3UR+0Eggwl8OdGJ75Nd845d3MVKbvgQsHVnacuoGpzqExsv+Yv7FxBJyUgQARWA6z3YL/qifnx76aXL54YGaZKB0xvF6pEiYocoV5O3bzud+81X+fd9vyR77XZW7LPR4QgQjMcRImLx9O3itYDkZ2ZnJ/Y270L2jURBF9nzxXg7d+k8EIorwsDJygIS9GDKntlI/Z7DmkTBkTHEIZQRbKRvZCfmryQi2UjH0yuz3KQgMVK8hq7EWMRGna8PsBbOeNVuw9HVi6W6bmOIJgs+AP4xOM1ElcDKHkHlsvU2Tjx4Xgqkh5f2kcm6jCkLzxO6WIdaWZqARBfLtxjOWIXQuBEqPM95prEDND5p3xnOEXHMoGFr1EiadJm3JmGdUuWBymOb//bhsLLxdzRFSUVFRUXk3cXT4KKMJN5pQVUorb72kYWNZFt2eUIpjvcp0OZdnfpVrXT+i0nwpojDhKJcEPZdk3E2Z8Xzu238fP9j3g6SYdKaJJqJ0+NpTAqUdbccYXrgUBIHOkVGKRo8iI2D8wHfIFPwsGXmJnY2DU/Y1sGQtsiCSPYtuY+OYhvqQImEazdmA0jp9wBfGW1SmOIRkGUnQkaUtZ3//1ByhukHFzePSLiQci7OjcYCnttdz+3M/5GMNL2CJjlK54+lZzydLW0a7rw1fxJeyfFvHq4ixbGwaJafoxOuzTG0JFaat/OHoH2j1tNIf7GdgtB/XmHMpq+EQCY3EwU/czSvf+BmPVV1KdX8TG793N1v+/bN8bPtvuax1N56GRnIPvIY2FORvxeuSjnFQOlxpNUIyvyah0yNrtQTCMTTEWRw6iFh+8bmRFTQdgoCQU43rBIfQqp4/Imv0cOMfSGQuZH3Xr07JiTZeNuYpKsefXzrr7XpXbCIhiillY9ax0j1fSHlAO+gPk2XRKVUDLz9F+eGdaEQBfxpBaLJDSBAEnOJyNOYmWofV6+x3CqogNA8M+MI0DwRYX5YFKAHJ/b4w4djMbR7nmqFA+JwIlB5nUY4VQVADpU8HyZKxOXQICYJArt2QYkkfZ9whNN8ZQgDlLjNGrYYaNUdIRUVFReVdxI5O5QbQIi+dsm5RrgVRgJahicwXQRApNKxCK6bPbRQFiQscX6TSdDm/qP0Fr3ScgsNhHunydRGTY8lAaW3Aq7SAH8vx2dM6zGqpmUTmQqh6H4msCj5teoUDHW4Od7pT9hW12Bgpr6Zw90tYO1tmdXzLWKD0Aa2LLIuOPLuBAX8Yb2E5er8HvVvJ3MnWVlI/VEc4nuqkqBuqwyhaiUcy+O3rbfgPHeb+7fexYvA4tTfcye5lF7H2+JsII+nzh05kPEfoyNCEqygQDfBm35vEfFUUZRix6KW0D6dXW29Ag47v7fv+pPygCUHIvaCKuN5Aj2Dk11Xv4VdfuI/6j9yBP6eQ4qP7+NLBx7jtwX9l2cP/x7Ajh5qsshRBSBAEbAat4hCahD8cY4VwHEMicG6Xi40h5CxVSsbGysIMUTdL+p+F5deDNRdxy5dw+Rsode+a9T6HKlcQcmTRevEHTmkuUatdcXXtnygbG3cI+UIxZFlm0B/BadFj7mmn8slfUf34z8nUJJKC0TiyLBMIx5MOIYAC/SoEMcquztmLqCpnN6ogNA+M5wetW6BYJscDkvs8p9daNxyIkHUOlYyZ9RL/77JFXLe26ExP5R1PqXPcITS3gmGuzUCPZ+oFhzs4liF0GgQhSSNSnW+jRnUIqaioqKi8i9jRtRM5VEimIXPKOr2kIc9upG2SIDQbREHDBvsnENFQM1gzV1N9WzR7lJyecUHI2tkKgK+glG73KJ0jQVZJLWgK14AgIK67ncpYA+/J6GFbwwCtg6m/g4arPw6JBBu/+0+UvPwUJGbOerF2tSELAvtwUO604LLoGfRHcBcqZU+Tg6WjieiUwOeagVoyteW0DwW48NhrfG/nTzDoJHbf9V90br6cjouvQpuI43hxdi6hdMHSu7p3EUtECXmryDDpyHcY0jq4TZoMllqu4ZWOl3mo/iEERLK0C9D6vdg7mxmsXAGQvLZzZmfQfsH7OHDHV3j5Px/iuzd9m/tWX0f7hkt5dMOHsRq1STfKODajFu8JQkMwHGeLWIOMAAsumNV5ntXkVKONj2IPdwOwvPcJpEQIYePnlPXLriNhK2B95+xdQnGDiW3//kt6zrvolKfTu3oLpqE+7G2NgOLiB0UQ8oVjRGIJnBYdC//6R2RRgy7g49LO/fhOyBAKRRPEZTnpEAJYYFmOnNCwf+CNU56XytmJKgjNA3tahjDpNMnSlfESqE538LTNIZ6QFUHoHCoZA/j81oqkkKYyfyx0WTFqNZRnW+Z0v4pDaKrweTodQgArCh3UdHkYjZxeV56KioqKisqZwBP2cHjgMBFfJQ5j+mu/0iwTg/5I2rKQmdAIWuzafI6NHJuLqb5txlvOj5eM2bqUn70FC9jTMkyp1oM9PgIFSgAuK25AlozcadmG06LnmZoeGvsnyqs8pZW8ds//MbB4NYv//EvW3v9N9J7p3TnW7lbcGTmEJB1lLjMuq554QqY9Ix9ZEKYESx+YVDY2GhvluOc4Tu1Cco8e4IsH/8RwxTJ23f1dvMVKq3ZLeRl786qpfvMFhGh06gROwKCxYZWyU4Klt3VsQyeYiQdLcJi05NmN+MOxKQ4QgKWWq7BonOzt20umtgRJ0JN17DCguFRAKTcz6TSpnWkFAduicv5WvI6nL72Vl+wVKe6gcWwGCe9oLKXk0B+JcYGmBjl/FZjeAdf9kzqNaRIRVvU+hlx+KWQvVtZLOsTN/0i+9xAF3v3zPp2+5etJSBLF25VOgZJGxKjV4AtFk9k/i3w95B14jeZLr8VTVM7lR7fhS+PkAjDrJspJzVoz8mgZTf69834eKqcHVRCaB3a3DLOmJCOZsD9eAjVfncZqOj3c/IvdbD82kFzmDkZIyJxzgpDK6cFu0rLrX7dy1fL8Od1vrk0pGUuc0Hlg3CF0OkKlAS6uchGOJdjZNDUvQEVFRUVF5Z3Gru5dyCSI+Sun7ehZMlYu3jp8ai4hAIdUTOPIKQQvzyMtnhbMmkx0onI+1q4WQvZMOhJ62oaDXO3qVQbmjwlCBjvCiuupHnqeG5dZybbqea6mlwPtI8l9Ri02Dtz+Zequ/ywZx+vZ/J9fxFWb/obX2t1Kqz0Pi15iffRN7u7/FzTE6Y0IBLILksHSRo0du5TPgb4JQahhuIGEHMepLae4pZaIRsv+T3+FqNmWHCOKAnvXXIZ11EfOCe3DpyNTWkDtWDZRPBHn1Y7t2ORlgIYMky4p1KS7F5EEPWusNwEkO59lHTtM1GDCW7xwbLtR8uyGKd3O8h1G9JLIoU43/nCMPPvU2AebUUskniAcm3BeySEPK8QmxHdAuRgALkX8cwYaqRx8HlNkEGHTnaljVt9MwuRifeev5306MZOFlouvoeDNbWQfUpw8NqOELxRLBqGv3/44UaOZ1q1X03bRVeSO9FDZWZ8Svh4YE4QshtQOZ9pINf5EN13+rnk/F5X5RxWE5hh3MMLRXh/rSifU7jzH+B/h+QmWfqammx2Ng3z8l3u4/bd7aR8KMhRQPuznUsmYyuklw6yb825uuXaD0skikOoS8oxGsRokNKepe9z6BVlY9RIv1PeeluOpqKioqJwFPPwwlJaCKCr/PvzwmZ7RaWNH5w60WEiECqctz3ZadFj0Em2D0zvWZVmmYzg4pSNXplRCT6CbQPTUxaS5IJaI8Wbvm/z3nv/m5faXk0HJANauVnwFC9jTOoxBEtlgaEMWJcidlKV03qeQEmFWj/yVa1cVUO4ys71xkFcndV5DEOg4/wp23f19QhlOVv3iPzEN9KTMQxMOYRrspd6QTZnLzJKB51jo38tyTeukYOnjyfHZ2koO9B9MHmPcxePSLaSo5zitWcXI0tTXK77qPNqsORS+/NSsSoyc2oV0+jvwRrwcHjyMJ+JGH1mGICiCjMuiRxKFtGX9AGXG81lh+TBV5ssBJT9ouGIZskZDIBzDG4qlzfjUiAILnGY6R5T95qd1CI21np/kPqkcPYREAsovPum5nRPoLSQcC3AFm1jT/TAJ12IoO+HctEbETXdS4n6DHN+Emws5QZF7Dxc1fwdb6CQCiyyzoudRcn21J51S05U34CkqZ+kffoTeM4xVr8UXijHkC7Mq0E1e7Zu0br2amMlCz+rz8ZvtXNO0PSkCwWSHUKogZE0on62dnTtPOg+Vsx9VEJpjxvODxgOlQanbdln18yYIHe3xUZFt4V/fW8WupkEu/d6r/O/fGwDOqVBplXOfXFv6vCzPaHTaJ5bzgU4SubgqmxeP9BNPnB1dUVRUVFRU5pGHH4Y77oC2NuUGuq1N+fkcEIWeaX6G656+7i0/bU/ICXZ07cQcXwKI2Kf5vtWOBijJMtE+HJz2u7FlMMATB7qo6/amLM/QFgPQONL4lub4VtnXt497dtzDBX+8kE/8/RP84egj2MUKVlmvB0CIRbH0dtDnKqJlMMDKYgf5wSPIrsWgnSRg5C5DLlrPyr4/IYlw5bI8VhY5ONjh5rmaXmLxCfdKILeQfZ/5GglJS9UTv0iZj6WnHUGWOW7No9xppsinlP9coj9Kv08Jlja6h9D6lBzDbF0VnoibVm8rALWDtZg1mVgSFkqGO+jMKycdxVlmnl64BWdPKxnHp7aUPxGnVskvOjJ0hG0d2xDREPUvwm7QohEFRFFp/JEuRwiUgPE1thvJ0pZhHOzFNNibUi4GpC0HAyhzKU4tSRRwpnkQnWw9P6lUcXX0ACHBAIXrTnpu5wpC7hIWjOzEGWhC3PT59J3T1n6ShN7Ous5fYwn3sa7jF3xy/7V8uO5OVvU8wrqTuIeyAw1sbf5frq+5neq+v8w4Vpa0HP74XWgiYZY+/H9Y9Rp84SgD/jA3HfkbEbOV1guvSo6tW3c5a/sb0HS0JvcRmFQytuip31D+3B8BcGgLkKOZ7OianYMtHX9v/Tv/+Mo/Ek+o8Q5nGlUQmmP2tAyjk0SWF9pTluc7jHTNlyDU62VZgZ3PXFjOy/90Ee9fnscL9X0Aaf8wq6jMF7ljFwu9J3Qa84xGT1t+0DiXL8lhOBBhX9vIyQerqKioqJzbfOUrEAzyxav+iWcrNyvLgkFl+VnO692vc2T4CLf+9VY6fB2nvH39UD3u8Aia8GKMWg16STNlTPGrz7D1nps539NMJJ6gdxph4GCH0oWr/kRBSBoThNynVxC6Z8eXeaH1FbKlVWzN+Cc+mvMrLs/6Crn6agAsvZ2I8Rh7JSc6jcjKAju5/iOI4/lBkxDOux3HaAfF7j2IgsCFi1xsqXDSNODnmZpUJ1DYnknTFdeTXfsmzrqJ0jHrWIexrsx8lhn6MUaUB8GbxHoGfWE8aYKlAQ72HwSgdrCOLG05lvbjSIk4fUUVac9bqxFpWrEFn85Eybb0N/5a/8RrlKVThKW6oTpe6dhGrr4ab0BKeRiXbzcy4A8Tic0cmp3VkJof1O0ZRSMK03amLck0oxkTnNI5z8fjAsYdQrIss04+RLttNUjvnAfXQs4SpESEhDkbln0k/SCDDXHDZ1g4vI1P7f0Am9t/ijW3DK79OfLSD1M5+AJSfPqIkSV9f0HWGBBKNvGepn/ngpbvI8jTZ4IFcgs5es1tuI4c4KIj24jGZfI6jrGks56WS68lbjQlx7Zveg9hUaJix7PJZf5wDKNWw+JnHqLsxSdY8NITiNEINoOWqG8Rb/TsJhKPnPLvSpZlfnroAV5qf4m/tv71lLdXmVtUQWiO2d0yzKoiBwZt6pdxgcMwL4LQcCBCnzdMVZ4VgBybge9dv5LHP7uJf35PJQtdcxsarKIyE+MOod4TLMnuYGTakMv54sJFLrQaQS0bU1FRUXk30N5OSNLxl+qLeGLpJSnLz3bavR3YNLm4QwFu/etttHnb0o6LxCNpXUQ7OncgIBD2VqR149pbGqh64peIiQQX7vgTIjKtabqNDfnDdIyMYjdq6fWGGA5M3OhZNC50gpGm05gjlJATDAT7qTS9hwszvkipcSNaMbVsyToWKL1bzGRxnpXseA/6mG8iUHoy1R8gYXKxsvfR5KLVxRlsKs+ibSiYDNsdp+3C9+PPLmDx4z9Phjubu9sY1egwFRdR7BvLBlp4GUvj9cRjEbqzFeFsvGzMLuVjEK0c6D+AP+KnzduKU1uOuUlx/YyUVk57/kV5GTxXsoHsw7sxDvVNnHNnC2t+8k0uuedmnEcUh5JBtGKTcni+9XlaPM0U6tcwEoyQYZq49sqzG5Bl6PPOnGma1XCQkCOLQI4S2t3jDpFj1SOJ6W8bdZLIJVXZbFiQlbJckGMgy+glEZ1GTHYaMwY7WSD0MpC9ecZ5nHPkLAFAXHc7SDM8kF//GeSFlyFs+RJ88QDCrc/A8o8grL0NXTzAwqGX026mSYRZPPg3qL4K4eY/I6/7NGu6f8819Xcp7/lp6NjyXvqr17D11Ucp9vZy85G/ETTbaN9yZco4XVYmLxetoapmJ9qAIjYGInE+2LKTshefwF26CCkSJrOpFqtBSyxQSTgeYm/fqYdL1w/X0+RuRETip4ceUF1CZxhVEJpDfKEodd0e1qfpkpVvN9LtHk1J2J8LjvYqH9iqXFvK8jUlGdx58cI5z4hRUZmJrLEa9bPBIWQ1aNlU7uT5+r45/9ypqKioqJxlFBfTbXUCcDBvEfKk5Wc77b52cvTVXJH1DXzhUW75663J1uoAQ6ND3H/ofi770+Vc8fgV3PjsR3mm+RmiceUGe3vndly6CnxB/RRBSBvwsvJX/0Mow8nRD36CjPYmrvA2pRWEDnV60IgCVy3LRRRSXUKCIOLQFnHsNJaMucNuYnIMk5gx7RhbVwtRSUe7yUmZy0Kuf6y8Kj+NICTpEdfeRtnwTjKCrcnFS/Jtyvn2pLqiZEnL0Q9/CvNAD6WvPAWAvq2ZVlseC7KtFHr2k7DkwJpb0clhVgpN9MQkglk5SYeQIIi4tIvY33eAI8NHkJFxahdiaz5KjykTjdM57bktcJp5pmwTMgLF25/DONjH8t98j03/8yXsbceI6fTk7n8tOT5TKktmFDmFVcQScsr7YdzFPV3ZGACJBFnHDjO0aAUIArF4gn5fiLw0+UGTWZxnoyBjYowh6ubmgx/j+to70McD2IxSsuNs3tBuAEaL3gHt5iez8FK44G5Y/5mZx5kyET72J7jka5BZNrG8ZDMJRylL+59Ju1n50KvoYz6ElTeBRkK48n/gqvso8b7JjYc/MX3+kCBQe9MXieqN3LvrZ6wcPM6RrdcS16eWAOokkWcWXYA2FqVo598BqG7Yw017n6B3+Qbe/Py3iGt1OOv2YTVIxAPliEjs7Dr1HKEnG59EI2jZaP8Ubd5Wnm97/pT3oTJ3qILQHLK3bYSEnJofNE5BhpFQNMFI8OTtI0+Foz2KIjzuEFJROZNoRIFsq37KxYZnNDptpsF8cll1Dm1DQRr7/af92CoqKioqp5F776UruwiAIbODTls2mExw771neGIzE4wGGQ4NYdPkkakt5YqsbzIajXHrX2/jpfaX+NprX+OyP13OTw7+BJNczBrrTXS4h7hnxz1c9qfLuW//fdQN1ZGnXYk/HEt14yYSLP/tD9D73Bz8xN20Xfh+Aq48rqt5jiFfKBkYCxCOxjnS4+U9iT4+9F+f4YPeBo70elOyhhxSMcdGjp22hywDQaV7rkkzvSBk7WqlOzMfrVaiwGEkx1+PrDFMtPs+kXV3gEbPmq7fJReZdBILnGaO9vimZCsNLl5N37L1lP/9MfQjgzh622iz51GSaaTItx+x9Hwo3YyMwCaxTskRKipLCkKg5Ai1+VqTeStOqQxXeyNHM0uwGqa/NjLpJHR5uewpXknxjufY8u3PkXPodVou+SDbv/4AA0vX4arbCwmlBMypVcrGMrSFRMPKw+kMkw5NOITeM4zdP8Ii2U+kowPDcH/asGprVyu6gI/BKqVcrM8XJiGnD4ueDik+ygePfInMcCd5/lo+VP958vRhfGMZQqXu3fTImZjyp3mNzlV0Ztj6FTDYTj42HYKAuOomijxvphV3lvY/TcJWCAsunFi45laEj/8Fe2yATW33T7vriM3Bges/hzPkYdBgZ+CiK6eMEQQBt6uIIwWLKd7xHFlHDvDp135La145h2+5i7jeyFDFMlx1e7HqNSDrsMiV7Ox6Lc0RpyccD/Ns83MUG9axyHQJGdoi7j/0UxLyzKWMKvOHKgjNIXtahpFEgdXFU7+4JlrPz23Z2NFeL1lmHS41K0jlLCHHbkixI8uyfEYcQqAIQgDP16UvGxsORNh+bOB0TklFRUVFZT646Sa67/x/yR8PLt8MDz4IN910Bid1csYzg6yS8n2VoS3misxvEonJ/OMr/8jTx5+j3HAx17ru4/Ksr7LCeq3y/8yvYpSL+HnNz5GRsbMcIMURUvbC47jq93HkQ5/CW7wQWaOh6cobyRno4Pzuw7RNcgnV9Xgxj3r55Ms/w+Ad4ZbtvyVnoCNlTIZUjDfiYXB08HT8augP9gNg0kx13gMgy1g7W2gw51LqHMux8R+B3GWgmeaaw+JCWP0xqgefwxye+P6vzrcxGo2ndU4dvfYTCIk4y373A0yhAO68YrJjPcr2JZvBmIGct4ILtPVKp7HCcswDPclg6fEcocePPY5NysbhjWDxj3AkswTrCe28T6TcZeHhBRcQ10h0rd/K9q/9lGNX30LMZKF/6Vr0Pjf2dqWML0unuE0K9Wtxjz2Azo36uPjLt3DxV2/j4q99kvue+gbffuxrXPT126l+5P4polBWg5J1NLxIeT+NdyXLnaUgJMgx3tfwZXL89Qgf/iXCdb8lJ3CM74W/SWLUDYkYiwL72BFfRk6aFvXvelbciIxAdf+zKYst4V6K3bsRV92kdFGcTOlmxKUfpNz9GprE9Hk+npUbuG/1dTxw4W2gS3/faDVIPFd5IQbPMGvv/xZdZiePXvMPJMbGDyxZi3mwl2xvP4IAuthCWjzNuEPuWZ/ito5t+KJeFhm3IggiKywfocXTrLqEziCqIDSH1HZ5WF5ox6ibGuZXMCYIzXWO0NFeH1V5VoR0SfYqKmeAPLshJawyGIkTjcvTtsGdT3JsBlYUOZIh65OJJ2Q+/dBePv7LPdR1e0773FRUVFRU5pauqhWIAuglkYP/8u2zXgwC6PR1AmDT5CaXObSFXJl1Lxvtt3N9zgNsctyBQ1uYXC8IIoWGVVye9VU+lP1DtmbcDWHFHTX+8CXz2GEqnv093WsvoGPzFclte1afjy+vmFuOPk/HgOIyT8gyNe0j/NvBP6IfDbD3c18nZrLw9d2/pq2lO7lt5mnuNDYwOuYQmqZkTO8eQhf00TjW8UuQ42QHjiKkyw+azMbPI8pxVvf8IbmoNNOMSaeZEqYNMOrMpeXSD+I8VgOAvGAhhd79YxueD4C44AKW04jP72VgyVoAcg/tAsCpU0prvBEvmVI5jpYjABzPXoBWM/OtWJnTzHFHId/9wk+ou/FOwo6JKoTB6tXIgoir7k1AEZ4qjFupMl3OSDCCJApU1LyGFAlx9JrbqL3hTv7+vk/x3dXX07juUopf+zsLXnwi5XjOhkP48ooJ2xURrscdwmHUYtLNLFwpvxiZS5r+i7KRnQhXfgcWvx+q3odw/UMsiLfwa+k/yBnajSnhY2diGTm22buO3jU4iqDsIpYOPAOTHDPV/c8iIMPKj6bfrvoadDE/xe490+5aEATqV15EZPHyacdYDBKvZ1Xgyytm1JbBv228Hck+0ShpcMkaALLr9mHRSxBSRMj9/ftnfYpPNj6JRZNFnn4ZAKWGDTikAn568AHVJXSGUAWhOeQ3t63jwY+vTbtu3CHUNZJeEHrojTau+fFrROOz/yDEEzINvb4p+UEqKmeSHFuqIDReM34mHEIAl1fncKjTM6Wjyi92NvNm6wiiAL/Z1XpG5qaioqKiMnd0u0fJsRlYWmBPdss625lwCOWmLLdKOSw2X4FenDkSwC7lU2pcj3tUcQY4TFp0Xjcrfv1dAjn51N3wudT216KGppaQxPcAACAASURBVCs/SoGvn9JDO0kkZFoHA7zv4HMs6Wmg/iN3MLh4NQduv4fMsJcb//YAo6NK2HKGVAKcvk5j4yVjxmlKxmxdrQC0OgooyTKTGWxBGx9NHyg9mcwFsOSDLO99IhnGK4oCi3NttAwFkq22J9N82YdxWxWRxFxVqeQHmVzgXKQMWHAhWmJURuoZyC7Cn1tI3j6lREwS9DjH3DtO7UIcLQ1ENFqGc0pO+jtwmHRkmXU0D0x1LkXNNkbKqsiufTN5nC0Zd2KVchgJRnAYJQr2bMNdWknrJdfQuflyhi94Dy8Wn8dTF3+MntVbqPzLb8ndr2TAiNEIGcfrk93FovEE3e5R8hwTwo19tJObDt3MLQeuZ3Pbj8n11SSFi40dD7Ks/ym44J/hvE9OTLTyvRze/COqhHY+0ng3APukFYqgoDIFYdXHsIZ6KPLsUxbICZb2P4NcugUyStNvtOBCEnobFUMvzbjvD64qYGP51GiTcax6iUBUZtcX/p0nvvC/DJocmCe9TqNZOfhyi3DVKzlCYX8BGkHiQP+BWZ1bX6CPXd27KDdehCgoBgpR0LDC8hGOe5p4qX3m+avMD6ogNIeIojBtm/cMkxaDVpy2ZOzpg90c7HDz5/3TBIKloXUoQDiWoCpXzQ9SOXvItRkIROL4xrpJjNuW03U+OR28Z4liw3/hyIRL6Fifj+/8/RiXVedww7pinjrYndJNRUVFRUXl3KPbPUq+w8jKIge1XZ5Tesh2pmj3taMXrfx/9s47PI7yXN/3zPa+6lr1Lkuy5F5wA2NjIODQW4AAoSTnl0IaIQlpkJB6TnJSyYEUEiChOWAgNIMxYAzGvUuyeteu2q5Wu6stM78/RsWyiuUGhsx9Xb58eco334zk3Zln3vd5mrpObq7eQGQkcj7njfXoBnzs/szdxAzj23I6Zy3GnZrNNQdeoaPXT3jru3yq6jWaF66kdfFqAHzZhWy7/LPM9tSQ/sRDABg1diyauA+0Qsgk2tAIE98/2IZ8eiLZeei1IilTGUofhbD0TvSxAco7RitkStPsyDJUdYxPbGoLyfx49jW8OvdC9HFOMn07EXKWjIptWYuRBC1niQfw+MO0z11OXO1BDL1Ke12yTmkbS9Tn46yvojYhG7Np/DNDsv8Q59b+FENktHI5P8lKa1+QYGR8EpNn5gLsLfUjxxmmLxBhZtCNrb2R1oUrR5Y7TTpMOg1tvkH23fAlevNKKH/kf3HWHcJZX4kmEh4RhHY29RKKSpS5lAqRJH8V1+2/lcSYm7ikNBa0PsJ1ez/DZ7dfxNpDX2dx85+QZ98AK+8ZN09T2Sf4bOSriAI0GQrR25Mn/LmoADMuQjLYKXM/B0C6bxeOUAvCnBsn30erRyi+kIKetxClyWPoj4V1qIWxV2OmV1D8yI4W7jxl84mvOUCiGMMfUkTO7Z07pjX+83XPIyFRaF6JNxihulP5v5ZrWoJTm84Du1UvoQ8DVRD6gBAEgTSniTbveEEoFImNvMn6/aYaotO8gRk2lC5xqRVCKmcOw33mwz5CwxVC9g+pQig/yUpuomXERygSk/jqk7uxGrX85PJybl6Sw2BU4vFtZ340sYqKiorK5LQeIQgNRqUJH+zPNJr7m4kNxvPivo6RFyknQl8ggtOsQzMYImPLq7grFuN3TZKwJgjUXnwDrkAPrvX/4JY3/oonMZ1D1/zXmGoi34o1vFpyDgt3bCDtPeXNvUObdVxJY7Is85udv+G52ueO+0HPHXBjmsw/CDA01dJuTiA9XUnqSvEfQtJbIaHg2IO7ZiHnrWRe++NoJKUCKt6iJ9Vu5EC7b4xxdjQm8eqBDurTignecDv2UBu2wQ6E7GVHTMZK1DWXJeJBPP5B2uetQJBlXLsUw90803LSDbNIkbOxt9RxIC5rrH+QLDOr/Umu3XcrszrWsbDl4ZFVOYlmZKClNzD+Gs1cAEDygdHo75gk4w1FWNawDUmjpWPuaLy7IAi4HEba+0JIOj07b/82obhE5j70YzK2bEASRXoKyvCHomxv6KUgyUp6nInMvm1cvf+zGIxmxM+8gnDLvxHuqoHLH8JUsIy8/u3IRRcirP312Iq0ITLiTGySZvP0/Mf4b9s3Sbap3qeTojMhll9FYfcb6KN+ZnY+j6S3QcnaKXcTSi/FEPWR4T3+GPhhhk3O/YNRBgYVAdJiGGuF0lU2DzEWZZa7Gv9glGRdCYe6DxKIjP/9PBJZlnnm8LOk6kuxa128V9fNS/s7qPP4EQUNFdYrONxXzRvNb5zw/FVOjBMWhARBKBYEYfcRf3yCIHxZEIQfCILQesTy8Tbm/6GkO0209o2Petzd3Ec4JnHN/EwauwM8t6dtgr3HU9nhQyMKFCRbT/VUVVROmFT72FhT73AZ+5HJJx8ggiCwpjSF9+q68YUi/HZjDftbffz4spkkWg0UpdhYkp/Ao+82TluMVVFRUVE5s5Akmfa+EGlOI7MznQDs+gi0jdX1NRIMKPM93HniiZh9wQhOkw7X9jfRB/w0nDP1w6O3YgE1SblcuOtFdFKUPbd+Y8Q49kj2XPxpdicWUPbEA1jam4jTZlLbV0tMGl+tMhE73Tt5aN9D3LP5Hm548caRWPTp4A64MU0ROW9trqfWkUZeogUAl/8ggmv2eNPdSRCWfRlzuIsS94sjy0rT7PQMhOn0DY4s21LbTW8gwuqSZAw6zRH+QUvHjKcvOIcKsZYBXw+B5DS8mfm4drwFQKI+j/MTvkdCawuiFGO/czRhTB/1c1HVtzm37heI+ecil3yS2R1PYRlUTLWTrAZEAdxHzGmYgZQMAompJA21jQH4QhGEWIzZVVtxl80nYhn74tjlNNIXjBAIR4lY7ez43PdAlknb8Rbe7CJiRjNbaruQZVhWmEhh12tcduhOtPFZiLdtgKShNjlzPFRcjXD13xC/1Yxw3T9BM3EbmM2ow2nWsXfQxZ5gguofdCzmXI9WGmRm57MU9WxELL8C9Oap98k/F0lnoegYbWNTMSxS9oei+AejiAKYdGMFod68EiJGM2VN+5FkcArFxOQY+7r2TTn2Hs8emvobKTCfgyzLNHYrAtLrlW6C4Rh5pmU4tC4e2P3HDyzJUEXhhAUhWZarZFmeLcvybGAeEACeGVr9q+F1siy/OPko/1mkO00TtoxtretBEOBbn5jBjFQbv3ujZlzs5UQcau8nL9GCUTfexFpF5cPCNZQa0eEdWyH0YcTOD3NeaQqRmMxvXjvM79+o4fI56Vww0zWy/uYlObR5QxOaT6uoqKionPl0DQwSjklkOE1kxJlIsOjZc4YLQpFYBHewAzmSgMOko9p9YhVNkZg0FDmvI/vNF/Bm5NGXd4xIb0HgnXOvIaA18NS5NyFlTOxnU+Ry8ssFn0ITjZB0cCdxumzC0uCI99GxeLr6afSimSWOz1Lb28h1L1zHvVvupTfUe8x93QEPZnHiCiHNYIi4Pjee5CwsBi2iFCExcPjYhtJHkns2kms2C9oeRZAVgasoxYpWFDjYrphLt/QG2NXcR0W6g+wERXhK9+5EMsZB0lHXOHc5GmSy+pWkrvZ5y3E01WD2tI9s4qyvBKAyPgu7UUuyv5Ib9t5IYc8bcN59CNc9jrDmh2iQWNz8ZwC0GpEEqwF3/3hBCEHAXTafhOq9iGFlfW8gzBzPYSwDXtoWnjNulzTHWF/TQHIaO++4h5hWh6dsPp2+EIc6+pmd5WR533NcVPVtxPS5iJ95CexpE19LUTNhZdCRZMSZaO4N0ukLqRVCxyJtLlLSDJY1/gFtLAhTtYsNozMiFF9AQc+bCPKJtY0Nt4f1D0YZGIxiMWjHBRfJGi3dM2ZTUL8XZBmDlIuAwM7OqY2ln615Fp1gINe4hM7+QYKRGPOy4whFYmysciMgUm69nKreSra0bTmh+aucGKeqZWwVUCvLcuMpGu9jSZrThKd/kNBRPcDvN3RTkmrHadbzhXMLqPMM8OK+9klGGaWyw8cMtV1M5Qwj2a58yQ8LQiMeQh9SyxjAnKw4Eq16/rS5nmSbge9/smzM+lUlKWTEmXhYNZdWUVFR+UjSNlSBneY0IQgCszOdZ7yxdE1vEyCTZEyjPN1Bp2+QvsDx+9kNv3iZ2VmNrb2JprMvPubDOYBh7jzuuPInaFaunnwbnYa4rDT6DFbMHc3Ea5U2tJq+mmPPa9DLqw0byDMuZ4ZlDZcn/ZZSy0X86/C/uOhfF7NjCt8RSZboDnVjnsRQWmyoRUQmkqOYNScNHEYjRY5tKH0kgoC47Ms4g03kd7+pnK9WQ0GylarOfgLhKBsOduIw6VhWmDiyW5ZvF0LOkvGVSBkLiQp6Zob3EI1JdMxVWspSh8ylAZz1VXjjUvAabMyQ67h232ewaWMIt7wIS+9UxozLQZh3MzPdz+EIKsJbss2A2xeasHLCM3MBmkiYhKo9gHLftap5B2GzFU/p+LCbZJsBq0HL65XukTa0vrwS3rzvT9Stuow3qz2YdBrOSYuxsv4XULAa4dPrwTR5tdZ0yIwzc6jdRygiqRVCx0IQEOfcgEaOICUWQfq86e1W8klMkV7SvbtP6LA6jYhRJ9IfiuAfjE5q/O0pm4+lv5c8bxuhQQPxuuwpBaFAJMBL9S+TbTwLnWiisUsxSZ+XFcfivARq3H6qOvvJNy3Hoonnr/v/ekLzVzkxTpUgdC3wzyP+/QVBEPYKgvAXQRBO7tPjY8Rw0tiRaUfhqMSOxl4W5ipvQC6c6SI/ycLvNtYgTVEl5AtFaOkNqobSKmccRp2GOLOOjiM8hLSigFn/4VWyaUSB1SWKufTPr6wYl3imEQU+fVY2W+t7ONQ+PnJWRUVFReXMZrgCe/hea3amk1qPH99J+PKcbp7cozzAz0jMpXCo/f+w+/jbxoZfvMzf+RqDVgft85ZPaz+nWc8NS/MnDUQZptRlp9majLa1Cac2ExCmZSz9Qt0LhKVBii2K4KQXLSxy3MIlSf9DOBbjudrnJt23J9SDJMcmTRiLVlUpY85QqnRS/EqU+3QMpcdQ8kmkuFyWNf2BhAFF5Cp12QlHJZ7e0UJ/KMqa0pSReHjrYCf2UMtY/6BhdEb6EhUfoa6BMKG4JHryS5W2MVkGWSauvpKWtHwAFvpfQxRExM++DVmLx4614i4EjY6zmh9Uzs9mJBSV6A+Nr/zoKSgjajCO+AgF+rwsad9Px9zlyLrxL+O0GpGr5mVg1mt4dlfbiNdW2OakujtIuzfEkvwE5nS/iCjHEC78GejGm5MfLxlxyotxGH15qDIFFdcg662IC26flsALQOF5yFoThd0bT/iwNoMOf2i0QmgiPKWKQLWw8xD9oSjJ+hJ2e/YQncTQ+vWm1wlEByg0nwtAQ3eAFLsBk17DvKw4Uu1GNlV5CA4KlFouYmvHVg52Hzzhc1A5Pk5aEBIEQQ98EnhqaNEDQD4wG2gH/meS/e4QBGG7IAjbPR7PyU7jI0HaUGzjkW1j+1q9hCISi/MUQUgjCnzh3AKqOvt5dYr2leqOYUNpVRBSOfNIdZhGTKX7gorR5dElpx80X1tTzN8/s5DlhUkTrr96fiZGnahG0KuoqKh8BBlufxkWhGZlOpFl2NfinWq3Dw1Zlnmlcj8AOfYs7CYdLodxJHXnePAGI7gGusis2kHz0vORdKfWsy/NaaLJlozT04pW0OPQph4zel6WZZ6uXkeSLp8EXd6YdXG6LJzaDJp9k7edDUfOT9YyZmiuZUBnwpiutDCl+A8imeLBOYmR9mSIGsSLf4UDPzfsuZGzmv6PbIcGu1FLbyDCvOy4kd8pgAzvxP5Bw2jzz6ZUbCTYp/j/tM9djq2jGWtbI6ZuN4b+PmqT8xAFKO5/D7KXgnWC+xJbCsLizzHD8woJAzUjAsrwvZUl3MWClr+iiw4ga3V0lcxRfIRkmfxD2zDEImPSxY7GbtJx9fxMUh1GXj7QwfaGHqIxic01XSRa9ZS6rFS41ytR5wn5x3dNJyEjbtQDR60QmgbWZISvHoKFt09/H70FCs+jqOcNmKaJuyHiRRcdGD2sUTvUMhbDqp9YEArbnXizCljorqQ/FCFFX0IoFqSyp3LC7R+vfAKH1kWqvoRgJEaHL0TOUAumKAqsKUshJsm8VtlJkWk1etHEw/sfnv55q5wUp6JC6EJgpyzLnQCyLHfKshyTZVkCHgIWTrSTLMsPyrI8X5bl+UlJEz+gfdxIH/pCaT1CENpa3w3AgpzRL7y1FWlkJ5j57cbDk5pqDVcxzEhVW8ZUzjxS7YYjTKUjH1rC2JEk2QysKJr8s8Zp1nPZnHSe3d1KrxpBr6KiovKRorUviNWgxT5kijpryFj6TG0be6emm+7BdjToR9qiilJsdPnD9Bznd1BfIMylDe8iCyLNyy845XPVaUTccS7MoQH0fi9ObRZVPdVT7rOvax81fYcpNE/cjmbVpNDc3zLp/p6gIgjl17ixN9eOWTcYiZHibsadnDlSOZHRvwchY/70KymOJH8l4hfeRyi/nMXNf+LGvTdybWo72QlmFuWNFaQyfDuRDHZImTnhUI7SVQC4epV2uM45S5BEEdeOt3E2DPsHZVNs6CUu0IBQeN7k81ryJWSDjaVND5Bg1SvG0v2DFHRt5NO7r2NZ4x8o9fwbAPfMhRi9Pdhb6lhQvRW3IxlvTtGUp23Uabh0ThpFKVbeqe3m8W3N9IeirChMIse3HXuoFWHezdO5gtMiM35UWFM9hKaJ0X7cv9NC6SWYw12k9e899rZylE/t+wyXVH5dqWIDbAYtfYEI4ZiExTh5db+nbD7FPY3E+vpI1SuVehO1ge7z7GNv1x5mmC9EEESahsykhwUhgDiznmUFiTR2B6huj1FkOo9XGl+l1d96XOeucmKcCkHoOo5oFxMEwXXEusuA/afgGB8LUh1GBGG0zx3g/foeCpOtJBxRrqvViHz+nAIOtPl4o8o94ViHOvqxG7W4HKrCrnLmkeowjsbOByIfqn/Q8XDTkhxCEYkntk/PLFNFRUVF5cygrS9ImtNIq78V76AXh0lHXpKFXU1npiD08JZ6DKZe7LpUBFlGDA+OpMYeb5VQ0NfP6oatdMxZyqAj4XRMF2+SUolj6WghTptFS38zoej45Nxhnq5+Gp1gJN80cfuaTZOMO9BJRJq4pc8dUO5/lz65joX/+y3iq0Yfbuu7+snxthPMUiqPHMEWnMFGhPxVJ3RuAFgSES5/CK5/Gqc2wrc6vsxvrX8jYXBs8m+mbxdC9lmKifIECOlzCQomCgNKJVHY5qSnqALXzrdx1lUS1RupNiezSjt0PlMJQuZ4xKVfIr/nLTIGDpBtiXJr189YW3U3+sQcJGsKmUMR412lc5EFgfQ3X2Sm+zAHypZOS0jQiiIXlKUyLzuO7oEw+UkWMuPNlHc8qxhnz7h4GhdvehxZIZSsVgidPgrXIGsMFHYdu22soHsTzmATmd7tI79LNqN2JNxosgohUNrGRFkmo2YvOpzYtSnscu8at92jhx5FL5ooNCsVaw3dAxh14ri2wYoMB5nxJt6s9hDsWgIyPHLwkWmftsqJc1KCkCAIZuA84F9HLP65IAj7BEHYC6wEvnIyx/g4YdBqSLIaaO1TlNFoTGJ7w6h/0JFcNjeddKeJX79eM2GVUGW7Yij9YbfhqKhMRKrdRJc/TDgq4Q1Gxnn2nKnMSLWzOC+eR95tnFbSn4qKiorKmUGbN4jLqeWq56/i/KfP58G9D1KeYWR3c98ZF2Hc1B3g9Uo3dpsXmyaVnDeeY/Vd17L8bz/nAn8th9u9xzXn2Qe3YI6EaDz71D28H00gNRMAS0czcbpsJCTqvHUTbusP+3mp/iVyTUvRiRN7z9i0KUhIdPg7JlzvCXrQxGRMfX2I4TCzH7iP+pc28vL+Dpr2VmOKhYnlFACQ0zeUSDSVuDJdCs9D/PxWhEWfo9zzArfsvJyLD91Fmm83lnCXIjxN5B80jEZHs202c2J7kYZ+hu3zVmDu7iRt+5t4swvxhmWWCruRHFmQUDD1fBb9F5I5iVW1P+MJ6WucF3sLecU3EG97DbHwPLK8O0CWCNuc9OUUkb31NQCa5kzPRwpAEASWFSRy5dwMzitNwRTpJb9nE+Ls60B36oSbjDjld8Fq0E5qVqxyCjDaoeDcobaxKT5HZJkFbY8gxeUh2VyKX5UsYzWO/mwm8xAC8GYVELTYqWjZz+aaLpJ1Jezo3Dnms8sdcPNKwysUmlahF80jcfPZ8RZFhJBG29oEQeDCMheFKVZ2N0CsfzZPHnyS3pIcxWw9Jwcee+yEL4vK5JyUICTLckCW5QRZlr1HLLtRluVyWZYrZFn+pCzLx47L+g8izWkaqRA61N6PfzDKorzxb3N0GpEvnlvAnuY+Xto/9stSkmSqOvopUQ2lVc5QUh2jve59wTBO86n1MzidXD4ng9a+II3dA8feWEVFRUVlQiKxD9bMua0vhNHaij/ixyAk89tdv+W98F14dZto6j1+o+bTwmOPQU4Oj1z1JTSxCMFoB3ZNKs76SmIGE86GSu587QF+tf5e0p59FLO7FSE2dXx0NBLlguq3aE3JPWaL0MkgJKcQ1OgxtjcTr1N8eiYzln6x/kVCsRDF5skFGptGCXpo9k9ckesJeEgN2hCQ+UfZhbTakrnt5d/hOrSDzF6laqc/IxeA3N4tSHF5p8zrBoMVLvwpwlf2Iyz/GvmBPVyz73au23Ozsn4S/6BhBjOXkS+0QbdiUt05azGSVosuOEBvTjGRwSBzonsQC887dhWPwYq44uskD1RhNJq4avD7NM/6Cmh0kHs2hqiP5AGlfc9TtgCA/Qm5aDIyjvu00+NMGLQaSt0voJGjMPem4x5jKsx6LQkWvWoo/QEglFyCdbCDFP/kxszpvl2k9B9EXPIFxOVfI923myzv+9gMoy9xpxTuRJGe0rks7DrMvuZedJF8+gZ7qffVj2zyeOXjSLJEieVCQGl5DEZi5CSYyX/5Cc7+we1oBkcrDU16DeeXpXLVvAwcngVEhAiXX7GM/Um50NgId9wxfVFo6PNWFZOOzalKGVOZJulO04ip9LB/0KIJKoQArpqfyYxUGz9+8dCYqPqW3iAD4ZgaOa9yxjJsFtjpC+ENfHQqhAAKUpSS/fouVRBSUVFRORH2d+1nyT+X8M/Kf0653UBkgD/s/gM1vceOMJ+KQDhKz0CYQW0lAiKfSLiXixLvxyikYkxdz6dfuYL1Nes/cJFqDI89BnfcQaCtgycqzmNl4xuEhSgFNW6snc30FMxk031/5r2bvk6TLYXyjetY8cP/x5qvXMnKb9/EWT//KnMevJ+Zj/2GWX/5OfMeuI+Fv/oWy372ZTL8HvYtvuDE/HOmidNioNmWjKmtCZsmFY2gm1QQeqr6aRJ0OSTqJq9+sWoVQWgyjxBPwEOqX/EY0RQXUffNnxFIz+Gud/7CTR1bkUQRvysLTSxEpneHIq6camypsOq7iF89CBf9EovVhmRLg9RZU+6WuORGIrKGsrZ1AERNlpFUpvaMAuaJVRjl0PQrmhbcBtc8SvPVr7JLLmRf69B7+NwVAGR6twHQWbEISRB4JWvhibfqyzLlnc8hZy6C5BknNsYU5CdZyTyidUzlNFF8IbKoo7zjmUk3md/6CJIpAWZ/CuZ+GsmezlnND2IzjLZDTlUhBNBdPAtLyE9FpIeD9UqBw3D8fCga4smqp8g0zseuTQWUdjGAfFOM3NefwdTbRebml8eNm+Y08cL//YT8egNdOYe5+ob78enNEAjAPfcc+/yHPm9pbFSqpI5XTPoPQxWEPmDSnEZa+4LIsszW+h5yEsyTOu1rRIHvXVxKS2+Qv7wzqrYe6lAMpUtUQUjlDMXlGDVQ94WiHylBKC9RuQFVBSEVFRWVE+PJqicJxUL8eOuPWV+zfsJtvINebnv1dh7Y8wDXvHAtT1Q+ccKtXcOV1+7ofpL0+ehFCyn6GVyc+ENCLbcwENLwnXe+wwXrLuTvB/7OQORD+Hy/5x4IBHi29Bx8Ritnt24AYMXzr2L2dDCQmoGs1dE3fzkPXXwnd679Lvuu/Ty1F1yDe+YCwlYH5u5OEit3Y2ttQO/3Ims09DqSeC53KZ65U7QxAQXdG7l272dGotWPlzizjmZrMnZ3K6KgIU6bOaEgdKD7AJU9hyg0r5rS1sAsxqERtLRMYizdGXCT6FUqSeSEZCIWG9u+cB++zDziaw8ykJKBpNOT4duJVjoOceVE0Jthwa2IX9iG+OW9oJn6IdmVns2b2rNY6n8ZbUz53WxccRH+5HQaUgs5R9xDTNRBzjTbujRaKFlLYUYKeo3I3tYhXyxbKlJCEVlDgtCAK4v7r/sRW4sWo9WMPuLZBjtIGKghPlCPI9iMPdSGOdw1YTtRum8XccGGU2omfST/e+1sfn5lxWkZW+UITE6ERZ+l3L2e/O5N41bHB+rJ692MuOgO0JlAa0Bc/jXSfHspDSnG0HqNiF47tVTQU1gOwOVCOwMDcYiSbcRH6MX6F/GG+yizXDSyfeNQ3HzJOy+hHQzRn5pJ7uvPIIYHx43tdLfx7ScqQRcgknSQw4lDCYJNTcc+/6HP2y1ZFXx/9WcJ6AzTF5P+A1EbOD9g0pwmBqMSXf4w2xp6WFOaMuX2SwoSWV2Swu831nDlvAySbUYq2/sRBCgaqmRQUTnTSB0SOQ93KmX6HyVByGnWE2fWUacKQioqKirHTSAS4OWGV8g3rSAo9fG9d76HWWfmvOzRB/buYDd3bLiD2r46ljk/T0NwCz/a+iPeadvCfUvuxWl0Htcx2/qCIA7SGqhmpvWSkeVajUiCMAuhs4IVZR72+9fzi+2/4IE9f+S6GddyU9lNOAyOU3buUzL0EPNOzmzSvZ2YxXYgg8K6boIOM/6U0RafohQrr/XY2VFeNvJ9OhlvVLk52ObjDsckVReyxOLmP3FW80MAXFJ5ot1lVwAAIABJREFUF49VPMyg7vjO227U0WJPYVXLTjShAE5tFtW9B8Ztt656HVpBT77p7CnHEwUNNm3ypIKQO+Bmlk+5zxWSlXvlqNnKtv93L+WP/hpvdiGgtIvJGiNCztSC2ClBFJnuu/RDGVezunEzxZ6XOZB6KT3Fs9j83T/Q3eHjJnEPg65FmA3Hdx+v14rMcNnY1zLi1IGYfw7pOx5BlCJIoo5arR2ncXSOjlALN++8ClEe33pYH7eUDQXfYUCfOLKsvPNZJIMdsfTS45rbdElzTuwppXIaWPV9pIbNnF/zQx6xzqDfkDqyam7rY8r/mwW3jW4/50akt3/JspaHsOjvQa+dPGFsmFB8EgOJqWQ3VbJg9dns9WexedeLyCt+wqM/mYErLpFUvZLIF4rE6PCGWJZmJPupF+isWETDOZ9k0W/uIePdDTQd5YHWn+RiQWUbBU0RqlPe5nBiBvPaKiEra/xEHntMEXuamiAri+beID++9Fu8VKy0d55dt4Nz67ZPT0z6D0StEPqAGY6ef6PKTV8gwqLcY6dB3HNRCeGYxP+8ovQIV3b4yEmwYJ7C+V1F5cPEbtJi1IlUdihJKU7zR0cQAshNtFDvUQUhFRUVleNlQ+MGgtEAxeY1rIq7myR9Id948xtsbt0MQOdAJze/fAt1fY2sivsmReZzOS/+2yy038ybLW9x2XOX8377+8d1zLa+IBpTPRIx0gzlY9alOox4fGHS9XO5MPE+Lk78CQmaUv6070/88N0fnrLzPiZDDzHViVmUuOtpSdajjcrotcp94MARglBBkhVRgMPHSBuTJJnDnX5yEi3oNONv6XWxABdXfZOzmh9CnnUd3PQC9nAnn6j+LoIcm2DEyRFFge4EJUjY4m4lTpdFV8iDd9BLVIrybtu73PfufayveY4c4xIMouUYI4JFTJ4wej4mxegN9eD0yoQ0OkzxowJhzGRm9+3fon7NlQDk9r0LucuVKocziJSylVRKmZS3PTWmEkfnb6NYbEE3Y80JjTsz3cG+1iNMx3NXoIsFSfUfQJZl+gIR4kyjvo1lnc8hIMFlD8IVf1b+vuQPcM63yenfyad3X0uR51UADFEfhd0bESuuVqqiVD7aaPWIV/4FnSjxiervIAyJgpZwF6VdLyLMuR4siWO3X/F1XP37uMB4YNr+nz1FFcTX7OfGus0kuW302KP88+xUDqdquP3xSmZsfAFQqoNkYM3hzeiCA9SefzW9BWX05JWS+9q/ECJjW3o33/JVogYj173uQTR0sSs3CcxmuP/+sRM4oj0sqNHzq4ylrL7tATblzuPzW54AoDoxW9l2IjFJRRWEPmiGlfFndio90xMljB1NbqKFm87K4ckdzexv9VLZ0c8M1VBa5QxGEARcDhNVnUp740epQgggN9F6ylrGvIEIX31iN52+yeN5VVRUVD4uPFvzLA6tixT9DHSikdXx9+DQZnLnxi/zQt0L3PTyzbT2d7Am/h4yjHMAEASRmda1rE38CdGInttevW1EQJoObX1BdNYaNIKOZH3xmHWpdiNRSaZ7IAxAsr6IVfHfoNh8PptaNhGMBk/dyU/F/fczaLVTH5dOsaeR5mQ9qT0R6hcolTQDKekjmxp0GrITLFR3+keSqiaipS9IMBKbsGLcHmrl2n23UtDzJpz/Y4RLH4Dc5Qif+AU5fe+ypOmPE47p8u3lwqp7Jmwt8ycropV1KHoe4O637+acJ87hjg138Ozh50nXz2Ou/bppXRKbJmVCD6GeUA8SEnZvlG6TE+MkL0AdwWacwSaE09kudoIszEvgkdh5uILVpPr3jyyf4d8KgK74/BMatzzdQX8oSmO3klhMzjJkBDL7thEIxxiMSiMv4QQ5ykzPC1BwHsy6BsqvVP6ecz2cczfC5zajTy7koup7+ETVt5nT9gRaafCUm0mrfIgk5COu/TVpvj2c1aRUCc5qfxJRisJZnx+//ezrkRyZfE23jtUzkqZ1iJ7CcnTBAc565Dd8+3kl5e5n16fi6I/xyc1dLPvrLwFo7BnAQYTyLS/iLp2HL6sABIHaC67G1NdN+vsbx4xbtWotG778Iwp6FXH5UKEDHnwQrr9+7ASG2sOa7cmsvu0Bfr3sU6w5/B6v//m/uOvtR0jt76I6KXtiMUkFUFvGPnCGK4Teq+8m3WkiM356CvwXVxWybmcL312/n4buAS6dnX7snVRUPkRS7Abeq+sBPnoVQnlJFtbtbGFgMHpMQ71j8dZhD//a1UqCVc89F5WeohmqqKionF72d+3ne+98HwC9Rodeo0ev0ZNqTuXuhXdj049/MdXc38z2zu3MtV034h9jEC2sif8uL3V/l2+9/S0MooULEr5Pkr5w3P4JujzWJv6cdZ7P88zhZ1iWPr02oJa+IAZbHcm6YrTC2ASjVIfSctXhC5FkG12XbVpIZeBl3mt7j5VZK6d3UU6G66+nPiQSPaylqLuJ7Rk2TOZMglYbIUc8UdPYipqSVBv1XQM0dA+Qlzhxa1F1Zz86jUBuwth9k/xVXHnwC+hFGeH6p6Bg9ejK+bcgt+1m4c6HcVtmcDhxFQD6qJ9ljb+jouNfCMhk+Xby+MwH8ZoyR3aNpKYRFUQsHc0kzJuDRtCyrX0nmYYFzI9bTLpx9rjrPxneYASzmIwv7MUX9mHXj/piuoNuABy+EF7L5O2Dub1DcfNHnt8ZQnaCmS3mcwlGH2dW+9N02JTKtVmhbXSKSaQkFR9jhIkpT1da/fa1eslJtIApDtk1iyzvdg5KVwBKWhhATu97WAY9MPfGiQdLLED8zCvwzq8o2vRTBGkDkmsOokv1+PlYUX4lct0mFu76Kx3WUmZ3rIOSiydO5dPqEVfcRdrzX2KF55/EBC3xwQbig40khBppsc3iheKfjjGw7y4aqsocDHLevm704XLC+gi9Pefwp3kzuXX7+pG4+Rs6d2AY8FF3wdWj+8+YTV92IXmvPk3r4lXIR3h0Va1ay6FzL0Rou57WHP14MQhG2sBemrGUVkcy//jnt1nStFdZl51NkaeRqrSCicUkFUCtEPrAcZp1mHQaZHl61UHDOEw6vrqmmF1NfcgyzHCpFUIqZzZH+h589CqElJvrhlMQPX+wXamSemJbM4Hw1PHBKioqKmcKz9Y8S723kcGQgz6/no6+CPXdfTxX+zy/2vGrCfd5vvZ5BAQKzOeMWW7SODg/4fsUms7lgoT7JhSDhtGJRjINC3i7dTODsfFGoxPR1OdG0rXhOqpdDMBu1GLSaWg86vPcpS/DIFp4ven1aR3jVFA1T0mFKn79OZpynGiSy7G4W8a0iw2Tl2TFatCyp9k7bh1ATJKpdfvJS7KOMRA2Rvq4pOou9EYT4u0bJxRLhE/8HCljAefX3EvCQA0FXRu5eddVVHQ+g7Doc3DbRowaiSsPfgHLoHtkP7vNTJslEUNbMyaNkyuT/8B1KX/l7Lg7yTYtmrYY1Nob5JF3G+noVl6KtvaPrRLyBDwAOPsD+G2T3yvn9G1Bis8/dXHzpxBBEJiZl8HzwtkUd2/AFOlFlCLMje2hyrLwhBPhilJs6DXiaNIYIOadjat/L4eaOslOMJNsU+6/yjrXI5mToOiCyQfUaGHFXQi3b0TOPQdx5bdOaF4qZzbChT9DTixkbeU3MER9CEvunHzj2Z9CcuawvPG3nNPwK2Z6N5Hu0GPKKKeweyM5fVvGbB62x9GfmonPGYdWgnnV/WijMgt2m/jF2Tdx3u1/ZEdjL9FgiDV7N9BVVEFf7hEJdoJA7QXXYO5xk7btzXHTEQUtRjmDgNAw8X30UBvYweQ8XD7PGDGIhgaKb7qSmuQcYtd96riv238KqiD0ASMIAmlO5YN6srj5ybhuQeZIWXBJqpowpnJmk+oY7ed3mKbXh3ymkHsKk8YOtPmwGrT4QlGe2TVxvK6KiorKmYQsy7zZ/BZphgpWx3+T8xO+w4WJ97LM/AOMwbN5qvqpkWjhYSRZ4pnDz5JmqMCqSRw3pkWTwPK4z5Ogyznm8bONiwhGA2xt3zqt+bYElZaco/2DQLnvKnXZqesaoD806lEhCloyDPPY1LyJqPTBiPWHO/1oRIF4WxR/pB+7JgVLRwv+lPFV3xpRoDzdQVNPgJ6hdrcjaeoJEIpKFCWPVg8JcpSLqu7BGulBvPYxSJwk9l1rQLz6ETRGG9ftvYW1VXdjinMh3PY6XPhTyJiHeMM6rJKPKw9+EWNESbWKM+totiVj6WgGlJ+pRji+Fz59gTAv7GsjJsv4/cq97NFtY+6AG0GSiQsMEHRO7LV5WuPmTxGLcuN5MLgSjRShrPM5XL49WAjRlnTiBth6rUjJUcbS5K5AI0eZGTs48mxhDneT37sZcfa1oJnGz8g1C+Gm9VB0Yq1sKmc4egviVQ8jaHTImYsgc8Hk22p0iDe/ALe8DHfVIX6zAeHWV+BTTyHF5bGi4bcjfkTD9BSWEzQaCRuM3Pl0Bz/9v2Ye/ucv+eu/7iNid/BObTdrGt/HMuAdUx00jKdsPt6MPPJefRqk8f5mDk0uGmMbNUNhNWO4/34wmzmQkkepeyiV+4j2sMIUG4NRiaaewPSv138YqiD0IZAep7wROZ4KIVDSMv77qll8ZmkumfFnlnmeisrRpNpH3xR+1CqEcobK70+FsfTBNh/nl6VSlmbnb1saTjhWWUVFReWDos5bR0egnQzD3DHLD3X04248B52cwA+23Es4NipUbO/YTkegnQLTybdfuQwz0YvmaVXvSJKMl4OIspFE3cQCSEWGA2TGVFUAZBsX4g17R2KSTzdVnf3kJlpwB9sASAlY0YUCDKRkTrj9zHQ7GlFgT0vfuHWHO/sxaEWyEkatB5Y1/J4s7/sIF/8S0udNPRm7C/GaR9HGZcKaHyHesQnSj/h5p89FvO5x4gZbufzQneiiAzjNepptKTh6OhGikclGHocmFABZJhSJsX6Pcu5pTiNenyIIHZ001hXswhEQ0MoSg3HjxUWATN8Oxe+m4MwVhBbnxVMjZ9CZsJDZnevI7n6bsKxhMHOacfOTMDPdwf5WL5Kk3E+EXAuJoOV8cxWuoZdxJe4XlWSxOZ8+6fNQ+ZiQUobw2TcRrv3Hsbd1ZkL2WWA5QpDV6hHP+wEJgVrKOl8Ys3lPUQViLMrbN36BzEA8a7b340tOI3j51Vy5soyV+XHcUP8mPXml9BTMHH88QaDu/KuxeNpw7RzvH5dqzEfQhHi/pXr8vtdfT+iPD1Ibn0mZu06pDDqiPaw4RemqqeqY2qT/PxlVEPoQmJFqIzvBPFKFcDxUZDj53trSkd58FZUzleEKIbNeg1770fqoMek1pDmMJ10h5PaF6PIPUpZm5+YlOVR3+nm3rvsUzVJFRUXl9PB2y9sAZBjHCkLNPQGQDQRaL6HeV8ef9/95ZN0zNc9gEC1kmxae9PE1go50wxw2Nr1BbIK3xUfS5R9ENNVioxhRmDgm2W7SkZdkYX+rj2hMGlmebpiNRtCxsWnjhPudaqo7+ylOsdHkUzwv0ruVuQxMUCEEYNZrKUqxcqjdx2B09DpEYxK1ngHyk6xoReX7tcjzKvPbHkWefxvMuWF6E8pahPDF7bDki0rr0NHkLke4+m8k+6u4pPLr2LVR2hwpiLKE2dM+rUNoA37O/v4dlD/8P/x7Tyv9wSgXV6SRnWDBH9JhEK20+McKQu6Am9R+5R652FhLece/xiR1AeT0vousNUHO0umd64dAfpKVBIuel0wXYQu1M6dzHdulYpISJxa5pktFhoP+wSiNQxUPj+/uZqdUwNm6Q8oGsky5ez1S5iJIKjrZ01D5OJFcMjZZ7Hgp+SRSxkKWNv8futhoxU1PYRmyIOC3O/jzo2/wv69U8udH36Bq1Vo0osAnWnfi6O+h7oKrJm2X7KxYRL8ri/yXnkDn941Zl2FWfo93dR6YcN/Kcy5CEkVK//BzaGgY4xVUONRdU32M1Mb/ZD5aT2kfE762pojnv7hMFXVUPtYMG3l+1KqDhslNslB3koLQgTblC60szc7aWWnEW/Q8/E7DKZidioqKyunjzZa3SNDljGn9CkclOn0hchLMhPqLcMQW8uDeh6jz1uEP+9nQuIEc41LFR0aWias5AJI0xVGmJtu4iL7BXnZ7dk+53d6OBkRDF0naMgDKH/k1rm2bxm03K8NJMBKj+oiWA51oIk1fwWuNr5/26s1AOEpTT4CiFBvN/UrLVZJHSTjzp05cITQ870hM5mDb6ANSY0+AcEwasRFIHDjM+bU/Qs5cjHDBT07txIsvRLjkd2R6tzOj+zX6khTxyto5vRbo9PffQB/oJ33n26x8bz2rS5NJd5pIsCit5EaSxlUIeYIeknzKPcTi6Gusrv0JF1V9G1109Ds5r2/LGRk3fySCILAwN56/eEqRrKno5UE2SbNGEodPlJlDxtJ7W/oYjMb445t1NNrnkxGsxhDtJ61/L3HBRsS5anWQyilGEBDPvx9zuIt5rY+NLI5Y7PSn55BQvXfcLprBIAUv/oO+nGK6ZsyZfGxRpOqyWzD1uFnyi69hbxpNOkzQZ4GsocZbOeGuB9qU6s+yNMe4dWa9lqx4M1WqIDQpqiD0IWDQarAbP5oPySoq02XYVPojKwglWqjz+E/qIWHYULokzY5Rp+HaBZm8dqhTecuuoqKicgbSH+5nl3sn6YaxN+6tfUEkGeZkxZGXaMHTeD4aDPxgy7280vAKg7FBCs1Ku1jivvdZ9Otv49qyYcpjSZJMY/cAkdh44SjDoKRYvd70Ojz2GOTkgCgqfz82+iDyTut7AKQbKzD2uEl/fyMz//l7rG2NY8eLU0SI3S19Yz7Xs02L6Ai0U9VbdTyX6bipcfuRZShKsdLc34xFE4/d3UHUaGLQMbmFQIrdiMthZE+Ld2Te1R39mHQaMuPMGCN9fLLyG4gmB8LVfwftafDsq7gWSWcm2V9JcKiaydLZfOz9ZJmMLRtoS8nh5eyFfKrqNVY2K95T8UOCkEZKpPkoQahzwE28V7l3sBq84JpFYc9Grt93M/GBOpzBJhzBZoQzuF1smIW58TR5I/TPVJK+3pDmjHiJnihFKTb0WpH9rV6e2t5Chy9E8VkXISCR7t2pmEnrLFB66ak4BRWVsWQuRC69lAVtf8cS7hpZ3F1YgbO+EjE8Ngwgb8M6jL5eDl1x6zHN1LtK5rL1Kz8BWWbRr75J+rvKd4hG0KGNufCEayfc72CbD5tRS0bcxGJrUYqVw6ogNCmqIKSionJaSLIZ0IjCR1gQsuILRekNTN8n4WgOtHnJijePCMA3LM5GEAQefa/xGHuqqKiofDi81/4eMTk2zj+ouSeARhRIcxhZmBvP4KCFxPAV7HLv5L+3/zdObTpJOiU9THxLacFKeeEJaju8EwrrLb0B/rGtiWd3t7FuZwsDg2NNSvWiGZe+gtcPPod8xx3Q2Ki0DTU2wh13jIhC+3p2IEUtpJtziD+smEvLgsish/9nzIOJIAjMynDi6R+k3RsaWZ5pmI+AeNrTxoYrk4pSlQohmyYVS2cL/uSMCR+Scns2c9mBL+IMNjErw4k3GKGhO0AkJlHXNUBBshVbxMPV+z+HPeJGvOZRsKWcnsmLIkLKTJIGDmN22nGbnJjbjy0IORuqsLU38pRrPhvW3ER3wUzK//FbnHWHcBh1aAQBORJP+0DbmNZAT8BDnFcgKmrQGCQ46wsIn34OBwN8au/NLG/4jbJh4ZkXN380i3IVD5aNiZ/i0ZI/0ihmkWiZXhrbZOg0IiUuOzub+nhgUy2zM51ULFqFpDVR0LOJGd0bEMuvAIP12IOpqJwAwurvo5FjnNX0x5FlPUUVaKIRnPWj4rqxx03O68/SuuAcvDnF0xrbl1XIlm/8kt6CMsr/8TvK/vl7xEgYKzmExWZCkfEhAAfafJS67OO6b9wBNz/Y8gNyk7TUeQYIR0+8avXjjCoIqaionBY0okCS1YDT/NEUhPKGPL7qPBMkGkyTg20+ytJGEwHTnCbOL0vh8W3NBMNT+2KoqKiofBi81fIWBtFCsn7szXtTb4A0hxGtRiTFbiQ7wUxjQxmp+jL8ET8FpnMRBIF99R6Ka3fjsSeTOtDNwMsv8cyuVrr9ijjjC0Z4cV8763a2EolKLM6Lp9sf5sntzfQGxqZpZRsX0YaXv88u5bIb/ptNuUMiVSAA99yDLMs0DOxBDuZj1OmIr9lP2Gxj92e+ga29keL1fxsz3gyXDYNWZHfzqEmzSeMgRT+D1xtPr49QdWc/eq1IdryZJl8zNk0K1s6WCf2DNNIgq+p+Rk7fe1y/92bO0+3FYtCwp7mP+q4BopLMUmcP1+27lbhoJ8IN66ZODToFCK4KkgPVxJm0NNuSMXccWxBybX6FkFbProIFnFOWxu7bvkkwLpk5D/0ES48bp1lHOOQkIkXwBJWo+agUpXewB4cvRsBsVrQyezrkLkf83FtoXOUU9LyJFF8A8Xmn9ZxPBcWpNuxGLVsb/WyVZuByGhHFk7eMqEh3sKOxl9a+IF9aVYCgNSBkL6HU/W+0sZBqJq1yeonPQ1h4OzM7nydhQGnt6skvRRJF4g/vG9ms+NmHQRCoXnvjcQ0fsdrZ/l/fo/b8q8jc8ioLfvsdEjU5CNoA21rqxmwbk2QqO3wTtos9dugx1h1eh2CuJirJpyQ9+OOIKgipqKicNr57cSm3Lz/zb9gmYtj0/UR9hPpDytvcUpd9zPKbzsrBG4ywfrcaQa+ionJmIckSb7dsJk0/e4xBcyAcpdsfJjN+NNFqYU48wYhEXOB6coyLKTKfS33XAP4tW7BEQzRcdwe+tBxurd+ExxfksfebeGFvG4+810h91wCL8+K5cXE2i7McXDE3g0hM5sltzbT1BUeOYZMqQIb7L1vKrvQZ/HL5DYzUGjU1Ue+rZ1DuRR9RxKv4mgP0FpTSVTaPhpWfJPutf5O0f9vIeDqNSFmanRqPf0wEfZZxAYf7qke8fU4HVR39FCRZiciDdIU8JMQSMPZ1MzCBf9Ds9iexDXbAJb9Hm5DD5ZVf4bv2l2jsGWB7Yy8L9Q3c2fRFLJoo4s3/htwVp23eI6SWo4/6ydV102xNweZum9IjShscwLXzbd5In8OKWdnoNCIRi40dn/sOghRj7v/9kDRdjMCA8hA37CPUHexGRibOFyE6XEnjyFD+tqch3vIinPsdxPN+cDrP9pShERUfoa31PbT1BUk/Sf+gYcqHfIRmpttZWZwMgJB3NgIyUmIxZMw/JcdRUZmUFXchG2wsbfoDADGTGV9WwYiPkLP2IK5d71C3+opJ0wKnRNRw+OIbOHTFbcTVVzHTp1S8vdO0Z8xm9V1+QhFpzAtYUMTl9TXPATAgKHH0qo/QxKiCkIqKymnjogoX83Mm90Y4k8mIM6EVhRN+m3CoXfnSKUsf+wW1MDeeEpedh9UIehUVlTOMyp5KukNdE6SLKSJNZtyoIJTmNJERZ2J/o44Vjq/RHzDw0v52VnsOEDGa6Zkxm7rzryKhp51vWjqYmeagvmuA3EQLN56VzaLcBJJr97Pq7uuZd/Btrp6fgVGn4V+7WjnU7uPtwx7WbfPCQCYZvM33XnuQva4idqUNVS5lZbG1fSsANnkGxh4P5q4OegrLAaha+2l86bmUP/YbDN6ekXlXZDiRj4qgzzIqyWinM22surOfohTriPCR2a0Ibv6jKoQMES+LWv6KnL8a5tyAeOurMPMKru1/mD/qfs2cgc38TfNDDGa7si5t9mmb8xhSletaFKunyZaMLjKIsa9r0s31mzagj0ZoOGvNGBPlQHI6u2+9G4u7lbUHXqPfPyQIDSWNDVcKxflDiFYNMgLY00YH1uhgxV1QsvYUn+DpY2FuPPVdA1S2+07aUHqYRXnx6LUiXzuveLRNJk/x8BLn3XRMrxYVlZPGHI+48Dbyet7BFFY+Y7sLK3A0HkYTDFCy7k8EnQnUr75swt1nuF/k0oN3YohOLdK4ZyrVj6WeELIssr9rbNLYcIBL6VGC0Dut79Ad6kKDjpZAFRpRoFqNnp8QVRBSUVFRmQCtRiQrwUy958QEoYOTJB4IgsDNS7Kp7Oin4t5XqfjBKyN/5v9oAzsae0967ioqKionwlstbyEgkHGUoXRzbwC9ViTZPtb7ZFFuPIFwjK31PTy3pw2zCIvaDuAuX4is1dEx+yz8yemUvL6Oc4uT+OK5hXyi3IXdqMPU1cHsP/8c7WCIkqf/hCvQy9XzM0m2GXj1YCc7m/oocdlZPeDCkxRmWdsb2AYH+NvctWA2w/33s7V9K3LEiUPnIr5G8Q/qKVDSxmSdjj03fw3NYIjyR/53pJrFYdKRlzg2gt6uTSVBl8Prp0kQ8oUitHtDI/5BAK6RyPmxFUILWx5GH/UjnHevskBvRrjiT7DmR6zRbOdB/a+QHFmKGJSQf1rmOyHJpciCSNpgDe44FwDWjpYJNw2Go2RueYWGuHQyF49PFeopqqA/PZfsrkbkiBMBcUQocwfcIMskBgIYLTFka6oiAn2EGfYRGgjHTpkglJ1g4cC957NyRvLoQlcF3PIyLPzsKTmGisoxmXkFAhKF3cpnZ09ROaIUY+bjv8fRXEv1JTch6cd7ZpnD3ayq/wW5vVtYW3k3ojS5X2cwIYWw1U5icwNCJIWmgcNj1h9s86HXihQkj/XMeqbmGcwaBwXmlRzqOUh2glGNnp8EVRBSUVFRmYS8RMukFUKhSIz1u1uRpImrfA60+Uiw6Em2jf8ivHROOl86t4Ar5mZw+RF/uvxh3q2d/I2rioqKyunkrZa3SdQVYNKMFbKbewJkxpmwdHeS9v4bMGQAnBFnJs1pZHtjL4PRGLdZe9AH/XTMWaLsKGqoW3Ml9tZ6kg5sHxlPEwow98EfAzLvf/GHyKJI+WO/waQVuHxOOkvzE7h2QSarS1Jwlt8EwHtnp3Dlvtf4d8ly3L9/iLfPzmIRZ8ZqAAAgAElEQVRL27tEB/KxG3XE1ewnbLbSn5YzcpyB1EwOXXEbiVV7mP/775P/8hMkHtjBoniRYCTGjqbeEZPRTMMC9rh30x3sPuXXdTjdpviIyPlkjx9J1BBISh3ZzjbYwZyOJ2HWtZA6c3QAQYAlX6T3iic4lHE15jteAbvrlM9zSnQm5PgCkgaq6R9OGpvER6j27W3k9rXRufxCtBrNhNv0p+eQ5GkGNBiIp9WvtFF7Ah5sQdBJMczmMMJwu9hHmLI0Oxa9ch3STzJh7Eh0mgke47LPAo32lB1DRWVKkkuREoso7lLSwHrzSpA0Wlw7N9OXU0z7vInbWZc2/gGdNAhnf5NM7zZW1/5YCQ2YCEGgL6sQR2M1BimLvlj9mAr7A20+ilNsY/4/dAe72dS8iTzj2fx/9u47PK6rTPz499zpGpWZkTSjOurVTe49caqTkN4hkIR0wgZCL2F3aYFdfsCyEAIEFjZACISFAGmkOIkTl9hylS3bkiVZvZcpkkbSzNz7++PKsmVJjuNYlu2cz/P4kXTvuee+Yyczo3fOeV+PuZhQZJBMT0AmhKYgnzEkSZKmkJscy1sHu1FVbUIRyKe2NPKt5/dhMxm4dFbKhGsrWwOUpk3seABgMRr47KUTuy28UtlO7UmuSJIkSXo/+ob62Nu9h7K4m8cd94fCpLTV8Ymdmymq3o7QVAxDIZrOuwKAFblJvLCnjUtKPRS9+jIRi5We4iOrQtoWnUf+S38k7+Vn6Jq1CDSNub/9EfaOJrZ/4t/pLZzLgevvZs4ffoL37RdpPP/KcVuND6/eee12F99c/F88+eP/407rGzSt206ckspIz3nEuYy4Du6lL69Ub01/lOYVl2L1dZOycxP5Lz6N0DQWAVfYnfyq5AqeyFxAmtOKJ7EE1aiyvnk91xdcf0r/bqvaRzuMeeLYVNWIRbET39nFYHIq2lG/vK9o+DmKEIgLHpl0nsQ5l5I459JTGtt7oaTOxV2zAaMrkYDZTmznxFp4Ve1BZu18gxGjmeCqC6ecK5ieQ8Y763ANBVCiiWOt57tCXSQG9NfNeFs/wlEyPQ/mNDIaFBZmu3iruuuUrRCSpDOCECizrid9/X9iH+5iwJKML6cIV03llG3mPcFKZnf+A1Z8Ci74CgCz1v8HPmsGWzPvnvQ2/qxCkvfvIDmyjGbrFtr620mLS0XTNCpb/VxaOv59+PN1zxPVohTEXDhWDy8mrpWGShOhkSg28+SJ6g8quUJIkiRpCjlJdkYiKq3+0IRzz+1uBeDP2ycumR+JqBzsDE7a8eB4cpNjqX0fXc0kSZJO1oaWDWhoR9rNaxpJldtY8ZOv8d/rf0xuQyWHLrqW3vzZFLzwFKZ+vW5DutPGvatzyHVa8VS8Q+fsJagm89i8msFI3SU34KivJrFqN/kvPY1nzxaqrruLnmK9/k3LsovoLF1I0d+fJKazdUJsmZbF7OrcyTOHfkps7o9oDO1lYdzHWGR8FHXEg2c4gL27nd782ROuRQhqPnQbG772U177zz+w5VOPcuDaj2OJi+WhqheYn2ZnYCjKtoM21LCDX21/4ZT/3VZ3BIkxG0h32Kj11eIwZkzoMJY0UE1J14uIpfeDY2Kh6TNCyhzihtpJtw7RFJuM7ZjW86GRKJv3NnJBy046Fq4mYrNPOVUwLQuAWcNdqGHn2MqprlAX7oCeNIk39x4pKH2WW5qjJzlPVVFpSTpjzL4egTa2bazm8lupvPmBydvMayoXHvp/qHa3XgsMYM2X0ebewsrGn1PU9c9Jb+HPLkRoGmU9+qr79Q27AGgPDNE3GB5Xr1PTNP5y8K+4zYU4TZnEG1KxKrGMGOrRNKjplO+zjyUTQpIkSVM43Gns2G1jTb2D7GrykWg388aBTrqCw+POH+wMEo5qEwrcvZu8ZDu1nf2y2LQkSafd281vE2NIIMmkd4ZM3f4Wi37+LWJ7O/jfsmtY/41fUX3NHVTefD/GoRCFz/9+7FohBM6aSsz9ATrKVkyYu2XJhQw5Epn9h8fI/+czNC+7mIbzr+SoCaj88CdRjSbmPPXjsS1ph2XZlqKh8bt9v8NjWMpA7eewDFzIwOhTb25LFQB9BZMkhI4StcXQVzCb+ouupfrqj2EP+rh+qJ6PLc/izhU5WCK5NB9Tn2Iy6xrW8Vztc+867rDqjiAFnjgURVDjq8Up0onpaqP/qPpBq+sfQ7MmwOrPnvC8p91oYelZShONcR5ij9ky9k5dD8sbdmCNjNC8cu1xpwqmZwNQMtDOSMhJ71APoUiIzsFOXH49oWi2DkHCGZoce48+uiyL790wd+x9hSSdM5KLUN2lFPXo28Z6C+fStPrySYeWdr5ASrAS5ZJvgnX0PbIQiKt/gpa1krU13yTdv3PCdf6sfACKu4fRNEF5q97avrJF/2Di6A5je7v3cshfR4HtwtHpBYmmfNqHqwHktrFJyISQJEnSFHKnSAg9X9EGwPdvnkdE1fjbzvHL5ve1TnyBOhF57lgGRqJ0HpNgkiRJmk5RNcqGlo2kmecjhP7WMH3L6wwmerjvskfYvewKojH68+FAqpeG868kY9MrxDceSZ6k7NpExGyhq3TBhPk1k4lDF12Hra+LvpxiKm9+YMJWgmFHIvtvvBdn3X6y3xifbHEZs1mecC8fSnqUyz2fIcGcyO4mP4GhMEJAav1+wjY7gdEkw4noLl1EyJFI5kb9E+kEm4lkcx6asY+qzvbjXvvYrp/yg20/POHkfXVHkCJPLD2hHvwjPnL8CShqdGyFUKavnGzfZpTVnwOb84Qfw2k3mhAq0A7RFOfGOhgcWynWHRwisP8ANze9QzAtC3924XGnCtvjGXIkkhNoY3BQX03b2t9Kx0AnTr+BqFAwWlSITz/uPGeLBJuJmxdnTrqNXJLOdsrs60kL7CZ2eOrnTnOkn9WNP0XNWAxzbxl/0mhB3PoUwpHNtQc+R3bfxnGnw/Z4BpJTyWxrQB1JpqpvP6CXZxACilOOvN9+tuZZjMJCjm3l2LFkUz7N/YcwG8MyITQJmRCSJEmaQnKcBbvZQF3XsQmhVsoyHVxQ5KYs08GftzdNKHAXYzaQnfjePgnMS9Y7JNTK5aySJJ1GFd0VBMOBsXbzpv4AruoK6mYvpz8Kma6YceNrLr+VkdgESv/8hN69S43i2b2ZrlmLJu0oA9C48jL233APO+/9Cppp8q5RrYvX0DFnKQXP/x57x5HtuEIISuyX4TEXI4SgLMNBe2CI2q4BYi1GEmsqR+sHnXhdCM1goHn5pSQd2IWtW/8lJsOufwr9UvW2Ka8bDA9S56ulZ6h7rFX68XT3D9PdP0KhJ446fx0Amb16nAMefTtUaefzqDYXLLnvhOOfEbFuVLuHrJFamuL07la5r/2Fub/5Pld/8x5+9voPSO1p5tBF151Q2/NAWjbpPS1ER/TtVM3BZrpCXTj8GsN2G0LhnNkyJknntFl63bXC7nVTDlna9CtsI70ol39vQq03AGxOlNv/ijExi2v3fYZljb8ETR077c8qwNlUgyGcQftQDQD72vzkJNqxW/RabKFIiBfrXiTbuhyzcuR1K9lciIpKRkovVTIhNIFMCEmSJE1BCEFO8vhOY3Vd/VS2BrhqXhoANy/KpLqjn4pm/9iYfa0BilPiMCjv7ZPAsYSQrCMkSdJptKl1EwKFdIte08dT8Q6KqrLFqxeHznSOr3sStcVQdc0dOOqrSd/6Os66A1iCvkm3ix2mmUw0rLmKkTjH1IEIQeWtn9Dv+fZLUw4rSY3HbFDoHRghM9qPvat18vpB76J5+cVoQiFz0ysA5Mbrq1q2jm5HmMyB3gOo6L+k7Orc9a73OPxpdKEnjlpfLQAp3XqL5X5PBmgaWYFyRO75YDp1Haimi0idS0roID1JeqImZ93fSKjeQ3lSAc9fdjdvfuOXtC65YGy8QR3m1oq7uKjmO5gj41/b+tOzSexpxTCsf7pfH6jHN9yHqz+Kah9NLJ4jW8Yk6ZyWmIeaMm9s29ixXIOHWND2J5j/MUifuIp0jMOLcverMPdmljc9wbX7P4sloq9C9GcVYvX1kBZ0M4KP7lA3la0BSo5ajf9aw2sMRAYoiBlf0D7JpCf74x2tVLfLhNCxZEJIkiTpOHKSYsclhJ6vaEMI+NAcveXvlfNSsZoU/rxdr6Wgqhr72gLvuaA0gCdeX5EkO41JknQ6lbeVk2TKwaLoqxpTdm5kICmFclMSzhgTcdaJK3paF6+hL6eYwr//loxNrxA1mematVA/qWlk+LYhtOiE697NSLyT7tIFpOzcOKGW0GFmo0JJahwA83oPAdD7LvWDJjPsTKJz9iLS33kNEQkTY4xHibqoC1RNec3e7r0AGIWZnZ0Ta10c62CHngQpSomjxleDWYnB0dXLUIKLqC0GZ6gB+3AXIuf89xz/TBApc3AO1iGSXHx77cO8+dXHuOeqr/Or8+5AXH4VQy73uPFFXS+TGtzD3I5nuWPXreO2ggTSs1HUKBm+ARQs7O7aDUBifxhDrEAz2iDGhSRJZz5l9nWkBCuJHxpfRsEa9nFl1VfAbEdc/O/vPpE5BnHdL+BDPyDbv5Xbdt9Bcn8Vviw9YT+3S389Km/ZQ3NfaFx5hmcPPku8MYUUcykAIholad8ObEo88UYPmrmBVv8QwaHwKXrU5waZEJIkSTqOnCQ7zX2DDEeiaJrGP3a3sjjbRUqC/kluvNXEZbNS+PuuVobCUZr6Bukfjrzn+kGgr0iSncYkSTqdhiJDVHRX4DHPAo5sF2srW0mrf4hMZ8zkFyoK+2+6D/NAgPTyN+kumU/Uoq8kyunbyE2Vn2BRy+9OKqa2BauwBvpw1h2Ycsy8TH2lUWlHDWFrDIGMnJO6V9PKtViCftx7tgIQo2UR1BoIjUyejKrsqSTWkEiKeRY7Ot49IVTVESTBZsIdZ6HWV6d3GGtv1lcHAZn+0e1pOeedVPynXcpsDFqEuZY2ymO9bA7H4gtFWF2QNHFVrKaxsO1PqMklcM/rxMQ7uW7fw6yt/jqWsJ9gWjYApYOdKNFEdnTs0LvbDYSw2FW0+LQT2nomSdIZYNZ1wPhtY+ZIPzfs+xSu4WaUW34H9qQTm0sIWHwP4uMvEmeMcPPe+xlOSUY1GCntGQTgxYPl+m1HP4Dd1bmL8o5y8m0XjNXqytz4Txb97Bs4aypJNOXTHdG3mlV3yPfZR5MJIUmSpOPITbKjanpnsaqOIDWd/Vw1N3XcmJsWZRIcivByZftYQen32mHssLxk+4SaRZIkSdOloquCsBom1aKvsPHs1reL7S1YRDiqTagfdLRAZh5No92k2o/aLpbb+xYAy5p+RUKoadJrj6dr9mKiJjMpO96ecowzxsz189Mp6jj4nusHHa27ZD4hZzLeDXpx6WRLLoq5my31LZOO39O9F6uWjTKSQ52/lsBI4LjzV7cHKfLEIYTQW84bMojtbB6rH+T1l6PGZ4Ar96TiP+1S5gIwS2lkJKqyua4HryuGnElq5qUHdpA0UI2y7AHIWIhy/1tw3hco6f4nd+66lVibj6jRRNFgB+qIk56hHuxDYI1GiLENIxxyu5gknTWc2ahpC8e2jRmjIa7d/xmSBw8ibvkd5J7EKsjMJSjX/RxzdADP0AGC6dl4O5pRh5PY0a6v1rTGdPLwGw/zsZc+hk2Jp/DwdjFNw/v2i3podftwmwoJhLsRxoAsLH0MmRCSJEk6jsMtYuu6Bnh+dxuKgMvnjE8ILc9NJN1h4/+2N1PZGsCgCAo9cSd1v7zkWFp8IQZHIu87dkmSpHdT3lGOQMFjLgYgZddGBpJTeXUkAbNBmVA/6FjVV9/OgWvuoL1stKOLppHn24jmXY5isnBJ7XfhBLtxHRa12OiatYiUXZsQ0am3neUbhojraqU3f9bYsVX1P2Fu2/+d+D0VA00rLyWxuoKYzla89gIAXq2duPonMBKgKdhId7ebqoZENDR2d+6ecmpN06jqCFLgiaVvqI++4V7SQy6MQyEGUjJAU8kMbEfJPf/sWQnjykUz2ijQ6gGIRDVWFyRN2j1rQesfUa1OmHOzfsBogQu/hrjvDaxKhLLOv9Kf6iXb18pwSO+u5hr9PS3WEkDIgtKSdFZRZl+Pu/8AiYO1XH3gC6QFKxDX/xIK1578pJlL0ISB9MAufFmFJLfWog2m4VNrcGQ9zT3rbuXt5s2Uxd7M9e7HiDHo20xd1XuIbW9GEwJH3QGSzfpzuy22hSpZR2ic950QEkLUCyH2CCF2CSG2jR5zCSFeFUIcHP16BvfQlCRJmlr24YRQ9wDPVbSyIi+JpNjxXXQURXDjwgw21HSz7kAnBe5YrKaT+7Q6d7SwtFwlJEnS6XC4fpBZsY9tF6suXkJdzyCLc5xY3uW5LGKzU3/x9WOdw5IHqrEPdyLmfxTlkm+Q6S+ntPO5484xmbYFq7AE/ThrKqcc46zRPyHuLdDboccPtbC45bdcVPefXH3gc1jDvhO6V8uyi1EVA5mbXibVphcf3dUx8b6V3fqxwf5UoqFM0BS2te+Yct72wBDBoQhFKUcKSmf1mAG9oHTywEGsYf/Zs10MQDGgeWaTHdE7ps1OT5jwmgj6v0Ve73qURXeC+ZhVZqnzEBmL8Qzqn/in9bYQHdF/VUgM6Iklu9knC0pL0tlm1rUA3LjnAbJ8WxBX/wRmX//+5jTb0VLnkRHYhT+rANPwEJldCSjGIKrtAPNib+Qm9+MsiL9lrA4egPftFxmJiaNt4Xk46qtwGbwoGEh0tcsVQsc4VSuELtA0rUzTtEWjP38ZWKdpWgGwbvRnSZKks06CzURSrJnndrfS0DPIVfNSJx1348IMNA32twUoTT257WIAeW79xUzWEZIkabodWz/o8HaxP8cWEW81UpZ5nI5gU8g5XDQ4/xJYcCeadzlr6v+bmJGe9zRP16xFRMxWUndumHKMq6aSiNVGMEPfbpXdt0k/seJT5Pq2cPvuj5Dhm7qF/GHDCS465ywhfcvr2NVYDGoCTQMH0Y5ZZVTZM5okGs7k8lIv0aFUnqvaNPmkTz1F9drRVsyfuoe6V/8IQGqPvuJpICWDTL9eA+OsSggBSuocUkMHuWF+GucVTF4TpKztGRAKLL530vMidR7OwXoGUtKxD/iJD+gr0RL9enLJZItAfPr0PABJkqZHQgZa5lJiIj64/Hsw/6OnZFolawUp/ZUEvXqtuHkdyQy1XUv+0HdYGP9hLMr4VfmWvm7ce7bQvOISeormYh7sJ6GrG5cpG4VqqvceAkWB7Gx46qlTEuPZbLq2jF0DPDn6/ZPAtdN0H0mSpGmXk2SnsjWAURGsnZUy6ZhMVwzLcxOBk68fBJCdaEcIZKcxSZKm3bH1g1J2bqDP6WGnOZlVBUkYlff+NjG3byNq6nyI84CiIK76MWZtiDWHfjBunCUSYHnjL7hr+3WsPvQjTNHBcedVs4Wu2Yvx7NqEiE6+hdZ1cC99uaVoBn0VU07fJlRHNlzyTcS967DZHdxY+SArGh5HUY+/Dbdp5VrM/QFSdm8mTskiYmya8Dy8p2svWjiRbGcSBZ44HEohnSMH2VDTMX6yp56C++6jWtWTHIWV5dS8/gwW1YSro5eI1cZwvItM/zZUVwHEp73bX+uZJWUOlkiQkpgARsPE/0ZM0UHmdD4HpddAwhRJndS5KFoUJVFfWZbVpXf9cfqNqEJgtKkgt4xJ0llHXPXfcOsfYOn9p25S73IM6ghxNh9hm52SvnbCvmWkxCZOOjxz48sITaNp5WX4cvTt0I5DByjoMBEUDXTbYumxxkFDA9x33wc+KXQqEkIa8IoQYrsQ4r7RYx5N09oARr+6p7xakiTpDHe4jtB5hck4YsxTjrt1ib68/WQ+VT/MajKQ6YyhTq4QkiRpmh1dP8gU9OM6uId1njmkO2NYY67ivvLLub7yIZY2/pJM39YJSZtjWcM+UoJ7UIouO3IwuRBx3hco6n6VnN4NWCJBljf+gnu2X8Oypl8Rn5jCotanuHPnLeT2rB83X9uCVZgHgriq90y4V9qW14ntaKZzlr443aCO4A1sRym4WK/HkzoX5YH1MP+jLG3+Dfduv4oLar9Hun87QptYl6inaB6DLjep29/CbclDsXSy5VDbuDE7OiqIDGaM1Ygrc5chlDCf//uL9A8fSThpjzzCc96F/GrxtaQFOnGFAtS5DeQ1h4hrbSCYlo2iRckM7ETJOzvazY8zWlg6eaB60tOlnc9jjgQRyz7xrnPExuuvdUUBPfnmCiiEY6wIBbllTJLORu4SKP7QqZ3TuwyA9P7d+L355HTVA+CJt04YKiJhMje9QtesRYSSPAy40xmJicNZd4CLXtlG2KyimLtYl79Uv2BwEB555NTGe5Y5FQmhlZqmLQAuBz4phDihda9CiPuEENuEENu6urpOQRiSJEnTIydJr+sz1Xaxw66el8ZfH1zBwqz3VzYtL9kuVwhJkjTtjq4f5KnQt4u9kTKH8wqSKO5+hRh1gExzgOVNv+TGyk/y4JYLuWnv/VPW5snp24RAg4JLx59Y+TBqcjFra745lggyFVwAD2xA3LsO7nqZmHgn1xz4PFft/wKxw+0AdJcuIGK1kbpj/LYxe3sTpc/8nJ6C2TSt0ouVpgd2YoyG9K1qh5ntiGseg4/8GVveCuZ1PcfNex/gvm1XckHt90gINR8Zqyj0FswmoaGaDFseQmi8VX8kEdUd6sY30gXDGeQkxoCmkWYtAaA3UsWjH/1XUBT2la3klhUP8NA1XyJpoI/H//YfANSkWyisDxLXWk8wLRtPf6WeYDvLtosB4C5FEwruyRJCmsqCtmdQ0xZAxuKp53Bmo1riSdQaGUpwURDsJjrsJjGgoMWOfvAy1eoiSZI+WOxJqIkFpAV2488uJLm7mY/OcxNvM00YmrJrM5agj8bzrtAPCIEvtxhH/QEW79aT/HlD7/CtC++mLW50hVFj4+l6JGek950Q0jStdfRrJ/AssAToEEKkAox+7Zzkuic0TVukadqi5OTk9xuGJEnStLmk1M3ls1O4tHTy7WKHCSFY4HVO2m3lvchNjqWuqx9VfW+deSRJkk7UsfWDkra9TYs9CWtxMe54K1n+cshbg/LgZsSX6uG2v6Csepj0wC6WNP9m0jlz+jag2t2QWjb+hNGMcvVjWLUhTPnnw/1vI275PaToxaDxLkN54G24+OvkBbZw585bSAnuRTWZ6ZizFM/uzYiIvqVIGRmm7Nf/j6jZSsUdnx1rN5/dtwnNYIac1RMDK7wUccvvEF+shRt/jS1vOfO6nuP6/Q9jUIfHhgW8+ViCfjIH9KT+nu59Y+f2dOoFrD2WAhY8/RgLnngUuyERVziWguHNPJ23ivuv+QpXXvolDiZl8Z1//oR//PazlLVV47Mb6EkwkdttwTQ0SDA9C6+/HA0B2ZPEe6Yzx6A5cyddIZTt24wj1ICy7BPH75wmBCJlDp6BKoLpOWT7Whk89C+4AgaMdgXVlgim43e4kyTpg0PJWkF6cDc+bz6KqpLnb5l0nPetFxhITqW76MjrkC+7iNj2ZhxaInGDUeb53yCiGPni5Z9GA/B6T8+DOEO9r4SQEMIuhIg7/D1wKbAX+Adwx+iwO4C/v5/7SJIkzaR8dxw/++hC7BbjablfXnIswxGVFl/otNxPkqQPnqPrB5mCfty1e9mYMY8V+UkkDDWTMNSMyL1QH2xzQMHFcNG/wbxbKWv/v7FVPIcpaoRs3zsohZfqxTqPlbkY8dVWxK1PQerciecNJlj1GcQn38FgNDG3/S8AtC9YhSk0QGKV3t695K//Q1xbA3tuf5jhhCP1I3J8myFrJZjtE+c+zBILs29A3PJ7xEeexhFqYEnTkeSW36t3GEtt6cOInZ7wIfoGRgD4Z005miYocRaTvG8bSQd2ooRHWLi3h8GEDoo663itYCm373iBN5+4l49UvIJBUwGoSxstlJyib3sIpueQ6d+GljIHYlxTx3sGU1Ln4h48OP6YGmFhyx9QYz1Q+u7lQ0XqPJIGagimeXH3tWGMKiSFAlhiIrJ+kCRJ43mXY4kEMbj1VUGOhoMThsQ11+E8dIDGVZePex3y5ep1hHavvYlZ9cM0pGt89Y3/4e2cBfx+yTXw6KOn5zGcod7vCiEPsEEIsRvYCrygado/gf8ALhFCHAQuGf1ZkiRJOgF5yUda3UuSJE2Ho+sHmbdsQNE0fEvOw24x4vVt1QflrplwnVjzFRRgWdOvxh1PDe7GEglCwdqpb3oiRaqd2YiiteT1bUBoEbqLywjb7KTu2EDK9rfI3PgydRdfT3fJgrFL4obacA0eQhRccpyJj5F3IdrcW1jS8iSJg3pL+GBaNqpiIKGphnglG4O1hZ1NfQCUt+1GG3Ezl2HM/QGUSIT4ploW7+mh22Hih6/8O28+cR9fX/cECcMDoGmQlQVCUDNXLxptidFr4oTcHtKCFShn43axw1LmED/UgiUSJGGomZUNP+Xe7Vfh9W9FWfYgGKeut3dkjrkY1SHU5FgMapTCvibskSFsthCKQ9YPkiTpKFnLAXBrdYScySTUV00Y4n3rRaImMy3LLhp33O8tQFUUBhLiiXEv42CGlRv2v8zqtn1858J7qF/7we5/9b4SQpqm1WmaNm/0zyxN0x4dPd6jadpFmqYVjH7tPTXhSpIknfvy3HrNotpOWVhakqTpcXT9INeerXTanKQt0LdweX3lqHGpkFQw8UKHF7H4LmZ1Po8j1DB2OLdvI5pigrwL3ndsovhKrGEf6YHdaEYTHXOX4ql4h9l/fJy+nCIOXnnbuPE5h9vN57+HhBAg1n4HrPFcUvMd0FRUs4X+NC8JjTWkWPNQLO1sPdTFcDhK10gtseSQ2HBkm5Szdh+FPaMJfK9Kpv+obmNZWVBfD6pK3RfvxiSsJLZ1MZiUgidcjUENT5pwO2uMFoW+cbsDuq0AACAASURBVO8D3LX9Oha3/BZb1kK49WlY8akTm2N0pZgtXt+2t7jjAAB2s1+uEJIkaTxHFmpsKumBXfiyC3HUV2Pt7SS2tR5H3X6S95aTtm09rYvXEImJHbvMEgkQtVgJpufgqDuAUvghogbB3kOb+d6P/wWjxcTnH3+NaE7OB7YV/XS1nZckSZJOUqLdTILNRK3sNCZJ0jQ4un6QiITJbdzPvqxZGI0GhBbFGyhHybtw6howqz8HRgsrGn8xdii3byNkrQBL3PsPMP9iNIOV/J43AGhfsBrjUAhVMbD7zs+jGcZv3832bUJN8E6ewDoeexLK2u+QGqxgbvtfAfBn5hPfWIvbnItQomxu2sdzlZVg6CcjphBHfRVhawwDyWk46/bTdtlDxIai7CqIOTJvTMy4LQi1fbU4jBnEtTYQSMvWt4spRvAuP7m/nzNBWhma0UaSMQQXPIJ4eC/itmeg+IoTWwkGkFSIZrDgsHWgGo0s7dQTQlZLCOJlQWlJko4iBCJrOZnBXfizCrD1dbHm3+9l1Xc/zbL/+jILf/FtlEiEhvOOdDgr6H6NB7ZcQuJADb7cYhIaqkkzFGMQJt5sfpPUBBvfTPKzbdDIL90L9ZWdH8BW9DIhJEmSdIYRQpCbbJcJIUmSpsXR9YPs1ZXYIsO0F+lbsJIHqrGG/cdfvRLrRln2IEXdr5LcX0X8UAuuwTpE4WVTX/NemO2Qt4b83vWgafQUzaW9bAUVd36OIZd73FCDOoLXX45ScMnxixhPZd6taDlrWN34U+zDnQS8+ZgHg3iDCQBU+w7wzN7NAOQnlOA4VIU/u5De/FIcdfs5eMFVpEUz2Vnq0O+flQVPPAG3HVnFdNBXQ5Kair2rjf70bLz+ckhfqNc0OlvZkxCf24/y6d1w/hdPriOYwYTmLsUdOkgwxUuOTy8Sa4yJyhVCkiRNILJWYB/uxL9gDpW3PMCe2x5i591fovzBr7P5s99j/dd/QX96NqC/NpzX8BgKKjl9G+nLKcY4MoyrvYM081xea1iHpmlc+/0vclnVRn64+qPUukafxz5grehlQkiSJOkMlJccK1vPS9I5rH+kn4HwzPw/fnT9oNidWwgrBoZn6wmh49UPGmfFQ6hWBysbHyenb6N+rPA49YPeI1F8JXHD7SQPVKMZjOy6+0vj6gYdlhbYjSkagvyLT/JGAnHVf2EiyoWH/t9YYen0Fj9G1YRqamZ3RwVCFaxav5u41gZ8OcX4ckswD/Zj72jGnrqamhQjgSGfvk3sqGSQf9hPz1A3eb12hKYSSknBE9yPyDn/5OI9k9icY13eTpaSOhfPQDXB0V/iAIy2KCTIGkKSJB3DqxfmTwlX07TqclqWXUxH2Qp6Subjzyka94HB3Pa/ED/UgmaOxevfii+nBABH3QG81iW0DbRS1VeFaGzk2688jtBU/mfRUbWEPkCt6GVCSJIk6QyUlxxLV3CYwFB4pkORJOkU8w35uPG5m/jSW1+akfsfXT8otXoXe5NySUzWV8Rk+baguksh1n38SWwOlFWfIadvE4tafo/qyoPEvFMXZNHlaEIZ2zY2lSPt5t9HgWZXLmLNl8nveZNkSz2q0UjO2y9TVD+IwdqKYmsls03jvF99H6Gp+HKK6MstBcBZtx+PuRgNjYquiglTH/If0uPs0lcvxcYFEKjvL95zSepcLJEAYbfebS0aY9VzTHKFkCRJx3KXolriSQ/sPO4wc6SfZc2/Rss5HzH/Y6QHdhNOiGPIkYjj0AG81sUIFF5vfB28XpIG/Vy7702enXUBfstop0qvl6Zg02l4UDNPJoQkSZLOQGOdxuQqIUk6p4TVMJ9b/zla+ps50DuxS8p0O7p+kLW3E09vK9VZczAaFAzRIdKDu1FyT7Aw9JL7UGM9xA+3oZzC1UEA2JMgcxn5feuPOyzHt1mvxfN+t18t/ySqK5/5XX8hkJaDe/9Oymr8GCwtGC1NLKnqJWzQV8P4sgoZTE5lOC4BZ+0+kk0FCBR2dk78JaXGVwNAavsAEbMVj6EWzWCFzCXvL95zRco8AExOTf851qTXV3q3hKQkSR88igHhXUZGcNdxhy1ueRJr2Ie45BuQez5GdZjU4F582UU4Dx3AZkjAYy7mtYZ1er23mBju2P48IbOVZ+ZeCjEx1H37s3zorx/i2YPPnqYHN3NkQkiSJOkMJDuNSdK56fvl32dr+1Zcxhw6BzsYiY6c1vsfXT/IuWcbAJ0lCwFID+7GoI6ceKcwcwzK+aOrnIquOOWxipKrSBqoISHUPOn52OF2Egdr31u7+akYTCi55+MZqCLgzSOiCErqh8AQAeMwc+pDDNpsmIeH9Q42QtCXW4rz0AFMio1EUzabWzejadq4aWt9tZiEBVdbB/1pWXgGqtBS5oDR8v5jPhd4ZqEJhfg4HwAGu0CLS3vfW9EkSTo3Ce8ynIP12MJ9k563D3eyoPWPaLNvhLT5kLUSTRjw+svpyynG1tuJxd+D17qEg75qmq4+D554gtIYlSVNe3lyyTVEf/EET+b0YFRMnJdx7q/mlAkhSZKkM5DXFYNREbKwtCSd7Z56Sm9jqyj89foC/nDgD8yyX8ns2KvQ0GjunzzZMV22tG8Zqx8Uv2cb7TFOLLk5gF4/SFNM76371aK74L71kLP61AdbrHeLyet9c9LTJ9tufkppZZgjQcKpLlSDgeKmI1t2S+sGGbLZMHKkcLUvt4SY7nYs/h7yYy5gT/cefrb7Z+OmrPPVkWBI1zuMpWfjHjyIkjrn1MR7LjDHoCUWkKTWE0zNwuyMIuR2MUmSpuJdAej14yazvPEJDEQRF/2rfsAaj5a2AK+/HF9uMQCOQ1VkWfVVmq83vq7Xfauv5+Nfvp3m2CT+Nns+/6h7jiWJa0m0JU7/Y5phMiEkSZJ0BjIZFLyJMTIhJElns6ee0tvXNjSwM8/Gtz5kZtm+QW7b5iLemApAU+D01ijY2LIRt7kAS9RMWt1etnuKSXXYAMjyb4WMxe9t+5UQkFY2PcE6s1A9cyiYIiGU3bcZNT4DkotOzf1S9cdhcUUBcA1aMYdVrMMq3i6NqMFAw9KLuKjmu3yo6iv05R4pUloSczkFtgv52e6f8dKhl8amPOirwTuYjHmwn4jbgTkShJS5pybec4SSOo+UwSo2femHJM/pRzhkQWlJkqaQvgDNYJm0jpBrsI7Znc8hFt8Dzuyx40reGjz9+xhK8RA1mnDUHSDO6CHRlM26hnVj4y4p9ZCWYOWnO/6XqBrl/JQbT8cjmnEyISRJknSGykuOlTWEJOls9sgjMDjIm4X5PPCZfGKDZpasL6B9006aOvUkTGPw9HUy6RvqY1/PPtIsZbhqK7GEhzmYMxeTQcEa9pHcX4XIu/C0xXMilJIrSQ1UEDPSM+54WmAX2f4tJ99ufjLuEjSDBaetnajJTO3SCyhujjKnLoQ/WU/gHbj8Zgp73yCv9y0G0jOImsw4a/chhGCF4z5SzKU8suFrVHRVEBwJ0hXqJK/LCoDJoer3kQmh8VLnYh/uxBb1ETvSCfEn0cJekqQPBqMF0uaTHpy4QmhVw2NoZjuc94XxJ3LOR9GipA9W4PcW4Dx0AACvdSm7unbRHerWpzYo3LTETSdvkGpcRLL1g/FcJBNCkiRJZ6i85FjqewaIRNWZDkWSpJPR2IiK4NOfLGLAaqKl91M8uuYhHl1xGxuqQgjVelq7mLzT9g4aGumWMlx7txFWDPiL9aK+Xn85Au3d282fbsVXItDI7X1r7FBJ54vcWPkgSkI6rP7sqbuXwYTmmY0nVE0gI4coKiXLfkPemqfZc+m1hG12zPERrOE+DOoI7lC1XqS0br9+uTBxofML2BQnD637FBtbNwKQ1aU/h8fH9qEJBTylpy7mc8Fogiy7bxOKFpUdxiRJOi6RtQJPcD8f23Ubt+/6MHfsvJmP77iBvN63UVY9DPZjtnllLkEz2vD6tuLLLSa+qRYlPEKWdQkaGuubjjQvsLrKEYYhNN8J1tI7B8iEkCRJ0hkqL9lOOKrR1Bea6VAkSToZXi9vFeSjJjSwequVLT/4LOU/+ShvPP05Cj1xaOFEGgOnb4XQxpaNWJU4kkx5uCq3U5GUhzvZoYfq24pqideLcJ5JPLNQHVnk964HTWVFw8+47OC/I7zLUO55FRzeU3o7Ja1MLyydmU98Ux124SDG4MRx6AC+7ELSBvaOjU3376Qvt4T45kMYhgYBsBriucj5FfrDIR55+xEAUtr7GXS5SY4cQkssAJPtlMZ81kvRayrlHU76JcgtY5IkHUfZRxDFV5CUkU9iZjGu7Lk4chfB8n+BZQ9OHG+0gHcZXv82fDnFKNEIztp9OI1ZxBs9rGvUt42Fo2H+7+AfsEQKqGtxMTgSOc0PbGbIhJAkSdIZKjdZr+Oxvy0ww5FIknRSHn2Upy4qBODeV/aTPOjDER1i/4fvxRFjJjzsouE01RDSNI2NrZtINc/B3tONs7uVbe5i0hxW0DSy/FsROavBYDwt8ZwwIVBKrsLr38qVVV9mafOv0ebfjvKxZyHGdervlzYfc6SfcKoT48gQsR0tGEKDxLY14ssuJi2wC9XmQk0qJCO4E19eCUJTcdRXj03hNGWyxvFZImoEo7DgbG0jmJ6NZ7AaJVVuF5sgxoUan0mW7x3954QPxjYNSZJOUlIB3PoUfPhp/evNv4WbfgNrHwVzzKSXiNzzSRysZTA3g5GYODI3/hMhBJmWJWxue4f+kX5eqn+JzlAH8+KuJaJqbKjpPs0PbGbIhJAkSdIZqiglDmeMic/8aRc/fLWa0Eh0pkOSJOm9uO02dsw1YRqMp6y+j4A7jVcf/jZVF11FvNWIOpJI20ALEXX6P4U86DtId6iLdGsZSfu2A1CbNw+L0UDCUAvxQ62I3DN0iXzxhzCoYfJ73oRLv424+sdgME3PvUYLZFtd+r9JfGMNjoZqhKbhyy0mI1iB8C5FyV5FWqACX1YBmlDGto0dlmGdz2rHp5hvuZrYzlZCKanEDnfI+kFTEGlzManD+g9yy5gkSadazvkApIf20LziEtwVW7D2dpFlXUpEDfN2y9v8es9vcJm8zHIsJS3ByhsHuoiq2gwHPv1kQkiSJOkMFWsx8uKnV7N2Vgo/XneQi37wJi9UtKFp5/6LkySdC/a2tTFsq8NpXcF/v3yA//n9G1RddBUA8VYT6kgiUS1K20DbtMeyqUVv0Z5u0RNCbfZEjJn6dqts32j79tw10x7HSclcCsseRHzkT7DioVNXRHoyycV6YWlLOxGzlYTGGhz1VWhCMJzuxhFqQGQuA+8KzNEBXGoLwfQsHMckhADyYlazcmAxQlMxuEbfcqfIlvOTESl6LSvVHAfWhBmORpKkc07qPFRLAl5fOY2rL0do4N3wEm5zITYlgR/t+BG1/hpm2a9BCMG8TAfm9mberOqc6cinnUwISZIkncFSE2z8+MPzeeb+5STEmPnkH3Zw6xPv0OqTdYUk6Uz3m50vIYTKrISVE85l9LXg7tNXuZyOwtIbWzbiNGUSp8aRWF1BubuIdJe+tH525z9QPXMgMX/a4zgpigEu+y4Urp3+exlMaClzSBk8QMCbpyeEDlXRn+LFMzK6Lcy7DLKWA5Ae2ElfTgmOQ1WI6MRVnHEthwCwJ+g1huQKoSkc3konVwdJkjQdFAMiZzVZ/q0MOZPpmLOEjI2vYAxHyLQuprW/lVhDIrk2/fV6QaidJ9Z9j8zNr85w4NNPJoQkSZLOAktyXDz/0CoevW42e1r8fOv5fTMdkiRJ72JT+xuIaALZscVjx6y9ncx98gdc/qPP8+lNbwPQNM11hEKRENs7d5BmLsNZU4kxPMI2TwlpDhvu/v24+6tQFt4xvStvziJKWhnugSr8mXnEtRzSC0rnFJEW2I1m0Fsek5CBmuDVE0J5JRhHhsaSP0eLa6knYrbgMragxqVN7H4j6UYTZUImhCRJmiYidw1xw+0kDDXTuOZKzINBUre/RZZ1KQAl9isxCBMiEmbe0z9BcyaSd+PVMxrz6SATQpIkSWcJgyK4bWkWd63M4aW97VR3BGc6JEmSptDs8xMUlTi0+QihYAgNUviP37L6Ww/i2f0OA8lp5AQ6EaqRxuD0dhrb1r6NsDpChqUMd2U5IwYTzVkl2EwG5rT/Dc1ogzk3TWsMZ5XUMszRASIpTgzhEUyhAXw5RaQHK/QaQ0YLAEr2SjICu+jLKQGYUEcIIK61gf5UL56hGoQsKD21+DQ0RxbCXTLTkUiSdK7KXQOA119Ob/5sgqlZZK1/gQxzGRe7vsws+xUA5Lz2LHGtDfju+wyG+PiZi/c0kQkhSZKks8zdq3KIMRt47PWamQ5FkqQp/Hr7PxFKmKK45Xh2bea8bz5A7qt/oX3+St7+18dpPO8K4kZCOIKuad8ytql1E0ZhxmMuxr17CzvdhSQnJ2CKDlLc/TLMugZsjmmN4aySNh8Aq2tk7FDAm4O7fx/Cu+zIOO9ybOE+YqwDhFxuXNV74Ogab5pGXMsh+tO8OAfrEXK72NSEQNy/Hi782kxHIknSuSoxHzUuFa+vHISg4fwriW85hKtuP17rYhRhxN7WSP7Lf6JtwSqGlkzc7n0ukgkhSZKks4zTbuZjy7N4vqKVuq7+mQ5HkqRJvNG8DqIxFMXNZtYff8pwvJNNX/g+e27/DEPOZPpTMgFI7bDREJjeFUIbWjbiMZfibGnF5utmY8os0h02CrtfwxwdQCy4c1rvf9ZJLkYzWEk0txK22RmJiSXe5sOgRcC7/Mi4LP2XhfTATjrnLMazZwsLfvFtbD0dAFgCvZgHgmhJMQjUI3VypMnZnGOrryRJkk45IVBy1+ANbANNpXXx+YzExJK1/jn9vBpl9tOPETHb2H/jvTMa6ukkE0KSJElnoXtX52I2Kvz0jdqZDkWSpGMEhkJ0RXcRq84lsaEO80CQurU3EfAWjI0Z8KQDkNKh0NLfjKqp0xJLW38b9YFDpFvK8FS8gyoEW1NKSXfYmNPxN9SkQr1IsnSEwYiWMhvPQBVdsxbSOWcJaQN79HOZS4+MS8xDjUkmPbCLA9fdzf7r7sJ1cC8rv/MQ2a/9lfhG/fnZ6hhdaSQ7jEmSJM2snPOxhn2k9O9DNVtoXn6kBb337ZdwHqpi/433MBL3wVk1KxNCkiRJZ6GkWAsfWZLF33a10NgzONPhSJJ0lCd3vI4whMiLWY57z1ZUg5Hukvnjxgw5khgxW0nv0RiODtM12DUtsWxs3QhAumUe7oot1KbkoyU48EbqSQ3uQVkgi0lPRkmbj3ugiorbP8Pej36atMBu1MQCiHEdGSQEIms5mcGdaAYDDRdew4avPUZPcRnFf3+Sef/7fQAS7L2olnhwZM3Qo5EkSZIAKLoM1ZLA0qb/AaBptAV94XO/o/Afv6OrdCFti84HwBD+YKzClwkhSZKks9T95+diUASPvylrCUnSmeTFulfRVDOzXYtw7y2nt2A2EZt9/CAh8CWlkdEXApi2wtIbWjYQa0gk1WcivrWejZ5ZpCRYmdPxNzTFDPM+PC33Peul6YWlnaFG0FTSgxUoWcsnDBNZK4kbaiNuuB2AIWcyO+/9Kjvu+QrhmFiCqV7c0TpEyhyZeJMkSZppNifKqofJ7dtAWmA3oUQPnXMWk7ZtPQiovOUTIAQJoWZWvXABVP5tpiOedjIhJEmSdJbyxFu5ZVEmf9nRTIsvNNPhSJIEjEQiNA+XY4uU4uzpIbajmc7ZSyYdO+DJINMfAKA52HzKY4moEd5p20KqZR6ePVsBWJ9cQmacQmnXS1BypWyDPpXUMgA8/ftxheqxRAKQOcnWutEkUbp/57jDnfOW8fa//ZwtD3+H5MGDsqC0JEnSmWLpA6h2N6saHgNNo/6Ca1AVhapr72TIlQyaytqab2EQGmQsnulop51MCEmSJJ3FHliTB8DP35S1hCRpxj31FH++7kIwBrjizWZm/fV/AeicM/kbyqE0L0mhIDHDyrSsENrTvYeBcL9eP2jPFrrdmbTbE7lQ24IlEkAsvOOU3/OcMVpY2j1wgPTALv3YZLWWPLNRzXFHxhxFNZmJowdjdEgWlJYkSTpTmGNQ1nyJ9MAusvs20Zc/ize+8yRNqy4HoKztGdIDO1Au+w9ISJ/ZWE8DmRCSJEk6i6U7bNywIIM/bWuiIzA00+FI0gfXU0/BfffxbLEVTTXwiRfKSd/+FsPxLoZc7kkvCaXqncYyu+KnpfX8ptZNCBRywtk4a/ezJ7sMRcDq4IuojmzIPu+U3/OcYTCipczB03+AtEAFakwyuHInjlMMCO8yMoITE0IA7oEq/RtZUFqSJOnMseAOVGcOqxt/CppK2B4PgCPUyOqGn6IVrIWyj8xwkKeHTAhJkiSd5R5ck09U1fjt5voJ5zRNO+3xSNIH0iOPUB8XobrIh6M7iaRgiCGLhaSOtglDzZF+ijtfwho3DEB6p3VaWs9vbNlEkimPjH37EZrKBk8p8+09eAPbURbeDop8G3g8SloZnoEDZAR3IbxLp6wBJLJW4Bqswxr2TTiXPFCNZjBDUtF0hytJkiSdKIMJ5cKvkTRwkKLuVwAQWpS1Nd9EMVkQV/3oA1P3Tb4TkCRJOst5E2NYmZ/EP3a3jiWA+kf6+eRrn+TZmmdnODpJ+mBoHmzjzq/kExUKN7+kMRAbC0Lg6tSLDZsiAxR1/ZOr93+OB8ov5fKD/8Yq/y+JKAZSugRNgcZTmsANjASo7N5LmmUe7oqthJxJbDO5+bBxPZowQNltp+xe56y0+Ziig8QPtSAm2y52WNYKgEm3jbkHqtCSi8Fonq4oJUmSpJMx63pUz2xWNv4CRQ1T1von0gK7Ua74HsSnzXR0p41MCEmSJJ0DrpqbSlNviIpmPwB2k52+oQD/tf1HBEYCMxydJJ3b2gfaufur+fRbTQw13MWtW3cQtMdiiEQIxztZ1vgED5Sv5YrqfyUnfBDDkvtg1nUkhWrpdbhJ7Q4zEBnANzxxhcnJKm8rR0XFK4pJOrCThuJFRNUIl4TfgIJLIC7llN3rnJVWduR778QOY0fGzUczWEkPjC8sjabhHqhGkfWDJEmSzjyKgnLx10kYamZVw2OsanwcrfAymHvLTEd2Wp10QkgIkSmEeEMIsV8IUSmE+PTo8a8LIVqEELtG/1xx6sKVJEmSJnPprBTMBoXndrcCIITgX+Z+Hv+wn8d3PT7D0UnSuatrsIuP//MuehMsOCqvYt6hAMkDPgbsduyhENs/fjdLm3+NMe98uOtllM/sg8u+AyVXY9AiDLkSyOgbBE5t6/lNrZswCSsldYMYwiNUZJexWqkgIdqDmP/RU3afc1pSEZrRhmawwvG6hBktkLGI0q6XKO18HqFFALCPdGEL9x3/WkmSJGnm5F+M5l3OwtY/oJhtiKv++wOzVeyw97NCKAJ8TtO0EmAZ8EkhROnouf/SNK1s9M+L7ztKSZIk6bgSbCbOK0zmhT1tqKq+7STfUURRzMU8feCPHOw7OMMRStK5pyfUw90v30PHQBfLE/6VmphlnNe6jwG7HdVgoPqSG7DnBxGaCld8X+9Sdbhuz+jqE7PLQEp/EGNEo3GSOkID4QG6Q93vObZNrZtJMc8itWIbYZud7QlebjWuR7UlQsHa9/W4PzAMRrTMJZC98l23fIm1j2JJ9LL24De4c+ctFHe+hKd/v35SFpSWJEk6MwmBuORbaOZYlCt/+IFcPXvSCSFN09o0Tdsx+n0Q2A+c+33ZJEmSzlBXzUulzT/E9sa+sWML4j+CWcTw3S3flQWmJekUiqpRHnztQZqCLVzi+ioBn/4WqPehz7LhIw8QNZmpvOF25nb+DQovA2fW+AmcOaiWeOITQhg0jdQ+QXOwedwQTdO475X7ufrZa95TF7KmYBPN/U2kG+eQvLecztmLGQz2cZGyA2XeLbKezXug3PxbxE2/efeBaWUo96+HW/9AfFwclx/8N66ofkQ/55k9vUFKkiRJJy9zMeKLh2D2DTMdyYw4JTWEhBDZwHxgy+ihfxFCVAghfi2EcE5xzX1CiG1CiG1dXV2nIgxJkqQPtItLPFhNR7aNAViVOObH3Up5RzmvNrw6g9FJ0rnlxUMvsq93HysTPkGKZRa1Xf04Y0w4Y0y492ylu7iM3OBGbCO9iCX3TpxACETKXNx2/T1QVrd9wpaxdY3rqOjeTX+4n4f/f3v3HV5VlTVw+LdvTe8JqRBaCD30jhQFpIjSRBm7oDOO2P0csTvYdewVsWJBFAQEEem99xZKSCEhvddb9vfHvSIoINWEZL3Pc5/cnLL3PmelnKzssuQ+yu3lZ9S2NelrAEhI98ZSVkxGq870qlyCGbtMJn22PAPAw//MjlUK4odguHMljPkcY3AjnNGdwcPv4rZRCCHE+anD/yg574SQUsoH+B64V2tdBLwHNAYSgAzg1ZOdp7X+UGvdUWvdMTQ09HybIYQQdZ631US/+DDm7cjA7nBSuWQxntkZNPO6gmBzLC9vePmM/6AUQpyazWHj7S3vEGJuSCPPHlTYHBwpKKdxqA8+6cl45meT1boz7TK+wxnUGBr1PWk5KjKBepbDOFFEZVtIKfq9F5DNaeN/m14n0BxD/6CH2Z+fyDNrnjmjnn5r0tfgYwym0a6DOExmdkW1YJRhGYUBLSBceqtcdAYDtBiO4a61GG6XRLwQQoia67wSQkopM65k0DSt9Q8AWutMrbVDa+0EPgI6n38zhRBCnIlhbSLJKali/Y5kSic/TcInL2OyO+jidxtHy47y8Y6Pq7uJQlzyZuyfQXrpEdr7jkMpA4dzS3FqaBTqTdiO9Wil0LEBRBRvx9B5/O/zBv1RRAIWQyWF3r5EZp84qfTM/TNJKU6mg+846nt0IsF3DHMPzeWbfd+ctm0Op4N1GeuJMLeh3o715MYnYCw6SEtDMsb2N1zI2yCEqAH7XQAAIABJREFUEEKIS9z5rDKmgI+BPVrr147bHnHcYdcAO8+9eUIIIc5G3/gwvC1G5hwqxueJp/FPPUizmVMJt7agkWcvpu785E/zlAhR26QWpTLkhyH8dOinC152ma2M97d+QISlJVFW18TQh7JL8bIYiTbZidqwhMIGcbQs+Rlt8oS21526sIi2AFQFeBGRW0lBZT4lVSWU2cp4d+t71LPEE2PtCECCzyhirB14cf2LbM3aesoid+fupthWROu8CDzzsshs04WOBfOowoRPx7EX7kYIIYQQ4pJ3Pj2EegA3AP3+sMT8S0qpHUqp7UBf4L4L0VAhhBB/zcNs5IoW9Zi/8yiGHr1J6n81DVbMJ3zTCjr53QDawP8tf0SGjola7dk1z5FSnMJjKx9nR/aOC1r2tD3TyKvMpYPfOJRS2B1ODueW0tIHOr/7FJ65WSRfMZT4nAWotmNdc9CcSnATnGZvrAFOIgpKUU5NanEqX+z+gtyKHDr63YByL3+rlIHegRPxNoZy75L7Trny2Or01QC03VeMVorcFu3oU7WUHT49wSvogt4LIYQQQlzazmeVsZVaa6W1bnP8EvNa6xu01q3d26/SWmdcyAYLIYQ4vaFtIikos7H+cB6Jw24gv2E8rb5+m9DcCnoF/JsdOdt5cOmD2J326m6qEBfc0tSlrDm6ksqcvmi7H3cvnkhWWdb5FTptGsTGUuhrZurqN2hRHEOYpRkAqfnleJSXMHHe6/imH2bL7Y8QEZyCyVkJJ5tM+ngGAyq8NYF+JVgdDkILYVv2Nqbu/IQGHp2pZ4k/4XCrwYd+gQ9RWFnE/UsewOa0/anINelrCDE3ImrnVvIbNie0fAuBFJPdZNT53QMhhBBC1DoXZJUxIYQQNUevuBD8PEz8sjsTbTSx7ZYHcZrMJHz8Eo2M7enmP57lR5bz9OqnZSl68fdyJ1YwGFwfp027oMVX2Ct4ft0LKFs9qrIvpzj5BgorS7hnyb1UOirPrdBp02DCBEhO5uMrgym1wlOvraLZojkAZCan89LK9wnMSWfz+Elkt+xAwtHv0fW7Q72Wf1m8ikwgwucoAFG5mje3vEm5vZwOvidfDSzIHEsP/3+xJXszr2589fc2xsZS6mViW/pGuiYa8UtLIqtNZ5of/ZEMHURIm0Hndv1CCCGEqLUkISSEELWM1WRkYMtwliVmY3c4qQgMZfuN9+OXfpjmMz4i3nsgCT5jmHVwFm9sfqO6myvqiuMSK2jt+jhhwgVNCn2y8xPSS49Qmn4V7esH46wKJ7TiZnbm7DjjFbr+ZNIkKCvj9jET+WxgPa5YX0bzpCJ6fvIa5sI8bvvhZSJLc9h8x2PktGhPbP4a/CvSTr7U/MlEtMXbpxSA2FwPiquKaerVjwBztGu/1q7XcRp79aKF92Cm7ZnGvC8mHbuvG+O8sJsUI2esA6C4WVOal25gprMXLaNluJgQQgghTiQJISGEqIWGtY2ktNJBcl4ZADkt2nNwwChi1iwkYsNS2vmOId5rAB/v/Jgvdn9Rza0VdYI7sVJq9uDnuG5UGk1QVubafgGkFacxZcfH+Ng6QnkTOsYG0TjEh5SURrTxHsPsg7PP7Ws9JYVsrwBWdCvFYVT84vswUztchTU3i3ZvPUloaR6zr3uI3PgE0Jr2GV/h9KkHzYedWfkRCZismnKrhegcMyZlpZ3vGNc+rWnz+Wt0f+FerIV5J5zW2e8mwi0teLLiRxKDHKT7hvBd90ZYq5wEF5swORw0ZDMGnGwJGoynxXj21y6EEEKIWk0SQkIIUQt1bxTEI54/Up60/liviAODryevcQtaTn8fr7wsuvrfTqxHF17a8BI/J/1czS0WtV6Ka0n1RwbdzZ3XTGLgre+yuFFHV0+hCzCM7KX1L6G1oiBtIA1DvfE0G2kb40+F3Ym1ZAANPLrw6sZXmb5v+u89hc5kCFv9+myKaYjZfyPtdniQkJzNM5dP4PUrbiYoM4UXO/0Dc3vXSmAts+bQoGA9hh73gNF8Zg0PiUMbPajyNROd7U2fwPvxNgYDELX2VyI3Lsc3I4VObz2Opajg2GkGZaJP4P34ltq5e2Iso294isUJwfhnhVPu4Yl/QQHxOQvYppsSFvvXQ9eEEEIIUfdIQkgIIWohk62IcR4rea3qaSpTNgOgjUZ23HAvAK2/fAODht6B91LPEs+Tq5/iSMmR6myyqO3q12dufE/mtLiMETsWYdAObh39FLeMepJDRbbzGka2Im0FS9KWEK2uorzClxYRfgBEBXgS4mNhe1oRvfz/Tbi1Jc+ufZbbf7md1C/fObMhbJMn80uXcJTBwfif9/P59Cf46MfnGJiyjpURrTnSoiNWs5GA8hT6Jr2Cju0NXf555o03mtDhrfDyt1Evt4D61g4AeGZn0HzGFA5Fx/PaoIl45GfT6a3HTkgKeRkDefybKtJDLBS0mI/RmkWLg4EopZjZtR+hpYnMsnclIeY0K50JIYQQos6ShJAQQtRGnoF4jZ9PucGHf6U9QFDRXgDKg+uxZ+R4gg7sInbJbEzKwmUB92B3Opm04jGc2lnNDRe1VdZTz/HYgLtom76Pl+a/wc9T72bSko/ZEN2Sgbe9w0u9b8SJOuthZOkl6Ty37nkCTFEUZXbD22KkicVOq2lvEZi0l7bRAeSUVJFdpBgY9ATd/e9ga9YORpS/xxc9PJnXrCtFFi9XYSere9w4tnUNRNk86b43n+KwSALr+WA0Gtlx9S30ahKKwWlncOLjGM1W1DXvu3ocnQVDZAKhfgV4VZVhKS5AORy0+eJ/OA0Gnmwxil+t0UzuNQHP3Cw6vf04lmJXUkhrzdt9JlORNQyDTzIAE1ZuosxoobKNFadWzHVIQkgIIYQQJycJISGEqKWMQQ04Mnw6JdqDEbvuIqR0PwBHuvTjaJuuxM39Ep8jh/ExhdHF71Y2ZW28IPMJHSo8RGJ+4nmXI2oPrTWP0JRyLx9e3fItJjSWmCjGr5/J4o8mMGTvSt7tNobFjTu5TnAPLzudpMIkHlv5GIN/GExGaQYJXreSnFtJq1BPOkx9gei1v9Lp7Se4LHMnHiYDW1MLUMpAvPcArg59nQ57S3lpXAQP3hPEa32Pm+/nD3XbnDayPfZjdbThrZ/3Mvv/XsD7aAoHrryWhi0aE+prpVvqB9Qr2Y3hqjfBP+rsb1BEW3z9ygHwOZpKo4UzCEzax2edr6XEP4jhCZFsC2rE091vxTPnKJ3eegJzcSFrD+WxCT8G5zdm6PpKmqRWYlZW7PUbc73PZvZ4tCEgLIbGoT5n3yYhhBBC1HqSEBJCiFqsQ0I73q3/OiUOM6N2/ovg0gOgFLvG/gubpw9tPv8fymajiWdf6nt04o3Nb3Ig/8A51VVcVcyL61/kmh9HcOvPt1LlqLrAVyMuVdM3prJ4bxb/N6QlTXasA6cTDh+GBg0IKy3g5XmvE1Kaz3etL3edUL8+ADaHjVJbKYWVheRX5JNTnsOunF08uPRBhs8azk+HfqaZ10BGhr1Dfm4DtFNz05qvCTq4m92jJ1Ac1ZCOn77MbdkbOJhTQlGFDQCTM5DsnH9TfuRajB7pLOpV8Xtj3XX/ZnXaBrShnFBDewxVlbSYMYXi8BiS+14FQFThJjqlfYZudwO0GH5uNyiiLVY/V9vC1y2h8fxvSGzVjR+CWtK1UTCxwd6M6RjN/sh4nuhyK57Z6SS8+ghHduylZaQfDfr1IHT4HEZ4TkIrRWbf7oRUptBywK0svP8yDAZ1bu0SQgghRK0mCSEhhKjlxg/vzw32SVRiYvTuuwgqS8Lm68/O6+/GL/0wTed9hVKKHv7/xIQnj6z4DzaH7YzL11oz5+Achv4wjGl7phFhaUNhVSGLUxdfxKsS1eZMJmI+7rjUgHCe+WYD3bxt3Nw99sRjJk8GLy/MTgcjdi5mUZPO5ASHo//7Xz7b9Rmdp3Wm61dd6flNT3p/25u+0/sy9qexLEldTmufaxgd9h5d/W/D2xDMrvRCbk9ZTsPNy9h/5XWk9B7C+rufJat1Z4Yu+5rbdsxhZ2o+ReU2vtuYxraIOF76dikNDwaRH5lCnrcZvLxcbTrOj4kL0U4TsV7taPzLd3jmZbH72n+ijSas9iIG738SHdQINeiFc7+noc1R3kbsJgP11y+m0i+IF5tdRZC3hUE+ScTlLCTAy8K1HWM42rgVj3a9HVNxIW8ve4PryxJRSqGUInzHBmye3kT6HUIbTND8qnNvkxBCCCFqPUkICSFELRcb4k2/Ht0ZWfYIRoOB4XsfwuwoI7tVR1J7DKThopkE7t+Jp9Gf7v53si9/L+9te++Myk4qTOKm+Tfx6MpHMekghoW8yBVB/8HHGMLM/TMv8pWJv920accmYtanm4jZfZwzOYUHB9+Lcjp5+Z17MHz9FdP3TWfEjyP5+fDP6Ouvhw8/hAYNGL1zEXajie8ff51nGx/ilY2vEGFJoJPfTXTxu4WufrfRzX88vQL+zeiw9+noNw5Poz8AR4sqaLl/IyO3zCG9Y28OXnktAE6LlS23/R/JvYcw8sAyBvzwDjPXHqS0ys7w9jF4XHkl/beaUAYbU0cluNoybtyxy9Basy5zOY7SJjSpKKbhrzM50rkv+U1agtZcfuB5vG25GEZ+BNbzGJZlslAR1Aztq9Aovh9wG+kOMzdEZzFqz0SG7HuUzqkf42k2MKJdFJUt2/LUsP+jLDqW9p++QvyMjzBUVRK2Yz3ZLToQn78IGvcHr6Bzb5MQQgghaj11bOnVatSxY0e9cePG6m6GEELUWkUVNvq+vJSr/A/yRN4j7AobysKmT2CsLKf7i/dhKi9j3f0vUhYawYr8tzlYvozPB39O29C2py33up+uZ39eEp18b6CpVz+Ucv2fYXPR12wr+Z4FIxcQ4RPxd1yi+DvExkJyMq/3uI4fWvZj0ZQ7MTsd0KCBawjYH477vmU/Hhh6Py/Ne4MRuxby8vimfNXNitXgQ6WzhF5RvXms6yQifSIBGPbOr2RYP6DSvJc2PtfQwff6Y19Tp5O4dC13zHyZkvqN2TTxvzjNlhMP0JqAud/R9Zdp5Hn6kzjoWgovG4Q2GimusPHNkQcI8zOx5Lo5KPX78KrE/ERGzh6JPWskH67ci3/KAVY89i5VfgG0PzKNyw6/Dpc/DT3vPe9bWzbjLgrnz+ULzzuZ4p9AJ798ptgfxertj4rugNr5PeujbmJVg7vA3UZlt9Hsx8+IXTqH0pBwvHOOkjx2DIN4Ha75ENpee97tEkIIIcSlTSm1SWvd8WT7pIeQEELUAX4eZu67Io5P0mNYGHwDrbLm4Ng+g8XJJbw/8C6000GHd5/CUlxAF/9b8TIG8eqGV09bZnpJOjtzdtDa+2rivC8/4Q/3pl790GhmHZx1sS9N/J1SUtgY1Zw3u48lJTCC9TGtjm3/43EAc5v3IqbgKIMOLOLf9zbgq25WWnoPZWy9KXT2u5m16esZPms4n+36jNSiVIqDXqPClEgb63g6+v3jL5NBzooKrAt/4sa5b1Hi7c+2CY/iNFsIKE9h9I4JxOavch2oFPlDR/P9TY+jw8LpOvNDejx3N/W2rsbXasJY2o1cWzLbsredUP6SlCWgFc0LogjZt41DA0ZR5RdATMF6eh9+E938KuhxzwW5tR4NOhARU8Bcv0h8nQW85ZyM1aQw3PADasQUdIdb6HzkM/okvQru1QC1yczekbez5daHsRYX4DCZCQ9KRhs9IH7wBWmXEEIIIWovSQgJIUQdMbZTDH2bhfJwzpVs1XHcUfQmRekHWFLmyX863oKlII8O7z+Lp00R53UFW7K3kF6Sfsryfk3+FYBYz67HtnnmZtLyq7fpNHsukdY2zNw/6+9Zyv5M57UR56W0UVMeGHIfEcU5eNgqWNiki2vHHyZipn59SiyerGqQQPeMpdz4WCPWtfDh4e9L6eJ/C0ZlppXPMK4J/R+h5pa8svEVhs4cSok9j8q02yjObn/KNhRX2Di0Nxnn1A/o/tht9J39Ifkevqy89VGqfAPwrsxm5O67iS7awrC9jxBRtB0ApRTeHTuy4YEX2Tz+UbTBQLuPX6TrKw/RsrgJOK1M3zf9hLoWpSzGURFD/9REtDKQ3qkPfhXpDE2chA5pirr63WO9dc6XIdLVG689e/nK+3UC7TkYrv8WghuDwYAa+j/oehftMr7l8oPPobTj2LmZ7Xqw6pE32XD3MzQrWQbNBoLV94K0SwghhBC1lySEhBCijjAZDXxyS2e2Pj2YhHtn4O1hZlrQR/yzZ30qmjZncodx+KYepO3Ul2hs6QbA/KT5pyxvYfJCgs0N8TNFYC3Mo/n0D+j17L+IWbOQ2CWz6VrQmozSdNYfXX9xL+y4eW043bw24rw9P+F5UgLCefWn/9Hz8FZ+ieuKPslEzEyezPJmXbF757J84Fay/U28/WY6wS3uOuEwH1MYlwf+h76BDxLt0YEhwc/RyDuBfZnF2B3uRKLWeORnE7x3Kx5zvyfkjcmMf/c+Bm2Zz5HIxsy+cRK7nnoHa5MmWO3FjNgzER9HIVz/HQb/SK7eez9BZUm/V6oUWW26sOo/b7Bj3ER8stIYvXUhVYUJ/Hx4AYWVhQBklmayJ2839qJ42u9fT25caxw+Xly172EsBieG676+sEmXsJY4MDDZPJU4+z7UqCkQ0/mEdjNwMvR+iNaZPzJ43ySs9uJju8tD6uEXVIxnVR6q1agL1y4hhBBC1FqSEBJCiLoosAGGYa8TUbyDXulTGNYmktKO3Xiz7SjCdm+m6/QZ1DPH8dOheSc9PbM0k63ZW4nT7Yj78TN6P30HMasWcKRrf1b+5w3sFis9Vh/GavA++eTSZ9mj57Tz3U2aBGVlHPUJ5s3uYym2eEJZmWv7edZbp/zFvVmemM2XeVZuDamiq6GYAfvXku4Xxq43Pj5hImYAxo1jwfX/xid0JmaHnQ/eLaHwykns6z/sT9UqpWjo2Y3Lgx4hwBxNiwhfonJSCZvxKd1eup/LHxxLnydup9M7T9Jnwed0ytrHoW4DWPH4u6Te/wyWTp0xmYwYHRUM3/MAweXJGMZOg7gBGG74AYvFysjdE/GpzDyxYoORI137k9btCprt34hPektszirmHJwDwLK0ZQA0Tg4kID+LjA69ufzgZEJKEjGMnOLquXMhmT2wBTXDW1W4Vixr/ud7hVLQ7zG44lma5i3lpq3X0jBv5bHdzbJ/wWnxgaZXXNi2CSGEEKJWMlV3A4QQQlSTViPRB5fQecunpPp3pF+zTmz0GMwXFYXcsP4XRgV04p0OW9ifv5+mgU1POHVRyiIAxk7fQXjiXjI69ObA4OsoC43A6dSkdulPg9W/0LpPHxYm/8qjlYX4W10rQv3Wo8dRXkGlyYLXbz164E+JhSpHFf9d+18Wpyzhvz2fpU9Mnz9fh3u+mscG/JNfm3Zlflx3PpnxNOEpKSxPW87ilMVc3eRqEhbuctVTVkap2QPv09Rb57hjYi+voMLsgc9v92bVKpg3j8LMXB4e/x5NAv245+7BvDcgi93ZiRgW2fmlQXta/aE4m8PJYo6AbzJxfhNY+PoQlMOB/+FEgvbvwCcjhSoffyr9g6gICKLSPxitFGE7N9Br62om5BzFqRQFjVuQ1v0KcgLD+THPQnZgPQb2bImn9cTHF6XtDEmcRGTRVtSoqdC4r2tHUEMM/5iB1yeDGbH7Hr5t/SGVJr8Tzk3peSWxS2Yz6EAKC+IbMH3fd4xrPo7FKYsxO0PpczgZh8lMvXpHaJ7xM/R9DOIGXpQwePR7CIqPQtc7T39gj4mohr3wnPlPrt5zH7vChrCywd3E5S1BtRwKZs+L0j4hhBBC1C6yypgQQtRlVaU4P+yDPf8IM1u8QbpfW/ZmFNJ16ou0zjvIHRMd3Nj+Nu5pf+LEuTfPv4Xig2n89+009g+5noODrkVrzcHsUtbszyC6NJcX5r7Azn79ebbzUiZ1mcTY+LGuk90rUD3VfwLzm/VgyUcT8LJV/mmlquyybO5Zci87crajbYEocz7jW4/nroS7MBqMvzcmNpaVBPCPsZMZumc5Sxt1xJs04n0/Y3NjBwoDGieDdtgY80MRHyXcyqImnfl8+hP0SN725xWy6iJ3TO4Z+iBzmveiffpe+h7cSL9DG4nPSuL+Ifczu8VlvLh2Ep/fFkwSuQCE2IbhUXol8+/pdUJxK/dnM2HRjQSayrj/wJWE7N9F0MFdmCrKAagICMZcWozRVnXCeU6DkdxmbVgT1YavzA0Z2a8VFqOB6RvTKK2yc23HGAK9T1xBTGk7lx94nlZZs2HwK9B5/J+v79Ay9JejyPBpzvIGEykzB1JuDqTK6A1K0fGdJzGkHOaecVdSGfId7/Z/l4lL7sFU0I23Pt5AZVw8PVvNx9CkH2rs165eVDWBvRKWv4xe8Ro2gxWLowzGzZAeQkIIIYQ45nSrjElCSAgh6rqidJyfDsNReISZzV/niH978lat4fpvXuCTofXZ0kXzy6gFx5bjzinPod/0ftyzqildV+5l2TNTSDf6cGTvenqXLuBq02pynH7s29qOmLREHppYD/9gL74b5p6w12AgwyeIyyZMocpkZtLijxm/YaZrOIzTNW/Mrpxd3L14IvkVhZSnj6GiMI7AmJ+we6+lS3gXXuz9IsGewQA4vpzGkKWFlJiszP7iX7w2KpYf+3iitYk46wg6hwxiR/EcdhV+j91gROd0wSOtEyElFfz0yURM6GP11ljTprmGwKWkuCZwnjz5wvZqMhjYENmc0f94iV5Jm8n39GNneBMAwopzyfL3prP9LfY2zyGs0Enbxk9yoHwZh8tXU3xwIsvuHUtMkNex4sbP+JS1pa/y5C9NablpDyVhUeTFtSavaWvymraiyjcAtMZUXopHYR7WwjyMleXkN2mFzduXwnIbn64+TO8GXiQVaY4UlHNNuyiiA71OaHZU4Rb6Jb1CSGki9H4Y+p1kmOBvdv6AnnErit+fexzKRLklmLVVI4n6ehbPdhnHvv5zCPDwIas8ixbrBvPU4tnkjexND/M3cOdKCG994e77hZK+Beesf0FFEYZ7toLRXN0tEkIIIUQNcbqEkAwZE0KIus4vEsMtP8GnQxmx515mxb+Ks2sX0ueF0WN9GfNbF7AtexsJYQkALE5ZjMHhpN2WVLLjEzAnzWJs8c+0MhzGbjZjaNiTwENLWF0/gcaJJVy1uy0ftFzH3ry9xAfFU9qkPk/06IgxahahHOWdkeH4+oTQvMqXJrZSlqYu5YlVT2JVfsRW/R/lh7K4qnwV71dcQVSrZmzK/JrRc8bwVPcnMSgDP4aUcKj5Hrrmb2T05IZkBZppVdCIfSXj2Frigapfwb6jXSl1NKWJ+TOOxq7C4r2aA9kT+KbtQP6Rv7uaA/AX3MO5Ch0Kq8GEx0UY6uas34BnLhtPeHEOH8ycjJetkkyfIJY0as+MntE4Ynay16Occb/m8u8fspn6TVPqV3rzhWEbHpEz+HlXb8b3ciWQ7A476wumEXc0kJab9nDo8hEkDr/pz5Uqhd3LhxIvH0oifl+lzOC006lkCSO9vqB15l62OxuyN2IgBV7DKMWVEPKuzKL34TeJz1mA0y8KRn8GLYaf/iJbjUBFtIXcg1CWA6U5GMty8d7xHa2MS0jxC2bIofXkX9GNtPJFWJUPPfenUWH1oqnvZpwBbTHUxGQQQGQ7DHeudPUYkmSQEEIIIc6Q9BASQgjhUpKF87NhOHOT+LH5qxSsTKX7gi/4v1utdOk9mkldXb0vbl9wO54rE/nXd9mU9PKjU9RejnjGEdD9Frw7jAWvIDLevwbf9FVsXtkez6pyJtxeSLuI9hiViY3p67ErB6YqI5HZDpIjzCiD7YSmhFta0NPvPgq+nMttW2di1E5KrN5MaTEE09Xt2Wp/iyL7cZMEawN+5lD8jJG09R1FPUs8luRDBH07lZZpu1nRtBvGxs247b3HSYyAR+6IITnMC8Phq1nWJA7/G6//O+/0Walo1IQp4R14p+sY2mYk8tU3kzCgL+hQtxlvT+fBNG/+N+cVrtm9FIBdDT15aWw4m5t50zS1gqc+OULjDMiuF0GJtzdKa364YwzT/acTbh/DwtseB+C9jdN5b+czvPJZMKGlNlY8/i4OD6/T1O7iVZVD66MzaZv5A95VORR7xfBVURuu8j9IROleNIojfu3I9ImnTeZMTDhRPe6BnveB5a/LP6X1H8G8B1mYfQPRixbx6i0TWRf+LlH2rkz+3wbyWrbiiuZzTj0cTQghhBCiBpMeQkIIIf6aTxiGm3+Cz4Zx9Z77md3+v1T9aqbfel9mxCzg4c4PU1xVzIbMjTy7LYgiLx86R+wlufXdNBj53xOKChv9Gva3OqEbVuCzKosrk1szR20gwBSNj70vGekNmfHlx7Q9sIsRN77CoZgALutopsiRhkEZaWW+nMip79F210pSmrUnffAYmsz6jHu3TGdf2kbib/43B0KL2Z+u2ZNmYkxCC8L9XUkBz5yjNP3pNSI2Lcfu4Ulqi0702bMaZ8om1g8eTatVi/jsuSRu/k8LDjX6gfu8xzP1b7i9+/L28c7Wd6nnFcaYZmP+NFH3Me7hYTolhV+6DeW/A/5DakA4bdP3sbZBG6Z2vIrbN/54bDLtc1FYWciUHVM4VHCIJgHN+LLSSUufEIaXHuZokJk3b2jInHYWAoscPDU1nV67oNgvgpT6FhwmC2nd+hO6ezNDvlrAin/Ek+49k12Z44gLieHzPR/Sa7M/MRlZbLvxvmPJIKUdRBZtJS5nETHFmzE7KzE6qzA6bRicVZgd5Sic6Mb9ocsd+DS5nJ5HSwiP8IPcg6id3xO5/Tui079Cx12JGvQ8BDU853twTNvrcP76NNENjmA3GElYvwPLjXcRvCwbL/tKDE0q0UYrqtXI869LCCGEEKIGkR5CQgghTlSWh3PqIEq+1VSIAAAYCUlEQVRKilmx4zLCt63izoma/w15n8zSTN5a8CTvvOsktVk9BiRsw/DAbvAN/1Mxe6c9RLN9H7L553jKQyJZMvEhDI4APll1mCZhPgxs6TonObeUWVvT6dcsjNbR/njkZZHw0fMEpB1iTsJgzDffjlE5cGDCsmg+HX7+Eh9bBYc79WVNsZEgXy8aRfijjSa8M9OIXvMr2mgk+bKhJF0+Apu3L95H02j246eE7dxAeWAoiVfdSEq7TnyX9jwV5l1cHzeeR7refWyeJHAtdV9mL8PL5HXC9j/5i/l9Kh2VfLDtA6bunIoRTxxU4NB2EkITuDb+Wq5ocAVWo/X3siZM4IBnEE/3n8CKhu2Jy07myUUf0j15G+NHPM7yhu2Y9+lEmvgYz7qHkM1p47t93/HO1ncprirC3xRJgT0d3PPqhHiEUmwrwu500NY8iFu/O0y9XVvQSmGx2TnSpT9bxt0FJiP+qfvo+MZTZMQ05IERqcQGtGBcq6G8uuxZ3nzfgjO8PuvufYGo4q3E5fxKXN4SvKpy0CZPaNgL5REAJgsYrWCygoc/tBoFIU1OfQFaQ3k+eAWd1XX/pZ8fxbnuA37YcDkNkhNZ/dyn1Hv7eepnJdH+mnSsLa5wrV4mhBBCCHGJkUmlhRBCnJ09c+HbcfzqdTdRU7/ngwFWqjwVDkc+sVl+XL3eRthVZQS174Ea+9VJi7CXF5P7Ulvy9nrBFgdrHniZefYgNiflcGdTK9EFR/HIz8ZQVUFicg6qqoLWwR5EbFuN02bn+fbX0XJAB27Jep7owk3sC76cjdE3MTvRQI9F39A/ZSMmfeJk0E6DkbTuAzg4aAyV/n9OGgTt2078rKn4pSWR0a4Ha0fczpcZ72P038TwxsOJ9Y8lqTCJpMLDHC48TLGtCA+jJ/X9Ymjg1+DYq0O9DsT4xhxL4FBW9nslXl7w4Ycwbhwbjm7gqdVPk1KcTIjujs/qxjhDQwhKyCapahGF9gz8Lf60CW1DkEcQwZ9OJ7fch+/jh2Gq8OXOZUsYv2YBFu0ErcnyDmDA7a8SbN5O99bZrPHMomO9jjzf67nTJ62AFWkreGnDyxwuSiLS2pqehlH45Zj5OKmEoPrlNIkuIMd2ELPTyPCdobRaMA9rcQGZrbuQOnAIfj4FRBZvJ6J4J+Elu3EYzCysmEDjGV/zQ9t4vhl8ALPBwrXzzAzbUsSah14hwTGHDulfuZJATa9AtbzGtWS7xfvsvyYvprwk9JvtWFQ+hKgfN7N50Dja/PINh5rHMbz1IrhhJjTuV92tFEIIIYQ4a5IQEkIIcXacTpxvdyK70siRGRYyjWU8cqsThZ033jdhNprpfmXiXy5xvfrHD+my/mH2zKlPuX8IOZUQXZKNyWk/sTqlqDBa0FYPKupF8lT8CFoHZ/KcehsPZzmq5dU4d8/GYCvlYEA3ni0YyNKKpnRvGETnGH8MTjvK4UAbTTisHu7hSdtpkruEsNK9HPFrx8Gg3mT6NAetabhoFk3nfkl5cDhfXHkH863LsYYsA8DbGISfMRI/UyQ+xlDKnQUU2TModhyl2J6JEwcA9X0b0PuX/UTtho3+A+l0ZDedM1dxJMxMWrN6bP/nNcw/PB8/Uz2aH+7PgHkraZ17CCeKrZHNKRw4nKTmHiRWLKHInk6Fs5CyqlycxhPvoV+JndijVcSWmEnzrGJrU2+cBjBqT4IsMWTbEnm2x7Nc3eTqk8ZAa831s+5jZ9EiPKlHX8dw+q5OInrdomPLvld5elMeEk55cD18jyThnZ1BXuMW5PfvSlu1gJjCDa6yDCZ0eBsM0Z1w7vyeIu3Fpj09iVy7lBeGRpAZkcXLUzTJnfpiHhDLwAPPojvcihrwLFh9zulL8e+ivxpL2cG1LJ/TkJiSbIxOB7ZhIbSKyMNw73YwGP+6ECGEEEKIGkYSQkIIIc7epk9hzj0c/d6ffJs3j95oxLtSM+lbJxGNc/BvbkO9lHvaP5SrbA52PdeT0D1HSUmKJtEjFJ9mTXHUb0hJRAzlwfWwWzxxGo18szGNSruTjtE+dEp6lztNc3CGNscw+lMIi3cNFdowBefa9zGU5ZBkbEhFQBNKPcIpsoZTbKkHStEobwVN8pfjWZWHNlohtBlk7kJpB6XWUA4E9uZAcF+Ks71p++krmMtL+bDdCFY1b87ohDisplNPUOzUDorsGRyp3EZy+SayKnbgNDrRTiPK4DjhWIvBk9bOy+g+p5DuO1dS7uHF4aHjsOfm0mD1LwRWFlMUHM6Ry4aQ16g567KrWJdVRcf0TTyw5j1yAyE53MrhcAsHY/zYFx+Bh8GPSHNbyvYHoQ85GRqsWRq1nP3BmXx/1QyifaP/1Oanlr/B90lTCN/fkeFrK+lzZBtaKfKaRFARZMdGPbwNfhgLSvHMycTu4UXBZR1o5bmUmKLNOL3DMHSeALE9ITIBzJ6ugpPXoD8bRrJXO1J+MuGVnUFagD/RhcUkPXQPIw4/gKFBD9Q/vgfjJTBl4aGl8Plwpu6/km6btpHuE0zfITsx9HkY+j5a3a0TQgghhDgnkhASQghx9mwVOF9vjXNzBgc2RbGktRWPKui2r5K4a49iWFEJSyv+spi5v/zClavGMN/ZlVm+Y2mZ0A1OMrwp+WgOWXtW8KDpO9ob9qM73Iwa9MLvCYhj7SqHLV+id/+ILkhDFR9BOaqO7XaavVFxA1HNh7l6L1l9oSwP9v+C3jsXfWARBlsZyQFdWBb2bxp+M42QxO0siW5HflA4zTydBNlKMZcUYS4vxWH1oMrLF5u3DzYvX6o8fThUZWR7kabIYKB14TKC2EGeNYzdgR1wOoLofjiFyObNabp4Fp6VZWxq25eSMf+gYeVG7AYriTTi4IINXL5vOS3yDv/pXiinE4P7pYCielGUBdfDXFqMV07GsZ49AFWeXvznZgPBTeP5dNCnGI9L0M0/tJCHl9/HLfOCuXJ7FjaLlQPNW9M6dgtNPVMpwhs/SgEos4SQ6puAjy2PqKLNOH3qYeh5H3S4+c8x+M3mz2H23Wzyvgb7Fzvwqypjae9h3BQ7Aw9vPwzjF1/4+X4uFq1xvtuVA0cryZpjJTMuiJEtVsM92yAwtrpbJ4QQQghxTiQhJIQQ4twsfxkW/5eMz7zIt/oDEOxTRL3BJTAjAHb/9UpXFTYH3z5/Gzc5ZwJQZgkm2a8jKQGdKbMEE1W0leiizdQr3o1R2ynSnqT0eJFWA246szY6nVCWA4VpYCuDqI5g9jj18bYK2PIFzoVP4nQ6WBl9J8XboNGC7zBoTbHZkzIvP4wBATi9fTBVVWAuLcZQUoylrBizw37qsv9gZ3BDtl11I30jDtHlyKf4VGYe21dsrccGWyN2ZodhKzES42WhnsWAf3ISIYl7MZZWUak8yWkQR1lAIMaqSuye3pSGRlIREkKJoZzczEP0WbOV0gBv7v1HAXd0uYfxbVxLo+/P38/o2dczYrGR0esKSe15BaGtikgomIX2jaC43wvYmgwkpCIFkldB8iqch1eCMmDoPhE63HTqRNBx9LyHUes/YGrhdeTss3F9r+1E6nQMty9y9ey6lGz8BObey7UVk3jZOoWYhs1QN8+p7lYJIYQQQpwzSQgJIYQ4N2V56JebUb7eTvJB16pgjXofxVJuRw16/4TVtE5n0Z5M0g4nclN4MhxaivPQMgylWYB7XpqIdhhie5Do2YY5+Q24f2iHv5wk+bwVpKLn3o868AsZvq1ZVP8h8ixhHExLIyM9jSCKaBPsxGmroKi0HO2wYcZBgAk8faMx+jbEZvekwbqlNFsyF8+ifCp9A9h55Ri2dujD1twKrgrazpUFX+NTmYkzujOGPv8HFl9I2wBHNuJI3YixKPW0zSz2CCfPWp8Czxgs9hLCy/YRUJaMcq8Mlp3hS9ZyP3bGB/H81cVMG/oVUd5RDJ81moTVedz5Sxn5HdrSuuVmfKqyUJ3HQ7/HwcPvwtxHhx395Uich1ey29SCVrYdqOu+hmZXXpjy/05VZdheiSe1wpNGhqMw4iNoM6a6WyWEEEIIcc6qJSGklBoEvAEYgSla6xdOdawkhIQQogab/wjOdR+Q9FUIJkMVDcYWQMSdcMeL516m1pC1G0pzIKpD9U04rDXsmIFz/sMYyvPO+vQKsz+Z3vFke8ehtAOvqly8bPn42PPwrczEYi/GGd0JQ99HoVHfkw6VozTHNT+SwwZOGzjs4KiCoiOQexByD+DMPeB6b/FGRbZFRSRAeBvwi6Dsk5Ec2W7Gvs3AjD7erB8YSYA1CLV6Mw9/b6escUPad1yHIaQRhuHvQEynC3Dj/qAsD+dH/THkH4L+T0CvBy58HX8T+4LHMa15kwqjDx6PHDijXlJCCCGEEDXV354QUkoZgUTgCiAN2ABcp7XefbLjJSEkhBA1WEEK+o0ENoWMJqjiMLH6MIb7dl0aEwWfqdIc2PIFGC3gFQLeweAVTLbDmyB/f4wmMxjNYDADGrL2QMZWSN+KM30LKms32mgBr1CUTxjKJxR8wqD5Va7lyi9mb6eUddinDmHn6ijMKVW8ONpAkZfiyWlgCwkhodduTFHNMNw0GzwDL1478pPh8EpIuP7iXu/F5v561+1vwjDsf9XdGiGEEEKI81IdCaFuwFNa64Huz/8DoLV+/mTHS0JICCFqNj3jNux7fsLkqED1fhD6PVbdTapZnE4wGKqv/s1f4Pzhbjb/2hDKHNgMCpPFk9aXJ2OJaoDh5p9cSS5xZtK3QlCjCzesTgghhBCimpwuIXSxnl6jgOMnRUhzbzu+UROUUhuVUhuzs7MvUjOEEEJcCKrHRMyOctcn7W6o3sbURNWZDAJofwOqxx206ZmMEYVFG2hxWSqWiChXzyBJBp2dyARJBgkhhBCi1rtY/f1P1lf8hK5IWusPgQ/B1UPoIrVDCCHEhRDRFh0/DAwmCGxQ3a0RJ6EGTMactZfmag0OowXPiDAMN81xDV0TQgghhBDiDy5WQigNiDnu82gg/SLVJYQQ4m+gxn5Z3U0Qp2M0oUZ/gqWgPzjtrp5BfhHV3SohhBBCCFFDXayE0AagqVKqIXAEGAtcf5HqEkIIIQSAVxCGO1e4JnW2eFd3a4QQQgghRA12URJCWmu7UurfwAJcy85P1Vrvuhh1CSGEEOI4Vp/qboEQQgghhLgEXLQ1g7XW84B5F6t8IYQQQgghhBBCCHFuqnlZFCGEEEIIIYQQQgjxd5OEkBBCCCGEEEIIIUQdIwkhIYQQQgghhBBCiDpGEkJCCCGEEEIIIYQQdYwkhIQQQgghhBBCCCHqGEkICSGEEEIIIYQQQtQxkhASQgghhBBCCCGEqGMkISSEEEIIIYQQQghRx0hCSAghhBBCCCGEEKKOUVrr6m4DSqlsILm62yH+JATIqe5GiItKYlz7SYxrP4lx7Scxrv0kxrWfxLhukDjXfpdijBtorUNPtqNGJIREzaSU2qi17ljd7RAXj8S49pMY134S49pPYlz7SYxrP4lx3SBxrv1qW4xlyJgQQgghhBBCCCFEHSMJISGEEEIIIYQQQog6RhJC4nQ+rO4GiItOYlz7SYxrP4lx7Scxrv0kxrWfxLhukDjXfrUqxjKHkBBCCCGEEEIIIUQdIz2EhBBCCCGEEEIIIeoYSQjVAkqpQUqpfUqpA0qpR47b/rFSaptSartSaoZSyucU509WSqUqpUpOsX+UUkorpU46m7pS6melVIFSau4ftit32YlKqT1KqYnnc511WXXGWCmVoJRao5Ta5a7n2uP2NVRKrVNK7VdKfauUslyI662rLlaclVI3K6WylVJb3a/bz7J+ifMFUlNjfNz+t071c0KcmZoaY6VUf6XUZve5K5VSTS7UNdc1NSDGU5VSWUqpnX/Y/rJSaq+7/plKqYALcb11UU2NsXvf3e627VJKvXS+11pXVWeMlVIxSqklyvX30S6l1D3H7QtSSi10P3MtVEoFXsjrrksuVozd+8YopXa74/fVWdbfUNWk52qttbwu4RdgBA4CjQALsA1o4d7nd9xxrwGPnKKMrkAEUHKSfb7AcmAt0PEU5/cHhgFz/7D9FuBzwOD+PKy679el+KruGANxQFP3+0ggAwhwfz4dGOt+/z7wz+q+X5fq62LGGbgZePs86pc41/IYu/d3BL442c8JeV36MQYSgebu9/8CPq3u+3Upvqo7xu7jegPtgZ1/2D4AMLnfvwi8WN3361J81fAY9wV+Bazuz+XZ+hKMsfu89u73vu6fz7/V/9JvdQKPyPdxjYxxU2ALEOj+/E/fh39Rf416rpYeQpe+zsABrfUhrXUV8A0wHEBrXQSunjqAJ3DSCaO01mu11hmnKP9ZXD+YKk7VAK31IqD4JLv+CTyjtXa6j8s6oysSf1StMdZaJ2qt97vfpwNZQKi7zn7ADPehnwFXn/3lCbeLHedzql/ifEHVyBi76zUCLwMPn2PZwqXGxthdn5/7vT+Qfo511HXVHWO01suBvJNs/0VrbXd/uhaIPtc66rgaG2Ncz9YvaK0r3cfJs/W5qdYYa60ztNab3e+LgT1AlHv3cFzPWiDPXOfjYsZ4PPCO1jrffdzJvg8vmedqSQhd+qKA1OM+T+P3HygopT4BjgLxwFtnU7BSqh0Qo7We+5cHn1xj4Fql1Eal1HylVNNzLKeuqzExVkp1xpXlPggEAwXHPXye0C5x1i5anN1GHtc1NuYs6pc4Xzg1NcYA/wZmn88fMAKo2TG+HZinlEoDbgBeOIf6RfXH+EzdCsw/j/Prspoc4zigl3u4yTKlVKdzqF/UoBgrpWKBdsA696Z6v/0udn8MO4f6xcWNcRwQp5RapZRaq5QadBb117jnakkIXfrUSbYdy3JqrW/BNcxnD3DtSY49eaFKGYD/AQ+cR9usQIXWuiPwETD1PMqqy2pEjJVSEbiGk9zi7vV12naJs3ZR4uw2B4jVWrfB1dX8s5Mcc6r6Jc4XTo2MsVIqEhjNuT30ihPVyBi7P94HDNZaRwOf4OomL85edcf4rxuo1CTADkw7l/NFjY6xCQjENZTlIWC6u8eBODs1IsbuuWu+B+79rdeKuGAuZoxNuIaN9QGuA6aoP8/Zdsk8V0tC6NKXBhyfeY7mD93AtdYO4Ftc2WrjcZOcPXOacn2BVsBSpdRhXL94ZqtTTCx9mrZ9734/E2hzFueK31V7jJVSfsBPwGNa67XuzTlAgFLKdKp2ibNyseKM1jr3t+7luJKzHc6ifonzhVNTY9wOaAIccP8s8FJKHTjzyxLHqZExVkqFAm211r/9B/pboPuZXpQ4QXXH+LSUUjcBQ4FxWmtJ3p+bmhzjNOAH7bIecAIhZ1mGqAExVkqZcf2dNE1r/cNxuzLd/4T97Z+xMizw3Fy0GLvL/lFrbdNaJwH7cCWIzqT+GvdcbfrrQ0QNtwFoqpRqCBwBxgLXu/9b0FhrfcD9fhiw1/2Fn/BXhWqtCznuF4xSainwoNZ641m0bRauMZJTgctwTZgmzl61xli5Zr6fCXyutf7uuPO1UmoJMArXuNibgB/P60rrtosSZ3A9UBw3FOgqXP8NOaP6Jc4XVE2N8S4g/LiySrTWsgLVuamRMQbyAX+lVJzWOhG44hTni79W3TE+3fmDgP8DLtNal53NueIENTbG/P5svVQpFYdrGH/OWZYhqjnG7rI/BvZorf/YW3M2rmetF5BnrvNx0WKM6/vwOuBTpVQIriFkh86k/hr5XK1rwCzg8jq/FzAYV7LlIDDJvc0ArAJ2ADtxdRv2O8X5L+HKYjrdH586yTFLOfUqYyuAbKDcff5A9/YAXL1KdgBrcP13strv16X4qs4YA/8AbMDW414J7n2NgPXAAeA73KteyKtmxRl4HtiFa4WDJUD8mdYvca4bMf7DMbLKWC2MMXCNu/5t7p/3jar7Xl2qrxoQ469xrfhpc59/m3v7AVxzVvz2u/r96r5Xl+qrBsfYAnzprn8z0K+679Wl+qrOGAM9cQ0T2n7c9+tg975gYBGw3/0xqLrv1aX6uogxVriGXe92lzP2TOt3b69Rz9XK3SghhBBCCCGEEEIIUUfIHEJCCCGEEEIIIYQQdYwkhIQQQgghhBBCCCHqGEkICSGEEEIIIYQQQtQxkhASQgghhBBCCCGEqGMkISSEEEIIIYQQQghRx0hCSAghhBBCCCGEEKKOkYSQEEIIIYQQQgghRB0jCSEhhBBCCCGEEEKIOub/AThGm1FMKRe8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "anomalies = full_data['2012-03-15 00:00:00':][full_data['2012-03-15 00:00:00':].values-prediction['0.9'].values > 0]\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(full_data['2012-03-14 14:20:00':])\n",
    "plt.plot(prediction)\n",
    "plt.fill_between(prediction.index, prediction['0.9'],prediction['0.1'], alpha=0.5)\n",
    "plt.scatter(anomalies.index, anomalies.values, color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare the original training data in same time period again with predicted results that are changed time intervals as 2H."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_prediction = prediction.resample('2H').sum()\n",
    "resample_full_data = full_data['2012-03-13 23:20:00':].resample('2H').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resample_anomalies = resample_full_data['2012-03-15 00:00:00':][resample_full_data['2012-03-15 00:00:00':].values-resample_prediction['0.9'].values > 0]\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(resample_full_data['2012-03-14 14:20:00':])\n",
    "plt.plot(resample_prediction)\n",
    "plt.fill_between(resample_prediction.index, resample_prediction['0.9'],resample_prediction['0.1'], alpha=0.5)\n",
    "plt.scatter(resample_anomalies.index, resample_anomalies.values, color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop and Delete the Endpoint\n",
    "\n",
    "Finally, we should delete the endpoint before we close the notebook.\n",
    "\n",
    "To do so execute the cell below. Alternately, you can navigate to the \"Endpoints\" tab in the SageMaker console, select the endpoint with the name stored in the variable endpoint_name, and select \"Delete\" from the \"Actions\" dropdown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
