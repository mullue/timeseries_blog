{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Contents\n",
    "\n",
    "7. [How to Build the Custom Sagemaker Container for Model Deployment](#7.-How-to-Build-the-Custom-Sagemaker-Container-for-Model-Deployment)\n",
    "8. [How to Deploy Models as Sagemaker Multi Model Endpoint and Invoke the Endpoint](#8.-How-to-Deploy-Models-as-Sagemaker-Multi-Model-Endpoint-and-Invoke-the-Endpoint)\n",
    "9. [How to Do Batch Transform in the Multi Model Server Framework](#9.-How-to-Do-Batch-Transform-in-the-Multi-Model-Server-Framework)\n",
    "10. [Clean up the resources](#10.-Clean-up-the-resources)\n",
    "11. [Conclusion](#11.-Conclusion)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. How to Build the Custom Sagemaker Container for Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by [an example of bringing your own container for deployment to a multi-model endpoint.](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/advanced_functionality/multi_model_bring_your_own), here we use the [Multi Model Server](https://github.com/awslabs/multi-model-server) framework and the [SageMaker Inference Toolkit](https://github.com/aws/sagemaker-inference-toolkit) for hosting the multiple forecasting models at the same time using one endpoint:\n",
    "\n",
    "- Multi Model Server (MMS) is an open source framework for serving machine learning models. MMS supports a pluggable custom backend handler where you can implement your own algorithm. It provides the HTTP frontend and model management capabilities required by multi-model endpoints to host multiple models within a single container, load models into and unload models out of the container dynamically, and performing inference on a specified loaded model. MMS supports [various settings](https://github.com/awslabs/multi-model-server/blob/master/docker/advanced_settings.md#description-of-config-file-settings) for the frontend server it starts.\n",
    "- SageMaker Inference Toolkit\n",
    "[SageMaker Inference Toolkit](https://github.com/aws/sagemaker-inference-toolkit) is a library that bootstraps MMS in a way that is compatible with SageMaker multi-model endpoints, while still allowing you to tweak important performance parameters, such as the number of workers per model.\n",
    "\n",
    "In this way, we can compare all the model forecasts in real-time more efficiently, and can save the cost of creating multiple endpoints.\n",
    "\n",
    "The main steps for building the custom Sagemaker container are described as below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import libraries\n",
    "Before beggining, first import all the python modules needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import jsonlines\n",
    "import json\n",
    "import time\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define model handler\n",
    "The code snippet __`container/model_handler.py`__ below shows how we define a custom handler that supports loading and inference for the GluonTs models.\n",
    "- The `initialize` method will be called when a model is loaded into memory. In this example, it loads the model artifacts at `model_dir` into the GluonTS Predictor class.\n",
    "\n",
    "- The `handle` method will be called when invoking the model. In this example, it validates the input payload and then forwards the input to the GluonTS Predictor class, returning the output. This handler class is instantiated for every model loaded into the container, so state in the handler is not shared across models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "ModelHandler defines an example model handler for load and inference requests for MXNet CPU models\n",
      "\"\"\"\n",
      "from collections import namedtuple\n",
      "import glob\n",
      "import json\n",
      "import logging\n",
      "import io\n",
      "import os\n",
      "import re\n",
      "\n",
      "import mxnet as mx\n",
      "import numpy as np\n",
      "import sys\n",
      "\n",
      "from pathlib import Path\n",
      "from gluonts.model.predictor import Predictor\n",
      "from gluonts.dataset.common import ListDataset\n",
      "\n",
      "class ModelHandler(object):\n",
      "    \"\"\"\n",
      "    A sample Model handler implementation.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self):\n",
      "        self.initialized = False\n",
      "        self.mx_model = None\n",
      "        self.shapes = None\n",
      "    \n",
      "    def load_model(self, model_path):\n",
      "        try:\n",
      "            predictor = Predictor.deserialize(Path(model_path))\n",
      "            print('Model loaded from %s'%model_path)\n",
      "        except:\n",
      "            print('Unable to load the model %s'%model_path)\n",
      "            sys.exit(1)\n",
      "        return predictor\n",
      "\n",
      "    def initialize(self, context):\n",
      "        \"\"\"\n",
      "        Initialize model. This will be called during model loading time\n",
      "        :param context: Initial context contains model server system properties.\n",
      "        :return:\n",
      "        \"\"\"\n",
      "        self.initialized = True\n",
      "        properties = context.system_properties\n",
      "        # Contains the url parameter passed to the load request\n",
      "        model_dir = properties.get(\"model_dir\") \n",
      "        gpu_id = properties.get(\"gpu_id\")\n",
      "\n",
      "        # Load Gluonts Model\n",
      "        self.mx_model = self.load_model(model_dir)\n",
      "\n",
      "    def preprocess(self, request):\n",
      "        \"\"\"\n",
      "        Transform raw input into model input data.\n",
      "        :param request: list of raw requests\n",
      "        :return: list of preprocessed model input data\n",
      "        \"\"\"\n",
      "        # Take the input data and pre-process it make it inference ready\n",
      "\n",
      "        json_list = []\n",
      "        # for each request\n",
      "        for idx, data in enumerate(request):\n",
      "            # Read the bytearray of the jsonline from the input\n",
      "            jsonline_arr = data.get('body')  \n",
      "            # Input json is in bytearray, convert it to string\n",
      "            jsonline_str = jsonline_arr.decode(\"utf-8\")\n",
      "            # split the json lines\n",
      "            json_list_request = []\n",
      "            # for each time series\n",
      "            for line in io.StringIO(jsonline_str):\n",
      "                json_record = json.loads(line)\n",
      "                json_list_request.append(json_record)\n",
      "            json_list.append(json_list_request)\n",
      "        return json_list\n",
      "\n",
      "    def inference(self, model_input):\n",
      "        \"\"\"\n",
      "        Internal inference methods\n",
      "        :param model_input: transformed model input data list\n",
      "        :return: list of inference output in NDArray\n",
      "        \"\"\"\n",
      "        forecast_list = []\n",
      "        for model_input_request in model_input:\n",
      "            forecast = list(self.mx_model.predict(ListDataset(\n",
      "                      model_input_request,\n",
      "                      freq = self.mx_model.freq\n",
      "            )))\n",
      "            forecast_list.append(forecast)\n",
      "        return forecast_list\n",
      "\n",
      "    def postprocess(self, inference_output):\n",
      "        \"\"\"\n",
      "        Return predict result in as list.\n",
      "        :param inference_output: list of inference output\n",
      "        :return: list of predict results\n",
      "        \"\"\"\n",
      "        ret = []\n",
      "        quantiles = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
      "        # for each request\n",
      "        for inference_output_request in inference_output:\n",
      "            ret_request = []\n",
      "            # for each time series\n",
      "            for i in inference_output_request:\n",
      "                l = {}\n",
      "                l[\"item_id\"] = i.item_id\n",
      "                l[\"quantiles\"] = {}\n",
      "                for q in quantiles:\n",
      "                    l[\"quantiles\"][str(q)] = i.quantile(q).tolist()\n",
      "                l[\"mean\"] = i.mean.tolist()\n",
      "                ret_request.append(json.dumps(l))\n",
      "            ret.append('\\n'.join(ret_request) + '\\n')\n",
      "        return ret\n",
      "        \n",
      "    def handle(self, data, context):\n",
      "        \"\"\"\n",
      "        Call preprocess, inference and post-process functions\n",
      "        :param data: input data\n",
      "        :param context: mms context\n",
      "        \"\"\"\n",
      "        \n",
      "        model_input = self.preprocess(data)\n",
      "        model_out = self.inference(model_input)\n",
      "        return self.postprocess(model_out)\n",
      "\n",
      "_service = ModelHandler()\n",
      "\n",
      "\n",
      "def handle(data, context):\n",
      "    if not _service.initialized:\n",
      "        _service.initialize(context)\n",
      "\n",
      "    if data is None:\n",
      "        return None\n",
      "\n",
      "    return _service.handle(data, context)\n"
     ]
    }
   ],
   "source": [
    "!cat container/model_handler.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Unit testing for the model handler\n",
    "Before we build the custom docker container, it is good habit to do some unit testing (__`container/test_model_handler.py`__) as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform linux -- Python 3.6.10, pytest-5.0.1, py-1.9.0, pluggy-0.13.1 -- /home/ec2-user/SageMaker/time-series-blog-draft/.myenv/miniconda/envs/gluonts-multimodel/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/ec2-user/SageMaker/time-series-blog-draft/container\n",
      "collecting ... collected 5 items\n",
      "\n",
      "test_model_handler.py::test_load_model PASSED                            [ 20%]\n",
      "test_model_handler.py::test_initialize PASSED                            [ 40%]\n",
      "test_model_handler.py::test_preprocess PASSED                            [ 60%]\n",
      "test_model_handler.py::test_handle[5-quantiles0] PASSED                  [ 80%]\n",
      "test_model_handler.py::test_handle[25-quantiles1] PASSED                 [100%]\n",
      "\n",
      "=========================== 5 passed in 2.94 seconds ===========================\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd container\n",
    "pytest -v test_model_handler.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define Docker Entrypoint\n",
    "The inference container in this example uses the Inference Toolkit to start MMS which can be seen in the __`container/dockerd-entrypoint.py`__ file as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import subprocess\n",
      "import sys\n",
      "import shlex\n",
      "import os\n",
      "from retrying import retry\n",
      "from subprocess import CalledProcessError\n",
      "from sagemaker_inference import model_server\n",
      "\n",
      "def _retry_if_error(exception):\n",
      "    return isinstance(exception, CalledProcessError or OSError)\n",
      "\n",
      "@retry(stop_max_delay=1000 * 50,\n",
      "       retry_on_exception=_retry_if_error)\n",
      "def _start_mms():\n",
      "    # by default the number of workers per model is 1, but we can configure it through the\n",
      "    # environment variable below if desired.\n",
      "    # os.environ['SAGEMAKER_MODEL_SERVER_WORKERS'] = '2'\n",
      "    model_server.start_model_server(handler_service='/home/model-server/model_handler.py:handle')\n",
      "\n",
      "def main():\n",
      "    if sys.argv[1] == 'serve':\n",
      "        _start_mms()\n",
      "    else:\n",
      "        subprocess.check_call(shlex.split(' '.join(sys.argv[1:])))\n",
      "\n",
      "    # prevent docker exit\n",
      "    subprocess.call(['tail', '-f', '/dev/null'])\n",
      "    \n",
      "main()\n"
     ]
    }
   ],
   "source": [
    "!cat container/dockerd-entrypoint.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Building and registering a container\n",
    "\n",
    "The shell script below will first build a custome Docker image which uses MMS as the front end (configured through SageMaker Inference Toolkit in `container/dockerd-entrypoint.py`), and `container/model_handler.py` shown above as the backend handler. It will then upload the image to an ECR repository in your account. `This step may take a bit long when running for the first time.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "sha256:4ec2e8bc51a6677e7bd6e3cedae6bcdd7fbc0819025fd63af46a40243552fa35\n",
      "The push refers to repository [783128296767.dkr.ecr.ap-southeast-2.amazonaws.com/demo-sagemaker-multimodel-gluonts]\n",
      "c3a8961ea0dd: Preparing\n",
      "a4e5c2f29143: Preparing\n",
      "2ad0f72db02b: Preparing\n",
      "9c5493c63a91: Preparing\n",
      "277c49a9d3ff: Preparing\n",
      "cd31335e8e41: Preparing\n",
      "c1b3849a086a: Preparing\n",
      "bf3f26e338ae: Preparing\n",
      "2ca7984a1779: Preparing\n",
      "dbc5ddf63966: Preparing\n",
      "b255b26a82a5: Preparing\n",
      "8f312108c760: Preparing\n",
      "22144637480e: Preparing\n",
      "24cd7a0a3078: Preparing\n",
      "8980490753a8: Preparing\n",
      "270e75e92418: Preparing\n",
      "2ca7984a1779: Waiting\n",
      "dbc5ddf63966: Waiting\n",
      "b255b26a82a5: Waiting\n",
      "8f312108c760: Waiting\n",
      "22144637480e: Waiting\n",
      "24cd7a0a3078: Waiting\n",
      "8980490753a8: Waiting\n",
      "270e75e92418: Waiting\n",
      "cd31335e8e41: Waiting\n",
      "c1b3849a086a: Waiting\n",
      "bf3f26e338ae: Waiting\n",
      "9c5493c63a91: Layer already exists\n",
      "c3a8961ea0dd: Layer already exists\n",
      "277c49a9d3ff: Layer already exists\n",
      "a4e5c2f29143: Layer already exists\n",
      "2ad0f72db02b: Layer already exists\n",
      "2ca7984a1779: Layer already exists\n",
      "c1b3849a086a: Layer already exists\n",
      "bf3f26e338ae: Layer already exists\n",
      "cd31335e8e41: Layer already exists\n",
      "dbc5ddf63966: Layer already exists\n",
      "8f312108c760: Layer already exists\n",
      "22144637480e: Layer already exists\n",
      "b255b26a82a5: Layer already exists\n",
      "8980490753a8: Layer already exists\n",
      "24cd7a0a3078: Layer already exists\n",
      "270e75e92418: Layer already exists\n",
      "latest: digest: sha256:e84562269db2c4e787a3abb6bde3d20b036c38da9aead3aa4ee898bcc7f18e35 size: 3650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=demo-sagemaker-multimodel-gluonts\n",
    "\n",
    "cd container\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -q -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. How to Deploy Models as Sagemaker Multi Model Endpoint and Invoke the Endpoint\n",
    "\n",
    "After building and registering the custom Sagemaker container, we can start to deploy models as Sagemaker multi-model endpoint and invoke the endpoint. The main steps are outlined as below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to define the S3 bucket and prefix of the model artifacts that will be invoked by the multi-model endpoint. we also need to define the IAM role that will give SageMaker access to the model artifacts and ECR image that was created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = boto3.client(service_name='sagemaker')\n",
    "runtime_sm_client = boto3.client(service_name='sagemaker-runtime')\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "bucket = 'sagemaker-{}-{}'.format(region, account_id)\n",
    "prefix = 'demo-multimodel-gluonts-endpoint'\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "models_dir = \"models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create a multi-model endpoint\n",
    "### Step 2-1: Import models into hosting\n",
    "When creating the Model entity for multi-model endpoints, the container's `ModelDataUrl` is the S3 prefix where the model artifacts that are invokable by the endpoint are located. The rest of the S3 path will be specified when invoking the model.\n",
    "\n",
    "The `Mode` of container is specified as `MultiModel` to signify that the container will host multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: DEMO-MultiModelGluonTSModel2020-08-19-05-31-12\n",
      "Model data Url: https://s3-ap-southeast-2.amazonaws.com/sagemaker-ap-southeast-2-783128296767/demo-multimodel-gluonts-endpoint/models/\n",
      "Container image: 783128296767.dkr.ecr.ap-southeast-2.amazonaws.com/demo-sagemaker-multimodel-gluonts:latest\n",
      "Model Arn: arn:aws:sagemaker:ap-southeast-2:783128296767:model/demo-multimodelgluontsmodel2020-08-19-05-31-12\n"
     ]
    }
   ],
   "source": [
    "model_name = 'DEMO-MultiModelGluonTSModel' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "model_url = 'https://s3-{}.amazonaws.com/{}/{}/{}/'.format(region, bucket, prefix, models_dir)\n",
    "container = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account_id, region, 'demo-sagemaker-multimodel-gluonts')\n",
    "\n",
    "print('Model name: ' + model_name)\n",
    "print('Model data Url: ' + model_url)\n",
    "print('Container image: ' + container)\n",
    "\n",
    "container = {\n",
    "    'Image': container,\n",
    "    'ModelDataUrl': model_url,\n",
    "    'Mode': 'MultiModel'\n",
    "}\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    Containers = [container])\n",
    "\n",
    "print(\"Model Arn: \" + create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2-2: Create endpoint configuration\n",
    "Endpoint config creation works the same way it does as single model endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint config name: DEMO-MultiModelGluonTSEndpointConfig-2020-08-19-05-31-12\n",
      "Endpoint config Arn: arn:aws:sagemaker:ap-southeast-2:783128296767:endpoint-config/demo-multimodelgluontsendpointconfig-2020-08-19-05-31-12\n"
     ]
    }
   ],
   "source": [
    "endpoint_config_name = 'DEMO-MultiModelGluonTSEndpointConfig-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print('Endpoint config name: ' + endpoint_config_name)\n",
    "\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType': 'ml.m5.xlarge',\n",
    "        'InitialInstanceCount': 2,\n",
    "        'InitialVariantWeight': 1,\n",
    "        'ModelName': model_name,\n",
    "        'VariantName': 'AllTraffic'}])\n",
    "\n",
    "print(\"Endpoint config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2-3: Create the multi model endpoint\n",
    "Similarly, endpoint creation works the same way as for single model endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name: DEMO-MultiModelGluonTSEndpoint-2020-08-19-05-31-12\n",
      "Endpoint Arn: arn:aws:sagemaker:ap-southeast-2:783128296767:endpoint/demo-multimodelgluontsendpoint-2020-08-19-05-31-12\n",
      "Endpoint Status: Creating\n",
      "Waiting for DEMO-MultiModelGluonTSEndpoint-2020-08-19-05-31-12 endpoint to be in service...\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = 'DEMO-MultiModelGluonTSEndpoint-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print('Endpoint name: ' + endpoint_name)\n",
    "\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print('Endpoint Arn: ' + create_endpoint_response['EndpointArn'])\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "print(\"Endpoint Status: \" + status)\n",
    "\n",
    "print('Waiting for {} endpoint to be in service...'.format(endpoint_name))\n",
    "waiter = sm_client.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Invoke models\n",
    "Now we invoke the models that we uploaded to S3 previously. The first invocation of a model may be slow, since behind the scenes, SageMaker is downloading the model artifacts from S3 to the instance and loading it into the container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the Mean Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will prepare two time series as the payload to invoke the model, then call InvokeEndpoint to invoke the Mean model to forecast. The `TargetModel` field is concatenated with the S3 prefix specified in `ModelDataUrl` when creating the model, to generate the location of the model in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    data = []\n",
    "    with jsonlines.open(file_path) as reader:\n",
    "        for obj in reader:\n",
    "            data.append(obj)\n",
    "    return data\n",
    "\n",
    "payload_jsonline = read_data('data/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_time_series = 2 # select 2 time series for quick response\n",
    "payload_list = []\n",
    "for p in payload_jsonline[:n_time_series]:\n",
    "    payload_list.append(json.dumps(p))\n",
    "payload = '\\n'.join(payload_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"item_id\": \"0\", \"quantiles\": {\"0.1\": [1.5405118683397176, 1.4554741560240922, 1.3917306274191918, 1.5535203902714856, 1.6868682440218221, 1.481299762167165, 1.6741983168122005, 1.6342995780939114, 1.70775578458321, 1.361224787680375, 1.543907365165602, 1.6231372876795858], \"0.2\": [1.7843796149207596, 1.8948115589364658, 1.7463301588067242, 2.064156981660703, 1.868239141851494, 1.7077491648392367, 1.9947164546725473, 2.0669598954758994, 2.0160320823484636, 1.7658390815196041, 1.9994900053363778, 1.9714402947370742], \"0.3\": [2.0142952356632726, 2.120184976345479, 2.0082169203526097, 2.3649007525673227, 2.2718384382275962, 2.080861105867572, 2.1973984203088777, 2.2773634266268363, 2.2461926145843347, 2.0758759234090185, 2.1394578174669703, 2.283098209008817], \"0.4\": [2.186745166682812, 2.3021799973559554, 2.2074804393102294, 2.5392996678280877, 2.4855614014338636, 2.2890245245649856, 2.3638192419521955, 2.4887149137270512, 2.4618889026138344, 2.2774178452563816, 2.346897183679217, 2.515683361161074], \"0.5\": [2.4661465564986376, 2.6158312261101444, 2.545419041351032, 2.695258664530787, 2.7052932445285585, 2.5523491710425725, 2.54458548159533, 2.7334683230849675, 2.5809316357161225, 2.4481348831683634, 2.572550229178061, 2.7023088589878173], \"0.6\": [2.7320633663787484, 2.794640044981753, 2.6600186344134973, 2.8211051787489954, 2.8546915649122266, 2.7781069931751734, 2.633544578629998, 2.8994804580970297, 2.692040827505053, 2.5879932076750354, 2.7309541453332704, 2.827659741455055], \"0.7\": [2.982033311184523, 3.020372971620418, 2.8579209873741487, 3.0501014845221124, 3.0649120845971503, 2.9998694837219606, 2.9020657403839767, 3.045338059733278, 2.926425624711083, 2.8982852998222173, 2.8482044737647536, 3.06056396781893], \"0.8\": [3.2806146479032394, 3.2262240006411527, 3.102491875719398, 3.2899831695096875, 3.2779567993175003, 3.205681394611685, 3.168968774605789, 3.2610464521139395, 3.2746424494796598, 3.133035433864899, 3.0089079824954, 3.417213732614772], \"0.9\": [3.7257068090457905, 3.5966114148290753, 3.3697276325880554, 3.542079351897696, 3.5787063248362765, 3.5582922836855877, 3.6743743930041934, 3.579192846719387, 3.6025449653751482, 3.3036438918839925, 3.4096643519219922, 3.629669532645825]}, \"mean\": [2.5304321688299303, 2.5545137212335516, 2.4364480016419283, 2.626334894846063, 2.6351204699481587, 2.5283412798988976, 2.585064872589243, 2.660555668671542, 2.611857968931903, 2.394385710437181, 2.5015184982258636, 2.677116929510862]}\n",
      "{\"item_id\": \"1\", \"quantiles\": {\"0.1\": [23.47415585169587, 24.626407101116783, 25.749669617532255, 23.868689568248715, 23.66398358840572, 24.7838751857662, 23.53931169035821, 23.93430424098449, 24.561243510502337, 24.32097364266159, 24.938905949615947, 24.00784918632494], \"0.2\": [26.104340864454993, 25.811413659969674, 26.97121295460826, 25.388114293003138, 25.972456209807415, 25.498633799102038, 25.880703873712406, 25.316892878666064, 25.51602917006777, 25.461720036149757, 26.28489527466909, 25.532320380704583], \"0.3\": [26.78581397461022, 26.742593815572217, 27.656676056770973, 27.08245055996461, 26.970879367124628, 27.003034401054546, 27.0576114547926, 26.971572745882572, 27.422847599327596, 26.63511773075156, 27.115701463478754, 27.070941207975753], \"0.4\": [27.68490225599055, 27.811853743876252, 28.74860017216063, 28.389073585561487, 27.70393562734516, 27.493903293722152, 28.35374597678977, 27.94298574674912, 28.27211457029513, 27.79209967003839, 28.122881016505342, 27.659712215904204], \"0.5\": [28.511503307894937, 29.183575014757643, 29.52707390245503, 29.32114251181835, 28.33905641400328, 28.480857534110715, 29.424839833174914, 29.21880525245203, 29.57790108392298, 28.916707142136474, 29.272026694100052, 28.29903193292682], \"0.6\": [30.004228752038912, 30.08645855471414, 30.123673149118662, 29.866772128344692, 29.567132454500424, 29.7977973259831, 30.33531600257574, 30.34257652350736, 30.288468798612787, 29.45149405185758, 30.66070932021055, 29.03356299078187], \"0.7\": [31.239765757481052, 30.72456310183189, 31.516973592533375, 31.271741517416693, 30.493141713949907, 30.652992323844384, 31.764738415792554, 31.363199591844673, 31.00969974935027, 30.317814209925196, 32.24727951438986, 30.182430098223357], \"0.8\": [31.771244201628495, 31.816602442326428, 32.59601965582504, 32.438096642351645, 31.68214349389252, 31.73219574478132, 32.75347772840845, 32.47321692151879, 32.064162271767955, 31.781116326282433, 33.03079166507741, 32.383498175530335], \"0.9\": [33.81937717461221, 34.037523943872955, 33.86200632022795, 33.494702804175134, 33.156100764608524, 33.190989264738995, 34.942755222602756, 33.25576779342682, 32.7645019763046, 33.60437604490126, 34.343745859915245, 33.825658408497475]}, \"mean\": [28.73313842549674, 28.888059017650207, 29.51039298368965, 28.957798326719463, 28.54864722422446, 28.866091690305943, 29.189970314936367, 28.946103045605966, 29.21792348904082, 28.711281442189893, 29.509528905718877, 28.605600479633463]}\n",
      "\n",
      "CPU times: user 14.5 ms, sys: 0 ns, total: 14.5 ms\n",
      "Wall time: 3.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    TargetModel='MeanPredictor.tar.gz', # this is the rest of the S3 path where the model artifacts are located\n",
    "    Body=payload)\n",
    "\n",
    "print(response['Body'].read().decode(\"utf-8\"), sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we invoke the same models a __`2nd`__ time, it is already downloaded to the instance and loaded in the container, so __`inference is faster`__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"item_id\": \"0\", \"quantiles\": {\"0.1\": [1.253290150649065, 1.5168044071218103, 1.6058552647964146, 1.416644839456339, 1.4760739247069175, 1.5949178583152142, 1.5046364888294557, 1.6182047801102133, 1.6813422376595226, 1.5831720115001264, 1.4905019439579128, 1.485792456486161], \"0.2\": [1.6883829741568546, 1.9559592496099052, 1.9406866875460265, 1.8858503955335346, 1.9056384521332805, 1.9906169079670368, 1.7944211778316737, 1.951096027600538, 1.8786202759916928, 1.9189115919840627, 1.8142189415399481, 1.9217967401626725], \"0.3\": [2.0337826948358066, 2.1890946619488885, 2.1138589880510317, 2.057806274822087, 2.191305388395044, 2.1336631568457687, 2.1655618649014063, 2.156779627699678, 2.137045801229956, 2.0013479094397364, 2.0042509785857057, 2.1127901772399023], \"0.4\": [2.4027328475107335, 2.538071579410444, 2.3633799633586343, 2.267904465537704, 2.3578441572073134, 2.476561251246665, 2.3770608015331303, 2.3552567273079217, 2.2626005383177255, 2.296212779806407, 2.4248797478730797, 2.2860613548913586], \"0.5\": [2.588465993203983, 2.7121932416711383, 2.5328589538574637, 2.4318447881781506, 2.479585046855669, 2.6513547633735164, 2.584772375062915, 2.6289624678476993, 2.4103004884656825, 2.5057180060841246, 2.622343640523044, 2.5541229802715777], \"0.6\": [2.7153035944795287, 2.833893369489872, 2.657297112069561, 2.637931135488063, 2.7022166401861134, 2.794171711089326, 2.8383641630517955, 2.818727247376876, 2.5939677075638485, 2.643623094971697, 2.77427553660412, 2.836151511512779], \"0.7\": [3.0002457796448, 3.04506137107629, 2.95649292429563, 2.9432358254949653, 2.9069382845027927, 2.9506395092513062, 3.004909374500564, 3.0411254458171806, 2.8052423360696452, 2.878693028680612, 2.9673868595376924, 2.984059373085217], \"0.8\": [3.1098878833301025, 3.4091850328850373, 3.1666246076225066, 3.263627993551424, 3.1656984084510875, 3.218050375764158, 3.1379079657808684, 3.4082833368221026, 3.1025819577852127, 3.367172498074259, 3.1681527042094344, 3.2981874598238985], \"0.9\": [3.5766102354350013, 3.7296258557280497, 3.686864164393901, 3.52232605120641, 3.4543663605395327, 3.5294383411600814, 3.5316111675824216, 3.5962005171451255, 3.5097316632802222, 3.6932268563140616, 3.642834957516275, 3.556459267549231]}, \"mean\": [2.5126919367863216, 2.6588227790583714, 2.5675443812023038, 2.481184295338156, 2.532218155876451, 2.5960900373944127, 2.546886944172082, 2.6249270605319084, 2.507430758308887, 2.5821409246988516, 2.5490743076128104, 2.5357796036584204]}\n",
      "{\"item_id\": \"1\", \"quantiles\": {\"0.1\": [24.347300487576124, 25.21493598226909, 23.89510604317277, 23.952584243510266, 25.387098338632654, 24.380101166602653, 24.20566398148768, 24.74463042580901, 24.00094428476905, 25.098619212316287, 24.809369910019438, 23.761372003972195], \"0.2\": [25.635162617107877, 26.06190342428777, 25.29566263551303, 25.461734097212567, 26.70332705618111, 25.847722616032232, 25.683495558360107, 25.910687122052636, 25.72507243000382, 26.481608962093212, 26.30791146308248, 25.14007792756555], \"0.3\": [27.325594707330218, 27.022635721542056, 26.705484122853463, 27.083597769897153, 27.24733549662947, 27.073577313674033, 27.221005466024646, 26.812630308234546, 26.44679796856581, 27.78281971714686, 27.472799848663094, 26.282223068196807], \"0.4\": [28.24903097319087, 27.642033092221546, 27.9185470316805, 28.602404338033296, 28.03256904425161, 27.906770994629934, 27.808265083853247, 27.718061926629755, 27.652849068879704, 28.728630604939916, 28.117873067425034, 27.268457634947527], \"0.5\": [28.967861246699805, 28.547662216477782, 28.758047812490343, 28.94177554175347, 29.118058642788576, 29.179060228431982, 28.663297317900746, 28.484406382965467, 28.732158756076206, 29.642054626430845, 28.691210382050055, 28.027397063290305], \"0.6\": [30.02758200852394, 29.44505489679361, 29.29896433773621, 29.376069976407987, 30.06021097369286, 30.147102506924444, 29.52254043510128, 29.85720539065604, 29.38329872370776, 30.361411764699074, 29.35553903475688, 28.779009995875857], \"0.7\": [31.323108672247034, 30.67066165155201, 30.21981421337356, 30.45940201293181, 31.21055405438962, 31.102589365784148, 31.049518988065685, 30.487198069317905, 30.706984460382976, 31.47038649837043, 30.714786722545618, 30.14487973481337], \"0.8\": [32.02549866911978, 31.80107250877067, 32.45378702468394, 31.4399176502291, 32.230851203314515, 32.19790153297398, 31.868538525416938, 31.778957282909495, 31.781289098731563, 32.77499264223897, 31.94360598082073, 32.199752053880644], \"0.9\": [33.54620820613793, 33.602241128651016, 34.254867850384066, 32.912691871826794, 33.91818048148624, 34.42176362961397, 32.80924887076854, 34.39546817653875, 33.80976405315094, 34.06452821819454, 33.60336414074884, 33.327433244170116]}, \"mean\": [28.984801701199146, 29.060325703468774, 28.764116748934498, 28.630362910934245, 29.399003222036377, 29.095177038013322, 28.6968274354355, 28.98418301685544, 28.715914485337386, 29.51104932938914, 28.91953682794091, 28.52903222190087]}\n",
      "\n",
      "CPU times: user 4.52 ms, sys: 0 ns, total: 4.52 ms\n",
      "Wall time: 31.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    TargetModel='MeanPredictor.tar.gz',\n",
    "    Body=payload)\n",
    "\n",
    "print(response['Body'].read().decode(\"utf-8\"), sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke other models\n",
    "Exercising the power of a multi-model endpoint, we can specify different models (e.g., DeepAREstimator.tar.gz) as `TargetModel` and perform inference on it using the same endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"item_id\": \"0\", \"quantiles\": {\"0.1\": [2.0058059692382812, 2.0848548412323, 2.1319191455841064, 1.7626827955245972, 2.1028003692626953, 2.1341395378112793, 2.153954029083252, 1.4223262071609497, 1.8531743288040161, 2.1007485389709473, 2.023390293121338, 1.9111007452011108], \"0.2\": [2.250101089477539, 2.2457194328308105, 2.2871243953704834, 1.9063371419906616, 2.3267104625701904, 2.3346588611602783, 2.345787286758423, 1.5654994249343872, 2.0083627700805664, 2.2628791332244873, 2.159290075302124, 2.080110549926758], \"0.3\": [2.3288064002990723, 2.4233856201171875, 2.3600692749023438, 1.9544258117675781, 2.4445018768310547, 2.5232415199279785, 2.528930187225342, 1.7129929065704346, 2.116767168045044, 2.4026944637298584, 2.377838134765625, 2.2108047008514404], \"0.4\": [2.41412615776062, 2.476562738418579, 2.456324577331543, 2.087014675140381, 2.514258623123169, 2.5901424884796143, 2.676973342895508, 1.8229917287826538, 2.2375881671905518, 2.5167603492736816, 2.456094264984131, 2.2990314960479736], \"0.5\": [2.5255746841430664, 2.522184133529663, 2.5094778537750244, 2.1893575191497803, 2.5785491466522217, 2.681475877761841, 2.7859489917755127, 1.89691162109375, 2.327765703201294, 2.612100839614868, 2.588010549545288, 2.4116156101226807], \"0.6\": [2.5778965950012207, 2.590466260910034, 2.6038496494293213, 2.2933032512664795, 2.6625564098358154, 2.7807390689849854, 2.8679938316345215, 1.9971269369125366, 2.395672559738159, 2.7096986770629883, 2.6925384998321533, 2.4974098205566406], \"0.7\": [2.6789631843566895, 2.6922101974487305, 2.7285945415496826, 2.4181528091430664, 2.7581963539123535, 2.878824472427368, 2.990676164627075, 2.1288981437683105, 2.482356548309326, 2.8257710933685303, 2.7962872982025146, 2.5492660999298096], \"0.8\": [2.7652249336242676, 2.78879714012146, 2.854750156402588, 2.551793336868286, 2.895071268081665, 3.033524751663208, 3.157639741897583, 2.219834804534912, 2.685163974761963, 2.958743095397949, 2.919548749923706, 2.6147706508636475], \"0.9\": [2.917468547821045, 3.0220181941986084, 3.058338165283203, 2.8172168731689453, 3.1398844718933105, 3.214970827102661, 3.422821283340454, 2.4087603092193604, 2.8729984760284424, 3.154329538345337, 3.0672078132629395, 2.7961254119873047]}, \"mean\": [2.4923038482666016, 2.5434224605560303, 2.5547690391540527, 2.227118730545044, 2.6070525646209717, 2.7087583541870117, 2.8014421463012695, 1.9086737632751465, 2.3270018100738525, 2.6357309818267822, 2.561795234680176, 2.360281467437744]}\n",
      "{\"item_id\": \"1\", \"quantiles\": {\"0.1\": [21.7309627532959, 21.21268081665039, 24.96367835998535, 30.535606384277344, 31.646024703979492, 31.800214767456055, 29.574499130249023, 28.26167869567871, 30.742969512939453, 30.591142654418945, 26.135709762573242, 22.19205093383789], \"0.2\": [21.87860107421875, 21.355621337890625, 25.35462760925293, 30.889272689819336, 32.06098937988281, 32.10415267944336, 30.13384246826172, 28.543546676635742, 31.06096839904785, 31.10061264038086, 26.431541442871094, 22.44685173034668], \"0.3\": [21.94552230834961, 21.467607498168945, 25.627845764160156, 31.145336151123047, 32.388954162597656, 32.49728012084961, 30.409595489501953, 28.90245246887207, 31.26402473449707, 31.42530632019043, 26.86223602294922, 22.66167449951172], \"0.4\": [22.08354377746582, 21.56975746154785, 25.805925369262695, 31.380191802978516, 32.730770111083984, 32.83235549926758, 30.67211151123047, 29.14577865600586, 31.54178237915039, 31.713287353515625, 27.070829391479492, 22.84776496887207], \"0.5\": [22.218292236328125, 21.774890899658203, 26.012914657592773, 31.58818244934082, 33.000083923339844, 32.95716857910156, 30.99258041381836, 29.31458282470703, 31.746807098388672, 31.857694625854492, 27.179393768310547, 22.985553741455078], \"0.6\": [22.288345336914062, 21.904098510742188, 26.232715606689453, 31.930545806884766, 33.121421813964844, 33.20529556274414, 31.324321746826172, 29.696269989013672, 31.96688461303711, 32.0379753112793, 27.339420318603516, 23.078460693359375], \"0.7\": [22.409788131713867, 22.050113677978516, 26.3481502532959, 32.207820892333984, 33.37940979003906, 33.457889556884766, 31.555667877197266, 29.897506713867188, 32.30264663696289, 32.19894790649414, 27.5301513671875, 23.25338363647461], \"0.8\": [22.544925689697266, 22.20128059387207, 26.659643173217773, 32.704345703125, 33.871917724609375, 33.83296585083008, 32.03856658935547, 30.25775909423828, 32.70680618286133, 32.497806549072266, 27.84885597229004, 23.34166717529297], \"0.9\": [22.759546279907227, 22.396825790405273, 27.00908088684082, 33.32112121582031, 34.54484558105469, 34.34777069091797, 32.302154541015625, 30.656400680541992, 33.03704071044922, 33.15358352661133, 28.295879364013672, 23.707834243774414]}, \"mean\": [22.204221725463867, 21.783876419067383, 26.028766632080078, 31.76331329345703, 33.017539978027344, 33.012638092041016, 30.972806930541992, 29.397367477416992, 31.836326599121094, 31.80663299560547, 27.21340560913086, 22.96190643310547]}\n",
      "\n",
      "CPU times: user 5.04 ms, sys: 0 ns, total: 5.04 ms\n",
      "Wall time: 2.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    TargetModel='DeepAREstimator.tar.gz',\n",
    "    Body=payload)\n",
    "\n",
    "print(response['Body'].read().decode(\"utf-8\"), sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"item_id\": null, \"quantiles\": {\"0.1\": [0.8090870702874826, 0.8428123078492686, 0.4624473413299772, 0.5177015624404087, 0.43006920648953173, 0.19331751739085123, 0.17339511072744607, 0.15734350423240206, 0.3918786635030125, 0.5235862509618792, 0.31944327647862414, -0.01251747265512182], \"0.2\": [1.5225365628796608, 1.4819382501119645, 1.1533033470218867, 1.0144062634158844, 1.1683039107980289, 0.762261028826825, 0.8815687774245442, 0.9600288129509906, 1.0746018416332428, 1.115368170630708, 1.1169586250187686, 1.183204264275807], \"0.3\": [1.9913532929619617, 1.7195532084583576, 1.7384239422684757, 1.4819066900965199, 1.7071997854235548, 1.2307796247473433, 1.5698870494702337, 1.7928686549204662, 1.4200078960506284, 1.5720736133402875, 1.5373370171181526, 1.788114767147786], \"0.4\": [2.256737710810241, 1.9244638423168219, 2.115409957951876, 1.855350419412394, 1.9605222797037896, 1.9739920868919456, 2.1379014667629477, 2.287974580365686, 2.1558390349033236, 2.299462214313219, 2.078212102685984, 2.468583779186728], \"0.5\": [2.467025712104701, 2.190376830336547, 2.5815126295275457, 2.2436204306879075, 2.6822272010805763, 2.514337117421298, 2.643490704620751, 2.6051789388425526, 2.5643858480551085, 2.799360356455019, 2.8267417200393763, 2.7203212299149984], \"0.6\": [2.892910671979501, 2.701598407114897, 2.8998802133464934, 2.649727101037164, 3.0423705379522974, 2.9391928564626593, 2.9099053635366614, 3.1204278126378737, 3.1341194714834915, 3.085612893054093, 3.246101566206285, 3.0881938243990175], \"0.7\": [3.225373230660865, 3.109639645110132, 3.3364863831972382, 3.227341331733362, 3.6374835075324503, 3.41606059260517, 3.4028878148320953, 3.4642605225816165, 3.507024013963478, 3.4877854657181566, 3.9676200442271634, 3.621031228417861], \"0.8\": [3.5424495567607233, 3.5806485448962575, 3.65401494803194, 3.9661293677744562, 4.014738848708807, 4.157134813949821, 3.8260110559373004, 3.9415933415457394, 4.100237749731559, 4.08022545676411, 4.494592339021939, 4.3003136333910845], \"0.9\": [4.036139267140843, 4.201858647821874, 4.203324762022674, 4.717008484765314, 4.4661009452117195, 4.801381194614556, 4.6101212167078955, 5.177064128891047, 5.378198893416591, 5.141674495882923, 5.542044207574799, 5.652505966696111]}, \"mean\": [2.5468881896947484, 2.428653444827029, 2.461287884370529, 2.4501503776996048, 2.5371553594819583, 2.459725647779233, 2.447055842041692, 2.602329330340219, 2.6129471627061243, 2.673173978850883, 2.748229206687317, 2.6736573148674334]}\n",
      "{\"item_id\": null, \"quantiles\": {\"0.1\": [20.802592605742113, 21.431941263711742, 25.93533959601745, 29.46063295054971, 29.706113664918618, 30.64494430988454, 28.548642159538414, 27.199046661041073, 29.576387696351905, 30.49450351351239, 25.318101081679266, 22.759459693167113], \"0.2\": [21.467208173608256, 22.082881763716568, 26.714448693970926, 30.380037977096535, 30.48099458321749, 31.040269041944736, 29.164466907118, 28.030318999366532, 30.612462415345377, 31.140782757392973, 26.111975775614706, 23.205059123874605], \"0.3\": [22.129422321622638, 22.34554399170061, 27.25270339843965, 30.78984568210248, 30.872772884845553, 31.471742262664357, 29.726783868016874, 28.440885669690847, 30.993921192538053, 31.694785694318703, 26.614967842494895, 23.72319445830664], \"0.4\": [22.433090549689634, 22.761681311373458, 27.64952091273456, 31.01830675586647, 31.195975910916015, 31.78326261599172, 30.011534859227087, 28.851810699055786, 31.64030262423662, 31.986597625570976, 27.128042530640613, 24.29032238017294], \"0.5\": [22.970857154676793, 23.182159965748696, 28.003490346519104, 31.46525889911433, 31.617967141194793, 32.23402094558562, 30.506052017948875, 29.42864844715595, 32.019715521452106, 32.350288648714034, 27.547336467609405, 24.682189329154674], \"0.6\": [23.261783751714766, 23.461791922777856, 28.23967119652952, 31.857207691310958, 31.935003231989775, 32.684997063316835, 30.996813813728707, 29.94762539647627, 32.55242034045271, 32.81999656996471, 27.876816278302716, 24.888174022954214], \"0.7\": [23.613826151314548, 23.957744663877275, 28.61821649673514, 32.33264482131184, 32.175405154131205, 33.06128370097515, 31.34064633064893, 30.39398838893331, 32.76105038546421, 33.265318054927754, 28.324000370106422, 25.564656379141226], \"0.8\": [24.054097499879514, 24.693243714735363, 29.055394932323974, 32.70855384904662, 32.797573351694794, 33.877332170530565, 32.102569798139754, 31.136037263190527, 33.55729319149967, 33.933498027463294, 29.00248631063894, 26.137660406145955], \"0.9\": [24.62081045393151, 25.305845388706388, 29.404725001574754, 33.0995060178299, 33.62381053949765, 34.66070753976484, 32.53859630959698, 31.86501055229192, 34.46955876363782, 34.50847512355893, 30.021005336279117, 26.45967003934745]}, \"mean\": [22.763565186062422, 23.291938206654223, 27.82517424687054, 31.496728125102113, 31.625599131893424, 32.457585335887025, 30.622844209453703, 29.456714359049215, 31.94665427630356, 32.4707666629274, 27.518080655561697, 24.61714152187335]}\n",
      "\n",
      "CPU times: user 4.83 ms, sys: 0 ns, total: 4.83 ms\n",
      "Wall time: 5.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    TargetModel='RForecastPredictor.tar.gz',\n",
    "    Body=payload)\n",
    "\n",
    "print(response['Body'].read().decode(\"utf-8\"), sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"item_id\": null, \"quantiles\": {\"0.1\": [0.6400716631554431, 0.2843922656464699, 0.35509664238253213, 1.0394838466459895, 0.6226457211437011, 0.6743560186156927, 0.7125763570702937, 0.03229604267139741, 0.246863504267121, 0.29444244357734917, 0.06849625469506981, 0.2807402284661189], \"0.2\": [1.3472023714194665, 0.8573461445764494, 0.9799641306312864, 1.3348348389014935, 1.1686285261993905, 1.2323588895931548, 1.4712221515973218, 0.667259860611519, 0.7356308837085632, 0.9453179442253173, 0.7127467437224793, 0.8365200380226373], \"0.3\": [1.8360639870871602, 1.1487364970339642, 1.2092435466198395, 1.8352871667751556, 1.5464536161065041, 1.5188189134606236, 1.7475541664839103, 0.9833682991092416, 1.1240863302356185, 1.2981067559363946, 1.1173646553754746, 1.0925820292775927], \"0.4\": [1.9810608094294335, 1.515343451015149, 1.6965688186410537, 2.2989088624958236, 1.9562644114182821, 1.8890014878890877, 1.9905861959816025, 1.3602674903233212, 1.4057228307049074, 1.6968461982271728, 1.701330623990998, 1.3428958824708532], \"0.5\": [2.4047886718367293, 1.8199786295849596, 1.9327404713023344, 2.46152774510146, 2.310447822954373, 2.1354465558613107, 2.262403303541924, 1.7810193283342644, 1.809047713765303, 2.0578960365926195, 2.0144591897056445, 1.5683945680678357], \"0.6\": [2.865167218933421, 2.3353727919060283, 2.114037185752236, 2.7656236124074276, 2.7305780264133226, 2.4427429704125276, 2.3932828726173665, 2.091471314432805, 2.1098538282320143, 2.2176345791553675, 2.3277660044914708, 1.8188080094325259], \"0.7\": [3.1209205555652137, 2.7110797376972906, 2.322192555934027, 3.2004466980313273, 2.9720737753454163, 2.8533648153039617, 2.7637532923743864, 2.3990814252874886, 2.3798724443222334, 2.525598436538006, 2.769862829159651, 2.124183324927349], \"0.8\": [3.467089495555964, 2.9784252964481435, 2.8766464469646476, 3.4106765400205714, 3.326487283116401, 3.259091523301226, 2.9270336233182004, 2.858476159492286, 2.868684168252507, 2.914159071530314, 2.9855492569171576, 2.5314989328014645], \"0.9\": [4.106595111937967, 3.34338038868316, 3.717393757948919, 3.8200279480291828, 3.9250240747210343, 3.8796677695593775, 3.6994392861816006, 3.4919749763111834, 3.4091804935321037, 3.3293926686553315, 3.6335296800061405, 3.2051077414457882]}, \"mean\": [2.4212492331707614, 1.8780372358054584, 1.905438093026634, 2.410322619964028, 2.254481097466525, 2.2158666410018117, 2.230063223465278, 1.7513646228964677, 1.8449200257759435, 1.9545328504609056, 1.9532483921602457, 1.639717226214331]}\n",
      "{\"item_id\": null, \"quantiles\": {\"0.1\": [21.038281589840473, 21.337165240229254, 25.927669075651625, 29.674552163458515, 29.618346005668915, 30.437563320389767, 28.22202043679642, 27.21673839028323, 30.48055784469918, 30.248185790684087, 25.77456613724146, 22.685488672889015], \"0.2\": [22.01140393576774, 21.73834139924848, 26.693326782425743, 30.323167769430057, 30.59486175270789, 31.077281091657138, 28.900759906780863, 27.569993412720287, 30.970185090007174, 31.05273725303119, 26.701554638507126, 23.281426691468134], \"0.3\": [22.489294063945824, 22.410611688073228, 27.10102091429068, 30.97054045260425, 31.071150329979226, 31.602466538425787, 29.611758531300094, 28.289443015137145, 31.10692745691031, 31.481004046976775, 26.980182858377955, 23.793377335771847], \"0.4\": [22.725954079030785, 22.99064765688954, 27.44097503524767, 31.311872665438422, 31.289234063708786, 32.020537247668315, 30.266460964632152, 28.74186108075095, 31.55135770850845, 31.918824639982876, 27.337195725905588, 24.216299657713616], \"0.5\": [22.966480239751206, 23.245425704531176, 27.711533186513503, 31.567639335069455, 31.943233634826548, 32.397685976035824, 30.76578765510937, 29.089474009347295, 31.879412783908368, 32.25361436531001, 27.600012182527898, 24.578824848461846], \"0.6\": [23.266156625623946, 23.567379509353607, 28.001476765727805, 32.01315405962434, 32.45760447743299, 32.75731778739454, 31.264117967229055, 29.600244374826215, 32.168829261568696, 32.64184682528421, 28.155002742980834, 24.832338019186995], \"0.7\": [23.574697881727136, 23.86537620112745, 28.67056279489252, 32.58280843754276, 32.85321204038542, 33.154629317450095, 31.68007562236278, 30.10778654893699, 32.587285573856946, 32.91851318673172, 28.569186414501146, 25.330040464008178], \"0.8\": [24.174854474658474, 24.48295211068432, 29.245635603069186, 33.25333016359773, 33.2125871009731, 33.419968222679174, 31.997716766817852, 30.630067904318157, 33.24398326026418, 33.411825205087375, 28.929593865741104, 25.914489149677273], \"0.9\": [24.764991871030166, 24.949994197324344, 29.78665531625718, 33.613709932943735, 33.91204745296957, 34.09443321060966, 32.52192425517981, 31.19269513637717, 34.007612015332946, 34.02547134921014, 29.900037241676692, 26.472176051663986]}, \"mean\": [22.953222013727444, 23.17597335187535, 27.87216985260761, 31.683111257195684, 31.872168117295992, 32.29386187598522, 30.554686724370086, 29.130472655178455, 31.9430677154342, 32.28223263669439, 27.74660846676381, 24.55735519897974]}\n",
      "\n",
      "CPU times: user 4.64 ms, sys: 281 s, total: 4.92 ms\n",
      "Wall time: 7.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    TargetModel='ProphetPredictor.tar.gz',\n",
    "    Body=payload)\n",
    "\n",
    "print(response['Body'].read().decode(\"utf-8\"), sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"item_id\": null, \"quantiles\": {\"0.1\": [2.855329990386963, 2.855329990386963, 2.855329990386963, 2.062182664871216, 3.4898476600646973, 2.5380711555480957, 1.7449238300323486, 1.4276649951934814, 2.2208120822906494, 2.5380711555480957, 2.062182664871216, 2.379441738128662], \"0.2\": [2.855329990386963, 2.855329990386963, 2.855329990386963, 2.062182664871216, 3.4898476600646973, 2.5380711555480957, 1.7449238300323486, 1.4276649951934814, 2.2208120822906494, 2.5380711555480957, 2.062182664871216, 2.379441738128662], \"0.3\": [2.855329990386963, 2.855329990386963, 2.855329990386963, 2.062182664871216, 3.4898476600646973, 2.5380711555480957, 1.7449238300323486, 1.4276649951934814, 2.2208120822906494, 2.5380711555480957, 2.062182664871216, 2.379441738128662], \"0.4\": [2.855329990386963, 2.855329990386963, 2.855329990386963, 2.062182664871216, 3.4898476600646973, 2.5380711555480957, 1.7449238300323486, 1.4276649951934814, 2.2208120822906494, 2.5380711555480957, 2.062182664871216, 2.379441738128662], \"0.5\": [2.855329990386963, 2.855329990386963, 2.855329990386963, 2.062182664871216, 3.4898476600646973, 2.5380711555480957, 1.7449238300323486, 1.4276649951934814, 2.2208120822906494, 2.5380711555480957, 2.062182664871216, 2.379441738128662], \"0.6\": [2.855329990386963, 2.855329990386963, 2.855329990386963, 2.062182664871216, 3.4898476600646973, 2.5380711555480957, 1.7449238300323486, 1.4276649951934814, 2.2208120822906494, 2.5380711555480957, 2.062182664871216, 2.379441738128662], \"0.7\": [2.855329990386963, 2.855329990386963, 2.855329990386963, 2.062182664871216, 3.4898476600646973, 2.5380711555480957, 1.7449238300323486, 1.4276649951934814, 2.2208120822906494, 2.5380711555480957, 2.062182664871216, 2.379441738128662], \"0.8\": [2.855329990386963, 2.855329990386963, 2.855329990386963, 2.062182664871216, 3.4898476600646973, 2.5380711555480957, 1.7449238300323486, 1.4276649951934814, 2.2208120822906494, 2.5380711555480957, 2.062182664871216, 2.379441738128662], \"0.9\": [2.855329990386963, 2.855329990386963, 2.855329990386963, 2.062182664871216, 3.4898476600646973, 2.5380711555480957, 1.7449238300323486, 1.4276649951934814, 2.2208120822906494, 2.5380711555480957, 2.062182664871216, 2.379441738128662]}, \"mean\": [2.855329990386963, 2.855329990386963, 2.855329990386963, 2.062182664871216, 3.4898476600646973, 2.5380711555480957, 1.7449238300323486, 1.4276649951934814, 2.2208120822906494, 2.5380711555480957, 2.062182664871216, 2.379441738128662]}\n",
      "{\"item_id\": null, \"quantiles\": {\"0.1\": [23.026315689086914, 23.026315689086914, 30.227596282958984, 32.45021438598633, 31.38335609436035, 30.938833236694336, 29.33854866027832, 28.98293113708496, 30.672119140625, 30.938833236694336, 27.204835891723633, 24.715505599975586], \"0.2\": [23.026315689086914, 23.026315689086914, 30.227596282958984, 32.45021438598633, 31.38335609436035, 30.938833236694336, 29.33854866027832, 28.98293113708496, 30.672119140625, 30.938833236694336, 27.204835891723633, 24.715505599975586], \"0.3\": [23.026315689086914, 23.026315689086914, 30.227596282958984, 32.45021438598633, 31.38335609436035, 30.938833236694336, 29.33854866027832, 28.98293113708496, 30.672119140625, 30.938833236694336, 27.204835891723633, 24.715505599975586], \"0.4\": [23.026315689086914, 23.026315689086914, 30.227596282958984, 32.45021438598633, 31.38335609436035, 30.938833236694336, 29.33854866027832, 28.98293113708496, 30.672119140625, 30.938833236694336, 27.204835891723633, 24.715505599975586], \"0.5\": [23.026315689086914, 23.026315689086914, 30.227596282958984, 32.45021438598633, 31.38335609436035, 30.938833236694336, 29.33854866027832, 28.98293113708496, 30.672119140625, 30.938833236694336, 27.204835891723633, 24.715505599975586], \"0.6\": [23.026315689086914, 23.026315689086914, 30.227596282958984, 32.45021438598633, 31.38335609436035, 30.938833236694336, 29.33854866027832, 28.98293113708496, 30.672119140625, 30.938833236694336, 27.204835891723633, 24.715505599975586], \"0.7\": [23.026315689086914, 23.026315689086914, 30.227596282958984, 32.45021438598633, 31.38335609436035, 30.938833236694336, 29.33854866027832, 28.98293113708496, 30.672119140625, 30.938833236694336, 27.204835891723633, 24.715505599975586], \"0.8\": [23.026315689086914, 23.026315689086914, 30.227596282958984, 32.45021438598633, 31.38335609436035, 30.938833236694336, 29.33854866027832, 28.98293113708496, 30.672119140625, 30.938833236694336, 27.204835891723633, 24.715505599975586], \"0.9\": [23.026315689086914, 23.026315689086914, 30.227596282958984, 32.45021438598633, 31.38335609436035, 30.938833236694336, 29.33854866027832, 28.98293113708496, 30.672119140625, 30.938833236694336, 27.204835891723633, 24.715505599975586]}, \"mean\": [23.026315689086914, 23.026315689086914, 30.227596282958984, 32.45021438598633, 31.38335609436035, 30.938833236694336, 29.33854866027832, 28.98293113708496, 30.672119140625, 30.938833236694336, 27.204835891723633, 24.715505599975586]}\n",
      "\n",
      "CPU times: user 4.28 ms, sys: 377 s, total: 4.65 ms\n",
      "Wall time: 2.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    TargetModel='SeasonalNaivePredictor.tar.gz',\n",
    "    Body=payload)\n",
    "\n",
    "print(response['Body'].read().decode(\"utf-8\"), sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. How to Do Batch Transform in the Multi Model Server Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MMS does not support batch transform directly, to perform batch tranform. We need to create models seperately in Sagemaker, and do the batch transform for each model one by one. Below shows an example of how to do batch transoform for one model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create the Sagemaker model from the model artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: DEMO-GluonTSModel-RForecastPredictor-2020-08-19-05-40-05\n",
      "Model data Url: https://s3-ap-southeast-2.amazonaws.com/sagemaker-ap-southeast-2-783128296767/demo-multimodel-gluonts-endpoint/models/RForecastPredictor.tar.gz\n",
      "Container image: 783128296767.dkr.ecr.ap-southeast-2.amazonaws.com/demo-sagemaker-multimodel-gluonts:latest\n",
      "Model Arn: arn:aws:sagemaker:ap-southeast-2:783128296767:model/demo-gluontsmodel-rforecastpredictor-2020-08-19-05-40-05\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "model = 'RForecastPredictor'\n",
    "model_name_bt = 'DEMO-GluonTSModel-{}-'.format(model) + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "model_url = 'https://s3-{}.amazonaws.com/{}/{}/{}/{}.tar.gz'.format(region, bucket, prefix, models_dir, model)\n",
    "container = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account_id, region, 'demo-sagemaker-multimodel-gluonts')\n",
    "\n",
    "print('Model name: ' + model_name_bt)\n",
    "print('Model data Url: ' + model_url)\n",
    "print('Container image: ' + container)\n",
    "\n",
    "container = {\n",
    "    'Image': container,\n",
    "    'ModelDataUrl': model_url,\n",
    "    'Mode': 'SingleModel'\n",
    "}\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName = model_name_bt,\n",
    "    ExecutionRoleArn = role,\n",
    "    Containers = [container])\n",
    "\n",
    "print(\"Model Arn: \" + create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Start the Batch Transform Job Using the Model Created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TransformJobArn': 'arn:aws:sagemaker:ap-southeast-2:783128296767:transform-job/demo-gluonts-rforecastpredictor-bt-2020-08-19-05-40-05',\n",
       " 'ResponseMetadata': {'RequestId': '26765de0-b2de-44e2-b099-8b69170deb33',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '26765de0-b2de-44e2-b099-8b69170deb33',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '136',\n",
       "   'date': 'Wed, 19 Aug 2020 05:40:05 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_s3_path = \"s3://{}/{}/data/test.json\".format(bucket, prefix)\n",
    "transform_job_name = 'DEMO-GluonTS-{}-BT-'.format(model) + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "transform_input = {\n",
    "        'DataSource': {\n",
    "            'S3DataSource': {\n",
    "                'S3DataType': 'S3Prefix',\n",
    "                'S3Uri': test_data_s3_path\n",
    "            }\n",
    "        },\n",
    "        'ContentType': 'application/json',\n",
    "        'CompressionType': 'None',\n",
    "        'SplitType': 'Line'\n",
    "    }\n",
    "\n",
    "transform_output = {\n",
    "        'S3OutputPath': 's3://{}/{}/inference-results/{}'.format(bucket,prefix, model),\n",
    "    }\n",
    "\n",
    "transform_resources = {\n",
    "        'InstanceType': 'ml.m5.xlarge',\n",
    "        'InstanceCount': 1\n",
    "    }\n",
    "\n",
    "sm_client.create_transform_job(TransformJobName = transform_job_name,\n",
    "                        ModelName = model_name_bt,\n",
    "                        BatchStrategy='SingleRecord',\n",
    "                        TransformInput = transform_input,\n",
    "                        TransformOutput = transform_output,\n",
    "                        TransformResources = transform_resources\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Check the Batch Transform Job Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobStatus\n",
      "----------\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "print ('JobStatus')\n",
    "print('----------')\n",
    "from time import sleep\n",
    "\n",
    "describe_response = sm_client.describe_transform_job(TransformJobName = transform_job_name)\n",
    "job_run_status = describe_response['TransformJobStatus']\n",
    "print (job_run_status)\n",
    "\n",
    "while job_run_status not in ('Failed', 'Completed', 'Stopped'):\n",
    "    describe_response = sm_client.describe_transform_job(TransformJobName = transform_job_name)\n",
    "    job_run_status = describe_response['TransformJobStatus']\n",
    "    print (job_run_status)\n",
    "    sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Inspect Batch Transform Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'item_id': None, 'quantiles': {'0.1': [0.8739945142644148, 0.48590547682888907, 0.3495625716857571, 0.1881405425184468, 0.4120799826333963, 0.0887970798999555, 0.29328429101392084, -0.08477926123025958, -0.4279553426660536, -0.13218306572573635, -0.5106247937961955, -0.3484832050003658], '0.2': [1.1991201764912163, 1.1606712157313253, 0.9725920532317711, 0.8718231301022143, 0.823875705284148, 0.6846382892416263, 0.8540394642411657, 0.38673848116402554, 0.3677199915723022, 0.4581388006244055, 0.5384592225328939, 0.43358834066061624], '0.3': [1.479926211688551, 1.4538570885019322, 1.331539427810686, 1.2532369983806533, 1.4616627239928386, 1.276972950323639, 1.1884392369790824, 0.9636320417985633, 0.836005123010022, 0.8733827141425876, 1.2203907694739538, 0.7285377823797798], '0.4': [2.016449010383011, 1.9753166138911564, 1.6359777629053787, 1.9290972137991216, 1.8496370305016425, 1.7190062168178777, 1.9021125357740383, 1.5930178439096165, 1.6886204575683743, 1.5072896969056522, 1.8703227173789019, 1.6434078633761624], '0.5': [2.182014168108404, 2.404287104065383, 2.0753185527432136, 2.325627394642921, 2.300904490696238, 2.055340842887066, 2.229760468326459, 2.1120650077074785, 1.9851241205002945, 1.9615614466161235, 2.23923713098032, 1.8834143412242719], '0.6': [2.5598555566904126, 2.5076766397521375, 2.449501692043561, 2.6172177522146125, 2.64514770940832, 2.2566394645365437, 2.4588025446458497, 2.374945098707438, 2.6174827884046876, 2.4277265746378873, 2.613461030991428, 2.360429524509022], '0.7': [2.8039298905867187, 2.762380332352654, 2.727564623925118, 3.0890842350654752, 3.17164175259047, 2.8923472378239414, 3.0466560889493985, 2.9525494271257826, 3.1347461636192984, 3.3654719957408252, 2.9057666972932905, 3.1746704178697702], '0.8': [3.0181528364535177, 3.061494002217384, 3.1567269393163597, 3.5527619706194464, 4.012792068140817, 3.470238106961041, 3.748555687787187, 3.4261591892329393, 3.757459854369391, 3.971884876449595, 3.654637574388346, 4.170086195675444], '0.9': [3.391009928090389, 3.562525998987522, 3.6865460798019827, 4.315927476927621, 4.577248223736041, 4.393804514202094, 4.313788149820394, 4.602704995496515, 4.703106543655252, 4.501667920562465, 4.469504661019359, 5.006538075363313]}, 'mean': [2.167310326333044, 2.164512679014738, 2.0595658962481544, 2.2316645226033067, 2.3291014589428873, 2.136573616339191, 2.1961746549187153, 2.0866235374410227, 2.016367078022199, 2.132414533740041, 2.116787910928974, 2.081604924677783]}, {'item_id': None, 'quantiles': {'0.1': [21.383784916723467, 21.288884979580487, 25.917160811348342, 29.564660560376385, 29.708482902073552, 29.841728258908038, 28.865648092008446, 26.92143877545348, 30.133420382428522, 30.671373067754693, 25.000717195040735, 22.894792123462942], '0.2': [21.93814361054814, 21.671138548395717, 26.643895052238953, 30.116755276531155, 30.622744258045593, 30.729447391452684, 29.49954205072827, 27.88458346944886, 30.86593208320603, 31.289532318996677, 26.09671546802741, 23.34328301001595], '0.3': [22.423500120573067, 22.31288503564003, 27.193158926957825, 30.653711575913107, 30.931772463965803, 31.201390011906966, 30.199828418224012, 28.202752969533257, 31.287657415919867, 31.770241108850772, 26.701224978055116, 23.659537166653415], '0.4': [22.725467474621485, 22.76247402967518, 27.612575334440812, 31.084084019297993, 31.339287320951172, 31.580550546720744, 30.416831576989185, 28.70563306750846, 31.52461975950191, 31.986698893176996, 27.352460590734275, 24.169618280619222], '0.5': [23.302958031300374, 23.28277832376596, 28.019683037983476, 31.705653545395574, 31.673726679489832, 32.07741774782925, 31.010212811515373, 29.05334934194346, 32.23422090370487, 32.49856213749402, 27.70458152716425, 24.548064406032513], '0.6': [23.70745766456245, 23.62611238363877, 28.36572688632024, 32.17555755943304, 32.17998792281666, 32.539011367738844, 31.377733411906558, 29.47217257997595, 32.64396335243342, 33.00637492861892, 28.21642483449948, 24.944525345306367], '0.7': [23.904030012871512, 24.133145097927958, 28.708676385781416, 32.52201036726415, 32.56899062070017, 33.142792739491895, 31.776120389045477, 30.084746596329584, 33.082670745055026, 33.375582647583315, 28.613087136814976, 25.41800367854091], '0.8': [24.60334314369676, 24.425036422095268, 29.091647011491705, 33.10369223406857, 32.86790290183262, 33.736693981860796, 32.28544522224254, 30.5081499707262, 33.64161631945799, 33.882516823698204, 29.108236028649305, 26.13729520602164], '0.9': [25.241640108900828, 25.0678215449348, 29.68573768182209, 33.90130690604575, 33.89275664490259, 34.51655000611572, 32.9413995154505, 31.083857107638845, 34.01634500232341, 34.303427329134465, 29.622124537636303, 26.84181810539067]}, 'mean': [23.289115617879048, 23.156099752816793, 27.94007096864577, 31.69365977575886, 31.81030680513245, 32.13756191418341, 30.865465887427398, 29.09747913387278, 32.114525702705244, 32.54833795470006, 27.54693519836517, 24.718976585905484]}]\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "s3_client.download_file(Filename='data/test.json.out',\n",
    "                        Bucket=bucket,\n",
    "                        Key='{}/inference-results/{}/test.json.out'.format(prefix, model))\n",
    "test_out_jsonline = read_data('data/test.json.out')\n",
    "print(test_out_jsonline[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Clean up the resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Delete the hosting resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'c1a2e521-143e-420d-b37b-cfd83eaf6ce7',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'c1a2e521-143e-420d-b37b-cfd83eaf6ce7',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Wed, 19 Aug 2020 05:50:00 GMT'},\n",
       "  'RetryAttempts': 2}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sm_client.delete_model(ModelName=model_name)\n",
    "sm_client.delete_model(ModelName=model_name_bt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series data is a highly valuable data source to various businesses, and the ability to forecast such data is critial to making optimal and accurate business decisions. In stead of using AWS build-in services or algorithms, this tutorial has demonstated how to use AWS Sagemaker to build your own custom algorithm to do forecast, and deploy multiple forecast models into one Sagemaker endpoint. This will facilitate businesses to compare state-of-the-art algorithms more efficientily and effectively, and enable the possiblilities to do smarter decisions based on the forecast.\n",
    "\n",
    "We have covered other use cases related to time series data as well, you can find other topics below:\n",
    "\n",
    "- Forecast air pollution with SageMaker processing and the AWS Open Data Registry by Eric Greene\n",
    "- Automate sales projections with Amazon Forecast, QuickSight and AWS Lambda by Yoshiyuki Ito\n",
    "- Detect DDoS Attacks with Kineses Data Streams and SageMaker Isolation Forest by Seongmoon Kang"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_gluonts-multimodel",
   "language": "python",
   "name": "conda_gluonts-multimodel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
